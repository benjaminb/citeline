{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c4115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================CONFIG=================================\n",
      "Database         User             Host                             Port            \n",
      "citelinedb       bbasseri         localhost                        5432            \n",
      "========================================================================\n",
      "Database version: ('PostgreSQL 17.5 (Homebrew) on aarch64-apple-darwin24.4.0, compiled by Apple clang version 17.0.0 (clang-1700.0.13.3), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "from database.database import Database\n",
    "\n",
    "\n",
    "db = Database()\n",
    "db.test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c7ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded samples: 326\n",
      "Embedder: BAAI/bge-large-en-v1.5, device=mps, normalize=True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from Embedders import get_embedder\n",
    "\n",
    "DATASET_PATH = \"data/dataset/split/train.jsonl\"\n",
    "EMBEDDER_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "samples = pd.read_json(DATASET_PATH, lines=True)\n",
    "embedder = get_embedder(EMBEDDER_NAME, device=device, normalize=True)\n",
    "print(f\"Loaded samples: {len(samples)}\")\n",
    "print(\"Embedder:\", embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b4136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example paper reconstruction:\n",
      "The morphology of extragalactic radio sources of high and low luminosity\n",
      "\n",
      "Abstract: The relative positions of the high and low brightness regions in the extragalactic sources in the 3 CR complete sample are found to be correlated with the luminosity of these sources.\n",
      "\n",
      "Mon. Not. R. astr. Soc. (i~y~.) 167, Short Communication, 3 IP-35P. THE MORPHOLOGY OF EXTRAGALACTIC RADIO SOURCES OF HIGH AND LOW LUMINOSITY B. L. Fanaroff and J. M. Riley (Received 1974 March 6) SUMMARY The relative positions of t\n"
     ]
    }
   ],
   "source": [
    "research = pd.read_json(\"data/preprocessed/research.jsonl\", lines=True)\n",
    "\n",
    "def reconstruct_paper(example: pd.Series) -> str:\n",
    "    return f\"{example['title']}\\n\\nAbstract: {example['abstract']}\\n\\n{example['body']}\"\n",
    "\n",
    "print(\"Example paper reconstruction:\")\n",
    "print(reconstruct_paper(research.iloc[0])[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f067f54c",
   "metadata": {},
   "source": [
    "### Establish set of documents to expand \n",
    "\n",
    "Since a target paper may appear in any number of training samples, we first collect the doi's of the document expansions already inserted into the database, then subtract them from the set of target doi's appearing in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c44273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing DOIs in database: 163\n",
      "Target DOIs to expand: 81\n"
     ]
    }
   ],
   "source": [
    "expanded_dois = set()\n",
    "\n",
    "# First, get the DOIs from the database that have already been expanded and inserted\n",
    "with db.conn.cursor() as cursor:\n",
    "    cursor.execute(\n",
    "        \"SELECT DISTINCT doi from contributions\"\n",
    "    )\n",
    "    existing_dois = {row[0] for row in cursor.fetchall()}\n",
    "    expanded_dois.update(existing_dois)\n",
    "print(f\"Existing DOIs in database: {len(existing_dois)}\")\n",
    "\n",
    "target_dois = set(doi for dois in samples[\"citation_dois\"] for doi in dois) - expanded_dois\n",
    "print(f\"Target DOIs to expand: {len(target_dois)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc4f8c",
   "metadata": {},
   "source": [
    "### Iterate over training set\n",
    "\n",
    "Next we iterate over the training set. Each example has one or more target doi's. These targets should be present in the `research` data frame, so using the doi we retrieve the `pd.Series` for that row. We can then reconstruct the paper (title, abstract, and body) and send to LLM for document expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e75e96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deepseek api, which copies the openai api\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "\n",
    "def deepseek_client():\n",
    "    assert \"DEEPSEEK_API_KEY\" in os.environ, \"DEEPSEEK_API_KEY must be set in environment variables\"\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    return client\n",
    "\n",
    "client = deepseek_client()\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert research assistant. Summarize the original scientific findings of the following research paper. Then write them out as a list of strings.\n",
    "\n",
    "## Task\n",
    "- Write the findings as a JSON array of strings, each finding being one string element.\n",
    "- Do not include acknowledgments or references: focus only on the original research contributions made in this paper\n",
    "- Only write out the JSON array, do not include any other text or formatting.\n",
    "\n",
    "Example output:\n",
    "{\n",
    "  findings: [\"Contribution 1\", \"Contribution 2\", \"Contribution 3\"]\n",
    "}\n",
    "\n",
    "## Paper:\n",
    "\"\"\"\n",
    "\n",
    "def get_deepseek_response(paper: str):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": paper}\n",
    "            ],\n",
    "            response_format={'type': 'json_object'},\n",
    "            stream=False\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e722f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DOI: 10.1086/430438\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/430438: 7 findings\n",
      "Processing DOI: 10.1051/0004-6361:20054427\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361:20054427: 16 findings\n",
      "Processing DOI: 10.1086/301341\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/301341: 10 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2005.10018.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2005.10018.x: 9 findings\n",
      "Processing DOI: 10.1086/421110\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/421110: 8 findings\n",
      "Processing DOI: 10.1086/324269\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/324269: 19 findings\n",
      "Processing DOI: 10.1093/mnras/stx071\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stx071: 10 findings\n",
      "Processing DOI: 10.1093/mnras/stae1049\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stae1049: 6 findings\n",
      "Processing DOI: 10.1086/170699\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/170699: 8 findings\n",
      "Processing DOI: 10.1029/2002JA009418\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1029/2002JA009418: 8 findings\n",
      "Processing DOI: 10.1038/nature12050\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1038/nature12050: 13 findings\n",
      "Processing DOI: 10.1088/0004-637X/792/1/8\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/792/1/8: 10 findings\n",
      "Processing DOI: 10.1088/0004-637X/756/2/164\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/756/2/164: 7 findings\n",
      "Processing DOI: 10.1086/344504\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/344504: 8 findings\n",
      "Processing DOI: 10.1093/mnras/stv2428\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stv2428: 10 findings\n",
      "Processing DOI: 10.1086/509786\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/509786: 12 findings\n",
      "Processing DOI: 10.1086/321402\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/321402: 8 findings\n",
      "Processing DOI: 10.1051/0004-6361:20041951\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361:20041951: 9 findings\n",
      "Processing DOI: 10.1093/mnras/stad3920\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stad3920: 8 findings\n",
      "Processing DOI: 10.1086/517927\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/517927: 10 findings\n",
      "Processing DOI: 10.1093/mnras/stw1066\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stw1066: 10 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2004.08313.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2004.08313.x: 9 findings\n",
      "Processing DOI: 10.1088/0004-637X/746/2/125\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/746/2/125: 8 findings\n",
      "Processing DOI: 10.1093/mnras/250.1.198\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/250.1.198: 8 findings\n",
      "Processing DOI: 10.1093/mnras/staa1522\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/staa1522: 12 findings\n",
      "Processing DOI: 10.1086/306975\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/306975: 5 findings\n",
      "Processing DOI: 10.1086/376841\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/376841: 9 findings\n",
      "Processing DOI: 10.1086/172262\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/172262: 8 findings\n",
      "Processing DOI: 10.1086/521871\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/521871: 6 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2006.10660.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2006.10660.x: 8 findings\n",
      "Processing DOI: 10.1051/0004-6361/201014694\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361/201014694: 8 findings\n",
      "Processing DOI: 10.1126/science.1209069\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1126/science.1209069: 9 findings\n",
      "Processing DOI: 10.1086/303726\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/303726: 10 findings\n",
      "Processing DOI: 10.1086/521818\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/521818: 7 findings\n",
      "Processing DOI: 10.1088/0004-637X/777/1/59\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/777/1/59: 7 findings\n",
      "Processing DOI: 10.3847/1538-4357/aad55b\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.3847/1538-4357/aad55b: 8 findings\n",
      "Processing DOI: 10.1093/mnras/stu1536\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stu1536: 10 findings\n",
      "Processing DOI: 10.1086/374306\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/374306: 7 findings\n",
      "Processing DOI: 10.1086/426070\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/426070: 5 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2009.14677.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2009.14677.x: 10 findings\n",
      "Processing DOI: 10.1088/0004-637X/730/1/15\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/730/1/15: 9 findings\n",
      "Processing DOI: 10.1093/mnrasl/slz070\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnrasl/slz070: 11 findings\n",
      "Processing DOI: 10.1046/j.1365-8711.2003.06897.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1046/j.1365-8711.2003.06897.x: 8 findings\n",
      "Processing DOI: 10.1093/mnras/258.1.29P\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/258.1.29P: 9 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2007.12671.x\n",
      "Error getting response for DOI 10.1111/j.1365-2966.2007.12671.x: Error code: 400 - {'error': {'message': \"This model's maximum context length is 65536 tokens. However, you requested 102177 tokens (102177 in the messages, 0 in the completion). Please reduce the length of the messages or completion.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "Processing DOI: 10.1086/171448\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/171448: 9 findings\n",
      "Processing DOI: 10.1051/0004-6361:20066327\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361:20066327: 5 findings\n",
      "Processing DOI: 10.1093/mnras/staa876\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/staa876: 10 findings\n",
      "Processing DOI: 10.1093/mnras/stu2058\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stu2058: 7 findings\n",
      "Processing DOI: 10.1086/191163\n",
      "Error getting response for DOI 10.1086/191163: Error code: 400 - {'error': {'message': \"This model's maximum context length is 65536 tokens. However, you requested 379855 tokens (379855 in the messages, 0 in the completion). Please reduce the length of the messages or completion.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "Processing DOI: 10.1088/0004-637X/770/1/57\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/770/1/57: 10 findings\n",
      "Processing DOI: 10.1093/mnras/stv575\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stv575: 10 findings\n",
      "Processing DOI: 10.1051/0004-6361:20034500\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361:20034500: 6 findings\n",
      "Processing DOI: 10.1093/mnras/stab323\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stab323: 12 findings\n",
      "Processing DOI: 10.1086/426376\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/426376: 10 findings\n",
      "Processing DOI: 10.1086/524921\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/524921: 10 findings\n",
      "Processing DOI: 10.1088/0004-637X/751/1/70\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/751/1/70: 10 findings\n",
      "Processing DOI: 10.1086/431894\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/431894: 9 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2011.18795.x\n",
      "Error getting response for DOI 10.1111/j.1365-2966.2011.18795.x: Error code: 400 - {'error': {'message': \"This model's maximum context length is 65536 tokens. However, you requested 121877 tokens (121877 in the messages, 0 in the completion). Please reduce the length of the messages or completion.\", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "Processing DOI: 10.1038/nature12898\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1038/nature12898: 7 findings\n",
      "Processing DOI: 10.3847/2041-8213/ac5589\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.3847/2041-8213/ac5589: 8 findings\n",
      "Processing DOI: 10.3847/0004-637X/824/1/57\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.3847/0004-637X/824/1/57: 11 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2008.13979.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2008.13979.x: 7 findings\n",
      "Processing DOI: 10.1088/0004-637X/788/2/119\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/788/2/119: 9 findings\n",
      "Processing DOI: 10.1093/mnras/stz1770\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stz1770: 12 findings\n",
      "Processing DOI: 10.1086/376502\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/376502: 6 findings\n",
      "Processing DOI: 10.1038/nature03879\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1038/nature03879: 10 findings\n",
      "Processing DOI: 10.1093/mnras/252.4.586\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/252.4.586: 13 findings\n",
      "Processing DOI: 10.1093/mnras/stv2314\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stv2314: 12 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2004.08349.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2004.08349.x: 9 findings\n",
      "Processing DOI: 10.1093/mnras/stac1686\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1093/mnras/stac1686: 8 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2004.07881.x\n",
      "Error parsing JSON response for DOI 10.1111/j.1365-2966.2004.07881.x: Invalid \\escape: line 4 column 116 (char 324)\n",
      "Processing DOI: 10.1111/j.1365-2966.2005.09238.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2005.09238.x: 6 findings\n",
      "Processing DOI: 10.1038/s41586-018-0625-x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1038/s41586-018-0625-x: 9 findings\n",
      "Processing DOI: 10.1086/587486\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/587486: 7 findings\n",
      "Processing DOI: 10.3847/1538-4357/835/1/52\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.3847/1538-4357/835/1/52: 7 findings\n",
      "Processing DOI: 10.1088/0004-637X/709/2/644\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/709/2/644: 14 findings\n",
      "Processing DOI: 10.1088/0004-637X/735/1/66\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1088/0004-637X/735/1/66: 15 findings\n",
      "Processing DOI: 10.1086/375181\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1086/375181: 9 findings\n",
      "Processing DOI: 10.1111/j.1365-2966.2011.20189.x\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1111/j.1365-2966.2011.20189.x: 10 findings\n",
      "Processing DOI: 10.1051/0004-6361/201321100\n",
      "  Embedding & inserting findings into database...\n",
      "  Processed DOI 10.1051/0004-6361/201321100: 8 findings\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "all_findings = dict()\n",
    "with open(\"error_log.csv\", \"w\") as f:\n",
    "    f.write(\"doi,error,api_response\\n\")\n",
    "\n",
    "for doi in target_dois:\n",
    "    print(f\"Processing DOI: {doi}\")\n",
    "    paper = research[research[\"doi\"] == doi].iloc[0]\n",
    "    reconstructed_paper = reconstruct_paper(paper)\n",
    "\n",
    "    json_response = None\n",
    "    try:\n",
    "        json_response = get_deepseek_response(reconstructed_paper)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting response for DOI {doi}: {e}\")\n",
    "        with open(\"error_log.csv\", \"a\") as f:\n",
    "            f.write(f\"{doi},{e},None\\n\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        findings_object = json.loads(json_response)\n",
    "        sentences = findings_object['findings']\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"Error parsing JSON response for DOI {doi}: {e}\")\n",
    "        with open(\"error_log.csv\", \"a\") as f:\n",
    "            f.write(f\"{doi},{e},{json_response}\\n\")\n",
    "        continue\n",
    "    all_findings[doi] = sentences\n",
    "\n",
    "    print(\"  Embedding & inserting findings into database...\")\n",
    "    embeddings = embedder(sentences)\n",
    "\n",
    "    # Get the associated pubdate\n",
    "    pubdate = (\n",
    "        research[research[\"doi\"] == doi][\"pubdate\"].values[0]\n",
    "        if not research[research[\"doi\"] == doi].empty\n",
    "        else None\n",
    "    )\n",
    "    if not pubdate:\n",
    "        print(f\"Warning: No pubdate found for DOI {doi}. Skipping.\")\n",
    "        continue\n",
    "    with db.conn.cursor() as cursor:\n",
    "        for embedding, text in zip(embeddings, sentences):\n",
    "            # Insert into the database\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO contributions (embedding, text, pubdate, doi) VALUES (%s, %s, %s, %s)\",\n",
    "                (embedding, text, pubdate, doi),\n",
    "            )\n",
    "    db.conn.commit()\n",
    "    print(f\"  Processed DOI {doi}: {len(sentences)} findings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1b503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually insert improperly formatted findings\n",
    "doi = \"10.1111/j.1365-2966.2004.07881.x\"\n",
    "sentences = [\n",
    "    \"Developed a method for aperture correction using resolved imaging to remove aperture bias in star formation rate (SFR) estimates, enabling accurate total SFR calculations in galaxies.\",\n",
    "    \"Determined the SFR density to be 1.915^{+0.02}_{-0.01} (random)^{+0.14}_{-0.42} (systematic) h_{70}10^{-2} M_{\\odot} yr^{-1} Mpc^{-3} at z=0.1 for a Kroupa initial mass function.\",\n",
    "    \"Found that the majority of star formation in the low-redshift Universe occurs in moderately massive galaxies (10^{10}-10^{11} M_{\\odot}), typically in high surface brightness disc galaxies.\",\n",
    "    \"Approximately 15% of all star formation takes place in galaxies showing signs of an active nucleus, and about 20% occurs in starburst galaxies.\",\n",
    "    \"Showed that the present to past average SFR, the Scalo b-parameter, is almost constant over almost three orders of magnitude in mass, declining only at M_{*} > 10^{10} M_{\\odot}.\",\n",
    "    \"The volume averaged b parameter is 0.408^{+0.005}_{-0.002} (random)^{+0.029}_{-0.090}h^{-1}_{70}, used to constrain the star formation history of the Universe.\",\n",
    "    \"For the concordance cosmology, the present-day Universe is forming stars at at least 1/3 of its past average rate, corresponding to a time-scale of 7^{+0.7}_{-1.5} Gyr for an exponentially declining cosmic star formation history.\",\n",
    "    \"Found a correlation between b and morphological type, as well as a tight correlation between the 4000-Ã… break (D4000) and b, suggesting D4000 can estimate b parameters for high-redshift galaxies.\",\n",
    "]\n",
    "embeddings = embedder(sentences)\n",
    "\n",
    "pubdate = (\n",
    "        research[research[\"doi\"] == doi][\"pubdate\"].values[0]\n",
    "        if not research[research[\"doi\"] == doi].empty\n",
    "        else None\n",
    "    )\n",
    "if not pubdate:\n",
    "    print(f\"Warning: No pubdate found for DOI {doi}. Skipping.\")\n",
    "else:\n",
    "    with db.conn.cursor() as cursor:\n",
    "        for embedding, text in zip(embeddings, sentences):\n",
    "            # Insert into the database\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO contributions (embedding, text, pubdate, doi) VALUES (%s, %s, %s, %s)\",\n",
    "                (embedding, text, pubdate, doi),\n",
    "            )\n",
    "    db.conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Abstract: {long_example['abstract'][:500]}\")\n",
    "print(f\"Body length: {len(long_example['body'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc95ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('catalog.txt', 'w') as f:\n",
    "    f.write(reconstruct_paper(long_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b10caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
