{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3429e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_json(\"../data/preprocessed/research.jsonl\", lines=True, nrows=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323dbba",
   "metadata": {},
   "source": [
    "## Tuning the Semantic Chunker\n",
    "\n",
    "Goal: find the semantic chunker settings that will most accurately chunk research papers to **paragraphs**\n",
    "\n",
    "Methodology: \n",
    "1. Pick 3 random papers\n",
    "2. Using their original papers, identify the paragraph boundaries\n",
    "3. Grid Search over SemanticChunker parameters to find the one that most aligns with paragraph chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a84f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bibcode</th>\n",
       "      <th>abstract</th>\n",
       "      <th>aff</th>\n",
       "      <th>author</th>\n",
       "      <th>bibstem</th>\n",
       "      <th>doctype</th>\n",
       "      <th>doi</th>\n",
       "      <th>id</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>title</th>\n",
       "      <th>read_count</th>\n",
       "      <th>reference</th>\n",
       "      <th>data</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>citation</th>\n",
       "      <th>body</th>\n",
       "      <th>dois</th>\n",
       "      <th>keywords</th>\n",
       "      <th>loaded_from</th>\n",
       "      <th>body_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2007MNRAS.379.1599L</td>\n",
       "      <td>We describe the goals, design, implementation,...</td>\n",
       "      <td>[Institute for Astronomy, SUPA (Scottish Unive...</td>\n",
       "      <td>[Lawrence, A., Warren, S. J., Almaini, O., Edg...</td>\n",
       "      <td>[MNRAS, MNRAS.379]</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1111/j.1365-2966.2007.12040.x</td>\n",
       "      <td>2344762</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>The UKIRT Infrared Deep Sky Survey (UKIDSS)</td>\n",
       "      <td>99</td>\n",
       "      <td>[1973asqu.book.....A, 1983ApJ...264..337S, 198...</td>\n",
       "      <td>[CDS:3, IRSA:1, SIMBAD:22]</td>\n",
       "      <td>2215</td>\n",
       "      <td>[2006MNRAS.371.1722D, 2006MNRAS.372..357M, 200...</td>\n",
       "      <td>1 INTRODUCTION The UKIRT Infrared Deep Sky Sur...</td>\n",
       "      <td>[10.1111/j.1365-2966.2007.12040.x, 10.48550/ar...</td>\n",
       "      <td>[surveys, infrared: general, Astrophysics]</td>\n",
       "      <td>data/json/Astro_Research.json</td>\n",
       "      <td>[1 INTRODUCTION The UKIRT Infrared Deep Sky Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>1994MNRAS.271..676L</td>\n",
       "      <td>We have made a detailed comparison of the resu...</td>\n",
       "      <td>[-, -]</td>\n",
       "      <td>[Lacey, C., Cole, S.]</td>\n",
       "      <td>[MNRAS, MNRAS.271]</td>\n",
       "      <td>article</td>\n",
       "      <td>10.1093/mnras/271.3.676</td>\n",
       "      <td>3121109</td>\n",
       "      <td>1994-12-01</td>\n",
       "      <td>Merger Rates in Hierarchical Models of Galaxy ...</td>\n",
       "      <td>46</td>\n",
       "      <td>[1974ApJ...187..425P, 1977ApJS...34..425D, 197...</td>\n",
       "      <td>None</td>\n",
       "      <td>678</td>\n",
       "      <td>[1994MNRAS.271..781C, 1994astro.ph.12088M, 199...</td>\n",
       "      <td>19 94MNRAS.271. .676L Mon. Not. R. Astron. Soc...</td>\n",
       "      <td>[10.1093/mnras/271.3.676, 10.48550/arXiv.astro...</td>\n",
       "      <td>[Astrophysics]</td>\n",
       "      <td>data/json/Astro_Research.json</td>\n",
       "      <td>[19 94MNRAS.271.  .676L Mon.  Not.  R. Astron....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2020ApJ...900..179K</td>\n",
       "      <td>To reach a deeper understanding of the origin ...</td>\n",
       "      <td>[Centre for Astrophysics Research, Department ...</td>\n",
       "      <td>[Kobayashi, Chiaki, Karakas, Amanda I., Lugaro...</td>\n",
       "      <td>[ApJ, ApJ...900]</td>\n",
       "      <td>article</td>\n",
       "      <td>10.3847/1538-4357/abae65</td>\n",
       "      <td>19402707</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>The Origin of Elements from Carbon to Uranium</td>\n",
       "      <td>274</td>\n",
       "      <td>[1955ApJ...121..161S, 1957RvMP...29..547B, 196...</td>\n",
       "      <td>[SIMBAD:17]</td>\n",
       "      <td>490</td>\n",
       "      <td>[2020A&amp;A...642A..62A, 2020A&amp;A...643A..49H, 202...</td>\n",
       "      <td>1. Introduction Since the time of Burbidge et ...</td>\n",
       "      <td>[10.3847/1538-4357/abae65, 10.48550/arXiv.2008...</td>\n",
       "      <td>[Galaxy abundances, Stellar abundances, Chemic...</td>\n",
       "      <td>data/json/Astro_Research.json</td>\n",
       "      <td>[1. Introduction Since the time of Burbidge et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bibcode                                           abstract  \\\n",
       "507  2007MNRAS.379.1599L  We describe the goals, design, implementation,...   \n",
       "818  1994MNRAS.271..676L  We have made a detailed comparison of the resu...   \n",
       "452  2020ApJ...900..179K  To reach a deeper understanding of the origin ...   \n",
       "\n",
       "                                                   aff  \\\n",
       "507  [Institute for Astronomy, SUPA (Scottish Unive...   \n",
       "818                                             [-, -]   \n",
       "452  [Centre for Astrophysics Research, Department ...   \n",
       "\n",
       "                                                author             bibstem  \\\n",
       "507  [Lawrence, A., Warren, S. J., Almaini, O., Edg...  [MNRAS, MNRAS.379]   \n",
       "818                              [Lacey, C., Cole, S.]  [MNRAS, MNRAS.271]   \n",
       "452  [Kobayashi, Chiaki, Karakas, Amanda I., Lugaro...    [ApJ, ApJ...900]   \n",
       "\n",
       "     doctype                               doi        id     pubdate  \\\n",
       "507  article  10.1111/j.1365-2966.2007.12040.x   2344762  2007-08-01   \n",
       "818  article           10.1093/mnras/271.3.676   3121109  1994-12-01   \n",
       "452  article          10.3847/1538-4357/abae65  19402707  2020-09-01   \n",
       "\n",
       "                                                 title  read_count  \\\n",
       "507        The UKIRT Infrared Deep Sky Survey (UKIDSS)          99   \n",
       "818  Merger Rates in Hierarchical Models of Galaxy ...          46   \n",
       "452      The Origin of Elements from Carbon to Uranium         274   \n",
       "\n",
       "                                             reference  \\\n",
       "507  [1973asqu.book.....A, 1983ApJ...264..337S, 198...   \n",
       "818  [1974ApJ...187..425P, 1977ApJS...34..425D, 197...   \n",
       "452  [1955ApJ...121..161S, 1957RvMP...29..547B, 196...   \n",
       "\n",
       "                           data  citation_count  \\\n",
       "507  [CDS:3, IRSA:1, SIMBAD:22]            2215   \n",
       "818                        None             678   \n",
       "452                 [SIMBAD:17]             490   \n",
       "\n",
       "                                              citation  \\\n",
       "507  [2006MNRAS.371.1722D, 2006MNRAS.372..357M, 200...   \n",
       "818  [1994MNRAS.271..781C, 1994astro.ph.12088M, 199...   \n",
       "452  [2020A&A...642A..62A, 2020A&A...643A..49H, 202...   \n",
       "\n",
       "                                                  body  \\\n",
       "507  1 INTRODUCTION The UKIRT Infrared Deep Sky Sur...   \n",
       "818  19 94MNRAS.271. .676L Mon. Not. R. Astron. Soc...   \n",
       "452  1. Introduction Since the time of Burbidge et ...   \n",
       "\n",
       "                                                  dois  \\\n",
       "507  [10.1111/j.1365-2966.2007.12040.x, 10.48550/ar...   \n",
       "818  [10.1093/mnras/271.3.676, 10.48550/arXiv.astro...   \n",
       "452  [10.3847/1538-4357/abae65, 10.48550/arXiv.2008...   \n",
       "\n",
       "                                              keywords  \\\n",
       "507         [surveys, infrared: general, Astrophysics]   \n",
       "818                                     [Astrophysics]   \n",
       "452  [Galaxy abundances, Stellar abundances, Chemic...   \n",
       "\n",
       "                       loaded_from  \\\n",
       "507  data/json/Astro_Research.json   \n",
       "818  data/json/Astro_Research.json   \n",
       "452  data/json/Astro_Research.json   \n",
       "\n",
       "                                        body_sentences  \n",
       "507  [1 INTRODUCTION The UKIRT Infrared Deep Sky Su...  \n",
       "818  [19 94MNRAS.271.  .676L Mon.  Not.  R. Astron....  \n",
       "452  [1. Introduction Since the time of Burbidge et...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "sample_df = df.sample(3)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42211ed8",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "1. Get all the first sentences of each paragraph / section\n",
    "1. Ensure the sentence strings appear in the body of each paper **exactly**\n",
    "1. Ensure the sentence strings appear in order wrt the body text on file (some papers jumble sections after OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd25d094",
   "metadata": {},
   "source": [
    "It was discovered that the Ukirt paper's encoding in the dataset contained an error: the paper body was stored twice (meaning the body text was stored then concatenated with itself). The true body is 86621 chars long, so we will manually truncate this in order to configure the chunking correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48d297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86620\n"
     ]
    }
   ],
   "source": [
    "# Get the actual index label of the first row in the sample\n",
    "row_index = sample_df.index[0]\n",
    "\n",
    "# Now use .loc with the index label and column name\n",
    "sample_df.loc[row_index, \"body\"] = sample_df.loc[row_index, \"body\"][:86620]  # Use .loc for setting\n",
    "\n",
    "print(len(sample_df.loc[row_index, \"body\"]))  # Verify using .loc as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635883b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Paper 0] all paragraph sentences are in the paper body: True\n",
      "[Paper 1] all paragraph sentences are in the paper body: True\n",
      "[Paper 2] all paragraph sentences are in the paper body: True\n"
     ]
    }
   ],
   "source": [
    "from first_paragraph_sentences import ukirt, lacey, kobayashi\n",
    "\n",
    "def get_truncated_sentences(lst: list[str], max_length: int = 75) -> list:\n",
    "    return [sentence[:max_length] for sentence in lst]\n",
    "\n",
    "first_paragraph_sentences = [\n",
    "    get_truncated_sentences(ukirt),\n",
    "    get_truncated_sentences(lacey),\n",
    "    get_truncated_sentences(kobayashi)\n",
    "]\n",
    "\n",
    "def are_sentences_in_body(idx) -> bool:\n",
    "    \"\"\"\n",
    "    Check if all sentences in the list are present in the body of the text.\n",
    "    \"\"\"\n",
    "    sentences = first_paragraph_sentences[idx]\n",
    "    paper_body = sample_df.iloc[idx]['body']\n",
    "    all_there = True\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if sentence not in paper_body:\n",
    "            print(f\"Sentence {i} not found: {sentence}\")\n",
    "            all_there = False\n",
    "    return all_there\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"[Paper {i}] all paragraph sentences are in the paper body: {are_sentences_in_body(i)}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98d4080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence indices: [[0, 1518, 2433, 3474, 4807, 5572, 6128, 6581, 7032, 7492, 8671, 9511, 10355, 11150, 11539, 12795, 13083, 14451, 15190, 15713, 17247, 18497, 20756, 21155, 22092, 22695, 24036, 25058, 25420, 27316, 28635, 29299, 29471, 29834, 31209, 32980, 33903, 35312, 35545, 36620, 37913, 38559, 39634, 39750, 41115, 41547, 42333, 45087, 45358, 45857, 45963, 47115, 47314, 48104, 48556, 49693, 50098, 51077, 51793, 52202, 52793, 54029, 55336, 55892, 56568, 57092, 57640, 58888, 59737, 60862, 61401, 61684, 62789, 63205, 63782, 64646, 65845, 66166, 67143, 67920, 68992, 69850, 70443, 70930, 71435, 71584, 72859, 73520, 74424, 75058, 75665, 76049, 76453, 77503, 78061, 79440, 80209, 81690, 82623, 83937, 85140, 86232], [0, 2355, 4217, 7240, 7796, 8573, 10416, 11689, 12200, 12967, 13461, 13992, 15168, 15423, 16484, 18438, 19409, 19653, 20356, 22039, 23560, 24007, 24469, 26148, 26857, 28526, 30410, 31334, 33231, 34643, 35568, 36348, 37572, 38863, 39252, 39948, 42920, 44474, 45196, 47027, 49634, 50188, 52985, 54336, 55613, 56112, 56754, 58011, 59094, 59858, 62232, 63465, 64624, 66540, 67709, 68764], [0, 1125, 2058, 3741, 5369, 6138, 7206, 8394, 10113, 10407, 11540, 12459, 13377, 15127, 16444, 16812, 17751, 18263, 18962, 20050, 20492, 21225, 22897, 24268, 24778, 26111, 27077, 27943, 29186, 29868, 30291, 30909, 31993, 33211, 33981, 35223, 36484, 37345, 38269, 38785, 39308, 39871, 41586, 42260, 42693, 43552, 43835, 44378, 45810, 46997, 47702, 48393, 48877, 51599, 52815, 53364, 54090, 56268, 57248, 58508, 59027, 69722, 71398, 72940, 73947, 74497, 75134, 76201, 77023, 77532, 78167, 78971, 80413, 80784, 81660, 82450, 83191, 83837, 84614, 85338, 86309, 87869, 89160, 90333, 90953, 91369, 92670, 93340, 94367, 95247, 95908, 97877, 98384, 99177, 100731, 104921, 106077, 107122, 107779, 108166, 108893, 111579, 113594, 114584, 115032, 115462, 116103, 117325, 118158, 119447, 120935, 121391, 121753, 122182, 122577, 122763, 123229, 123828, 124446, 125181, 126372, 127634, 128623, 131018, 131818, 133695, 134502, 135462, 136109, 136593, 137213, 137840, 138524, 139047, 139544, 140451]]\n"
     ]
    }
   ],
   "source": [
    "sentence_indices = []\n",
    "for i in range(3):\n",
    "    sentences = first_paragraph_sentences[i]\n",
    "    paper_body = sample_df.iloc[i]['body']\n",
    "    sentence_indices.append([paper_body.index(sentence) for sentence in sentences])\n",
    "print(f\"Sentence indices: {sentence_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778206ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sentences are in order.\n"
     ]
    }
   ],
   "source": [
    "# Confirm the sentences are all in order\n",
    "all_in_order = True\n",
    "for i in range(3):\n",
    "    sent_idx_list = sentence_indices[i]\n",
    "    for j in range(1, len(sent_idx_list)):\n",
    "        if sent_idx_list[j] <= sent_idx_list[j - 1]:\n",
    "            print(f\"Paper {i} Sentence {j} is out of order in paper {i}: {sent_idx_list}\")\n",
    "            print(f\"  Index of sentence {j}: {sent_idx_list[j]}\")\n",
    "            print(f\"  Index of sentence {j-1}: {sent_idx_list[j-1]}\")\n",
    "            all_in_order = False\n",
    "\n",
    "if all_in_order:\n",
    "    print(\"All sentences are in order.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3d71b",
   "metadata": {},
   "source": [
    "## Computing Boundary Similarities\n",
    "\n",
    "1. Package the vetted paragraph start sentences as reference lists\n",
    "1. Create a grid over SemanticChunker parameters for search\n",
    "1. For each parameter config, compare SemanticChunker boundary similarity to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc1ae15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference lengths: [[1518, 915, 1041, 1333, 765, 556, 453, 451, 460, 1179, 840, 844, 795, 389, 1256, 288, 1368, 739, 523, 1534, 1250, 2259, 399, 937, 603, 1341, 1022, 362, 1896, 1319, 664, 172, 363, 1375, 1771, 923, 1409, 233, 1075, 1293, 646, 1075, 116, 1365, 432, 786, 2754, 271, 499, 106, 1152, 199, 790, 452, 1137, 405, 979, 716, 409, 591, 1236, 1307, 556, 676, 524, 548, 1248, 849, 1125, 539, 283, 1105, 416, 577, 864, 1199, 321, 977, 777, 1072, 858, 593, 487, 505, 149, 1275, 661, 904, 634, 607, 384, 404, 1050, 558, 1379, 769, 1481, 933, 1314, 1203, 1092, 388], [2355, 1862, 3023, 556, 777, 1843, 1273, 511, 767, 494, 531, 1176, 255, 1061, 1954, 971, 244, 703, 1683, 1521, 447, 462, 1679, 709, 1669, 1884, 924, 1897, 1412, 925, 780, 1224, 1291, 389, 696, 2972, 1554, 722, 1831, 2607, 554, 2797, 1351, 1277, 499, 642, 1257, 1083, 764, 2374, 1233, 1159, 1916, 1169, 1055, 4311], [1125, 933, 1683, 1628, 769, 1068, 1188, 1719, 294, 1133, 919, 918, 1750, 1317, 368, 939, 512, 699, 1088, 442, 733, 1672, 1371, 510, 1333, 966, 866, 1243, 682, 423, 618, 1084, 1218, 770, 1242, 1261, 861, 924, 516, 523, 563, 1715, 674, 433, 859, 283, 543, 1432, 1187, 705, 691, 484, 2722, 1216, 549, 726, 2178, 980, 1260, 519, 10695, 1676, 1542, 1007, 550, 637, 1067, 822, 509, 635, 804, 1442, 371, 876, 790, 741, 646, 777, 724, 971, 1560, 1291, 1173, 620, 416, 1301, 670, 1027, 880, 661, 1969, 507, 793, 1554, 4190, 1156, 1045, 657, 387, 727, 2686, 2015, 990, 448, 430, 641, 1222, 833, 1289, 1488, 456, 362, 429, 395, 186, 466, 599, 618, 735, 1191, 1262, 989, 2395, 800, 1877, 807, 960, 647, 484, 620, 627, 684, 523, 497, 907, 960]]\n",
      "Paper 0 min length: 106, total length: 86620, original body length: 86620\n",
      "Paper 1 min length: 244, total length: 73075, original body length: 73075\n",
      "Paper 2 min length: 186, total length: 141411, original body length: 141411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reference_lengths = []\n",
    "for i in range(3):\n",
    "    # Compute all the paragraph lengths\n",
    "    idx_list = sentence_indices[i]\n",
    "    paragraph_lengths = [\n",
    "        idx_list[j] - idx_list[j - 1] for j in range(1, len(idx_list))\n",
    "    ]\n",
    "\n",
    "    # Add the last paragraph length\n",
    "    paragraph_lengths.append(len(sample_df.iloc[i]['body']) - idx_list[-1])\n",
    "    reference_lengths.append(paragraph_lengths)\n",
    "\n",
    "print(f\"Reference lengths: {reference_lengths}\")\n",
    "for i in range(3):\n",
    "    print(f\"Paper {i} min length: {min(reference_lengths[i])}, total length: {sum(reference_lengths[i])}, original body length: {len(sample_df.iloc[i]['body'])}\")\n",
    "    assert sum(reference_lengths[i]) == len(sample_df.iloc[i]['body']), f\"Paper {i} length mismatch: {sum(reference_lengths[i])} != {len(sample_df.iloc[i]['body'])}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e602b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "[59027, 69722]\n",
      "['3.2. Elemental Abundances from C to Zn Based on our fiducial model', 'The contribution to GCE from AGB stars (green dotted lines in Figure 5 ) can be seen mainly for C and N, and only slightly for Na, compared with the model that includes supernovae only (blue dashed lines).']\n"
     ]
    }
   ],
   "source": [
    "print(reference_lengths[2].index(10695))\n",
    "print(sentence_indices[2][60:62])\n",
    "print(kobayashi[60:62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06379bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from segeval import boundary_similarity\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import torch\n",
    "\n",
    "# Usage\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# hf_embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"},\n",
    "#     encode_kwargs={\"normalize_embeddings\": False},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b02725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked length: 178503\n",
      "Original length: 178503\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "class LengthPreservingChunker(SemanticChunker):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings,\n",
    "        buffer_size: int = 1,\n",
    "        breakpoint_threshold_type: str = \"percentile\",\n",
    "        breakpoint_threshold_amount: float = 95,\n",
    "        number_of_chunks: int = None,\n",
    "        sentence_split_regex: str = r\"(?<=[.?!]\\s)(?=\\S)\",\n",
    "        min_chunk_size: int = 64,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            embeddings=embeddings,\n",
    "            buffer_size=buffer_size,\n",
    "            breakpoint_threshold_type=breakpoint_threshold_type,\n",
    "            breakpoint_threshold_amount=breakpoint_threshold_amount,\n",
    "            number_of_chunks=number_of_chunks,\n",
    "            sentence_split_regex=sentence_split_regex,\n",
    "            min_chunk_size=min_chunk_size,\n",
    "        )\n",
    "        # Warn user if regex consumes chars\n",
    "        zero_width_pattern = re.compile(\n",
    "            r\"\"\"^(?:\n",
    "            \\(\\?<=[^)]*\\)   # positive lookbehind\n",
    "            | \\(\\?<![^)]*\\)   # negative lookbehind\n",
    "            | \\(\\?=[^)]*\\)    # positive lookahead\n",
    "            | \\(\\?![^)]*\\)    # negative lookahead\n",
    "            | [\\^$]           # start/end anchors\n",
    "            | \\\\[bBAZz]       # \\b, \\B, \\A, \\Z, \\z\n",
    "            )*$\"\"\",\n",
    "            re.VERBOSE\n",
    "        )\n",
    "        if not zero_width_pattern.match(sentence_split_regex):\n",
    "            print(\n",
    "                \"Warning: The sentence_split_regex pattern may consume characters. \"\n",
    "                \"This may modify total text length after splitting text.\"\n",
    "            )\n",
    "\n",
    "    def split_text(self, text: str) -> list[str]:\n",
    "        # Warn user if regex consumes chars\n",
    "\n",
    "        single_sentences = re.split(self.sentence_split_regex, text)\n",
    "        # 2. everything else the same up through finding breakpoints...\n",
    "        distances, sentences = self._calculate_sentence_distances(single_sentences)\n",
    "        if self.number_of_chunks is None:\n",
    "            threshold, dist_array = self._calculate_breakpoint_threshold(distances)\n",
    "        else:\n",
    "            threshold = self._threshold_from_clusters(distances)\n",
    "            dist_array = distances\n",
    "\n",
    "        breakpoints = {i for i, d in enumerate(dist_array) if d > threshold}\n",
    "\n",
    "        # 3. build your chunks **without** injecting extra spaces\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        for bp in sorted(breakpoints):\n",
    "            group = sentences[start : bp + 1]\n",
    "            # ← ← ← here’s the only change\n",
    "            combined = \"\".join(d[\"sentence\"] for d in group)\n",
    "            chunks.append(combined)\n",
    "            start = bp + 1\n",
    "\n",
    "        # last tail\n",
    "        if start < len(sentences):\n",
    "            tail = \"\".join(d[\"sentence\"] for d in sentences[start:])\n",
    "            chunks.append(tail)\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e546cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_params(\n",
    "        model_name: str,\n",
    "        breakpoint_threshold_type: str,\n",
    "        breakpoint_threshold_amount: float,\n",
    "        min_chunk_size: int,):\n",
    "    \"\"\"\n",
    "    Instantiates a chunker with the given parameters and evaluates its boundary similarity on the reference chunks\n",
    "    \"\"\"\n",
    "    # Set up the chunker\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"},\n",
    "        encode_kwargs={\"normalize_embeddings\": False},\n",
    "    )\n",
    "    chunker = LengthPreservingChunker(\n",
    "        embeddings=embeddings,\n",
    "        breakpoint_threshold_type=breakpoint_threshold_type,\n",
    "        breakpoint_threshold_amount=breakpoint_threshold_amount,\n",
    "        min_chunk_size=min_chunk_size,  # in chars\n",
    "    )\n",
    "\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "        # Get the predicted chunks\n",
    "        chunks = chunker.split_text(sample_df.iloc[i]['body'])\n",
    "        chunk_lengths = [len(chunk) for chunk in chunks]\n",
    "\n",
    "        # Compute the boundary similarity score\n",
    "        score = boundary_similarity(reference_lengths[i], chunk_lengths)\n",
    "        scores.append(float(score))\n",
    "        print(f\"[{model_name}]:({breakpoint_threshold_type}:{breakpoint_threshold_amount}), min chunk size {min_chunk_size}: {score}\")\n",
    "    print(\"=======\")\n",
    "\n",
    "    scores = [float(score) for score in scores]\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    with open(\"data/etc/chunker_scores.csv\", \"a\") as f:\n",
    "        f.write(f\"{model_name},{breakpoint_threshold_type},{breakpoint_threshold_amount},{min_chunk_size},{average_score},{scores}\\n\")\n",
    "    return average_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b93d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations generated: 1440\n",
      "First 3 configurations:\n",
      "[{'breakpoint_threshold_amount': 1,\n",
      "  'breakpoint_threshold_type': 'percentile',\n",
      "  'min_chunk_size': 50,\n",
      "  'model_name': 'all-MiniLM-L6-v2'},\n",
      " {'breakpoint_threshold_amount': 1,\n",
      "  'breakpoint_threshold_type': 'percentile',\n",
      "  'min_chunk_size': 100,\n",
      "  'model_name': 'all-MiniLM-L6-v2'},\n",
      " {'breakpoint_threshold_amount': 4,\n",
      "  'breakpoint_threshold_type': 'percentile',\n",
      "  'min_chunk_size': 50,\n",
      "  'model_name': 'all-MiniLM-L6-v2'}]\n"
     ]
    }
   ],
   "source": [
    "MODELS = [\n",
    "    # \"all-MiniLM-L6-v2\",\n",
    "    # \"bert-base-uncased\",\n",
    "    \"adsabs/astroBERT\",\n",
    "    \"BAAI/bge-large-en-v1.5\",\n",
    "    \"nasa-impact/nasa-ibm-st.38m\",\n",
    "]\n",
    "breakpoints = {\n",
    "    \"percentile\": [n for n in range(1, 100, 3)],\n",
    "    \"gradient\": [n for n in range(1, 100, 3)],\n",
    "    \"standard_deviation\": [0.1 * n for n in range(1, 40)],\n",
    "    \"interquartile\": [0.1 * n for n in range(1, 40)],\n",
    "}\n",
    "MIN_CHUNK_SIZES = [50, 100]\n",
    "\n",
    "all_configs_kwargs = []\n",
    "\n",
    "# Iterate through models\n",
    "for model in MODELS:\n",
    "    for bp_type, bp_amounts in breakpoints.items():\n",
    "        for bp_amount in bp_amounts:\n",
    "            for chunk_size in MIN_CHUNK_SIZES:\n",
    "                # Create the kwargs dictionary\n",
    "                config_kwargs = {\n",
    "                    \"model_name\": model,\n",
    "                    \"breakpoint_threshold_type\": bp_type,\n",
    "                    \"breakpoint_threshold_amount\": bp_amount,\n",
    "                    \"min_chunk_size\": chunk_size,\n",
    "                }\n",
    "                all_configs_kwargs.append(config_kwargs)\n",
    "\n",
    "# Print the first few configurations to verify\n",
    "print(f\"Total configurations generated: {len(all_configs_kwargs)}\")\n",
    "print(\"First 3 configurations:\")\n",
    "pprint(all_configs_kwargs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe707214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d3bdae00b34060a4a53484d25989ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 50: 0.05423728813559322033898305085\n",
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 50: 0.08623853211009174311926605505\n",
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 50: 0.09343434343434343434343434343\n",
      "=======\n",
      "0.07797005456000948\n",
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 100: 0.05423728813559322033898305085\n",
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 100: 0.08623853211009174311926605505\n",
      "[all-MiniLM-L6-v2]:(percentile:1), min chunk size 100: 0.09343434343434343434343434343\n",
      "=======\n",
      "0.07797005456000948\n",
      "[all-MiniLM-L6-v2]:(percentile:4), min chunk size 50: 0.05406976744186046511627906977\n",
      "[all-MiniLM-L6-v2]:(percentile:4), min chunk size 50: 0.08679245283018867924528301887\n",
      "[all-MiniLM-L6-v2]:(percentile:4), min chunk size 50: 0.09553903345724907063197026022\n",
      "=======\n",
      "0.07880041790976607\n"
     ]
    }
   ],
   "source": [
    "for config in all_configs_kwargs:\n",
    "    score = evaluate_params(**config)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea28df5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>breakpoint_threshold_type</th>\n",
       "      <th>breakpoint_threshold_amount</th>\n",
       "      <th>min_chunk_size</th>\n",
       "      <th>average_score</th>\n",
       "      <th>score0</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>percentile</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.079138</td>\n",
       "      <td>[0.052663076002393776</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.09525631216526396]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>percentile</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.079138</td>\n",
       "      <td>[0.052663076002393776</td>\n",
       "      <td>0.089494</td>\n",
       "      <td>0.09525631216526396]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>nasa-impact/nasa-ibm-st.38m</td>\n",
       "      <td>percentile</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>[0.054682955206515414</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>0.09553903345724907]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>nasa-impact/nasa-ibm-st.38m</td>\n",
       "      <td>percentile</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>[0.054682955206515414</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>0.09553903345724907]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>percentile</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.078816</td>\n",
       "      <td>[0.05287623474723998</td>\n",
       "      <td>0.088847</td>\n",
       "      <td>0.09472511144130757]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_name breakpoint_threshold_type  \\\n",
       "293             bert-base-uncased                percentile   \n",
       "292             bert-base-uncased                percentile   \n",
       "1155  nasa-impact/nasa-ibm-st.38m                percentile   \n",
       "1154  nasa-impact/nasa-ibm-st.38m                percentile   \n",
       "291             bert-base-uncased                percentile   \n",
       "\n",
       "      breakpoint_threshold_amount  min_chunk_size  average_score  \\\n",
       "293                           7.0             100       0.079138   \n",
       "292                           7.0              50       0.079138   \n",
       "1155                          4.0             100       0.079005   \n",
       "1154                          4.0              50       0.079005   \n",
       "291                           4.0             100       0.078816   \n",
       "\n",
       "                     score0    score1                 score2  \n",
       "293   [0.052663076002393776  0.089494   0.09525631216526396]  \n",
       "292   [0.052663076002393776  0.089494   0.09525631216526396]  \n",
       "1155  [0.054682955206515414  0.086792   0.09553903345724907]  \n",
       "1154  [0.054682955206515414  0.086792   0.09553903345724907]  \n",
       "291    [0.05287623474723998  0.088847   0.09472511144130757]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(\"data/etc/chunker_scores.csv\")\n",
    "results_df = results_df.drop_duplicates()\n",
    "results_df = results_df.sort_values(by=[\"average_score\"], ascending=False)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d42bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dec17317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 445\n"
     ]
    }
   ],
   "source": [
    "from semantic_text_splitter import TextSplitter\n",
    "\n",
    "# splitter = TextSplitter(capacity=1000, overlap=200)\n",
    "splitter = TextSplitter((300, 1200), overlap=0)\n",
    "chunks = splitter.chunks(sample_df.iloc[0]['body'])\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26768e6",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The semantic chunker never exceeded 0.08 average boundary similarity. Perhaps we can do better by relying on the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3dd4c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reference lengths: 294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([176.,  99.,  13.,   2.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          1.]),\n",
       " array([  106.  ,  1027.65,  1949.3 ,  2870.95,  3792.6 ,  4714.25,\n",
       "         5635.9 ,  6557.55,  7479.2 ,  8400.85,  9322.5 , 10244.15,\n",
       "        11165.8 , 12087.45, 13009.1 , 13930.75, 14852.4 , 15774.05,\n",
       "        16695.7 , 17617.35, 18539.  , 19460.65, 20382.3 , 21303.95,\n",
       "        22225.6 , 23147.25, 24068.9 , 24990.55, 25912.2 , 26833.85,\n",
       "        27755.5 , 28677.15, 29598.8 , 30520.45, 31442.1 , 32363.75,\n",
       "        33285.4 , 34207.05, 35128.7 , 36050.35, 36972.  , 37893.65,\n",
       "        38815.3 , 39736.95, 40658.6 , 41580.25, 42501.9 , 43423.55,\n",
       "        44345.2 , 45266.85, 46188.5 , 47110.15, 48031.8 , 48953.45,\n",
       "        49875.1 , 50796.75, 51718.4 , 52640.05, 53561.7 , 54483.35,\n",
       "        55405.  , 56326.65, 57248.3 , 58169.95, 59091.6 , 60013.25,\n",
       "        60934.9 , 61856.55, 62778.2 , 63699.85, 64621.5 , 65543.15,\n",
       "        66464.8 , 67386.45, 68308.1 , 69229.75, 70151.4 , 71073.05,\n",
       "        71994.7 , 72916.35, 73838.  , 74759.65, 75681.3 , 76602.95,\n",
       "        77524.6 , 78446.25, 79367.9 , 80289.55, 81211.2 , 82132.85,\n",
       "        83054.5 , 83976.15, 84897.8 , 85819.45, 86741.1 , 87662.75,\n",
       "        88584.4 , 89506.05, 90427.7 , 91349.35, 92271.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_reference_lengths = [length for length_list in reference_lengths for length in length_list]\n",
    "print(f\"Total reference lengths: {len(all_reference_lengths)}\")\n",
    "np.mean(all_reference_lengths), np.std(all_reference_lengths)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(all_reference_lengths, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b726e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_lengths[2][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5338faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[85140, 86232]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_indices[0][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc67e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
