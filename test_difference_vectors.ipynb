{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ca4f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ca1b8",
   "metadata": {},
   "source": [
    "Set up embedder and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4337568f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedder created: Qwen/Qwen3-Embedding-0.6B, device=mps, normalize=True, for_queries=True, dim=1024\n",
      "Collections:\n",
      " - astrobert_chunks: 460801 entities\n",
      " - astrobert_contributions: 89860 entities\n",
      " - bge_chunks: 460801 entities\n",
      " - bge_contributions: 89860 entities\n",
      " - nasa_chunks: 460801 entities\n",
      " - nasa_contributions: 89860 entities\n",
      " - qwen06_chunks: 460801 entities\n",
      " - qwen8b_contributions: 89860 entities\n",
      " - specter_chunks: 460801 entities\n",
      " - specter_contributions: 89860 entities\n"
     ]
    }
   ],
   "source": [
    "from embedders import Embedder\n",
    "from database.milvusdb import MilvusDB\n",
    "\n",
    "embedder = Embedder.create(model_name=\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True, for_queries=True)\n",
    "print(f\"Embedder created: {embedder}\")\n",
    "\n",
    "db = MilvusDB()\n",
    "db.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a80093",
   "metadata": {},
   "source": [
    "Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "752bde34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Number of samples after denormalization: 1265\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>target_doi</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>resolved_bibcodes</th>\n",
       "      <th>sent_cit_masked</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1146/annurev-astro-082812-141031</td>\n",
       "      <td>Indeed, Valenti et al. (2009) have argued that...</td>\n",
       "      <td>Indeed,  have argued that SNe Iax are actually...</td>\n",
       "      <td>595</td>\n",
       "      <td>10.1038/nature08023</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[2009Natur.459..674V]</td>\n",
       "      <td>Indeed, [REF] have argued that SNe Iax are act...</td>\n",
       "      <td>[-0.00657158, -0.029778033, -0.007904966, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1007/s00159-011-0047-3</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>1029</td>\n",
       "      <td>10.1051/0004-6361/200911982</td>\n",
       "      <td>20111101</td>\n",
       "      <td>[2009A&amp;A...507...61S, 2009A&amp;A...507...71G]</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>[0.036888514, -0.0060488163, -0.009207417, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1007/s00159-011-0047-3</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>1029</td>\n",
       "      <td>10.1051/0004-6361/200811254</td>\n",
       "      <td>20111101</td>\n",
       "      <td>[2009A&amp;A...507...61S, 2009A&amp;A...507...71G]</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>[0.036888514, -0.0060488163, -0.009207417, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1146/annurev-astro-081811-125615</td>\n",
       "      <td>Madau et al. (1996 , 1998b ) and Lilly et al. ...</td>\n",
       "      <td>and  developed a different method where data ...</td>\n",
       "      <td>904</td>\n",
       "      <td>10.1093/mnras/283.4.1388</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...</td>\n",
       "      <td>[REF] and [REF] developed a different method w...</td>\n",
       "      <td>[-0.0115360785, -0.003134946, -0.008171569, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1146/annurev-astro-081811-125615</td>\n",
       "      <td>Madau et al. (1996 , 1998b ) and Lilly et al. ...</td>\n",
       "      <td>and  developed a different method where data ...</td>\n",
       "      <td>904</td>\n",
       "      <td>10.1086/305523</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...</td>\n",
       "      <td>[REF] and [REF] developed a different method w...</td>\n",
       "      <td>[-0.0115360785, -0.003134946, -0.008171569, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            source_doi  \\\n",
       "0  10.1146/annurev-astro-082812-141031   \n",
       "1            10.1007/s00159-011-0047-3   \n",
       "2            10.1007/s00159-011-0047-3   \n",
       "3  10.1146/annurev-astro-081811-125615   \n",
       "4  10.1146/annurev-astro-081811-125615   \n",
       "\n",
       "                                       sent_original  \\\n",
       "0  Indeed, Valenti et al. (2009) have argued that...   \n",
       "1  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "2  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "3  Madau et al. (1996 , 1998b ) and Lilly et al. ...   \n",
       "4  Madau et al. (1996 , 1998b ) and Lilly et al. ...   \n",
       "\n",
       "                                         sent_no_cit  sent_idx  \\\n",
       "0  Indeed,  have argued that SNe Iax are actually...       595   \n",
       "1  Using a dedicated VLT/ISAAC multi-epoch SN sur...      1029   \n",
       "2  Using a dedicated VLT/ISAAC multi-epoch SN sur...      1029   \n",
       "3   and  developed a different method where data ...       904   \n",
       "4   and  developed a different method where data ...       904   \n",
       "\n",
       "                    target_doi   pubdate  \\\n",
       "0          10.1038/nature08023  20140801   \n",
       "1  10.1051/0004-6361/200911982  20111101   \n",
       "2  10.1051/0004-6361/200811254  20111101   \n",
       "3     10.1093/mnras/283.4.1388  20140801   \n",
       "4               10.1086/305523  20140801   \n",
       "\n",
       "                                   resolved_bibcodes  \\\n",
       "0                              [2009Natur.459..674V]   \n",
       "1         [2009A&A...507...61S, 2009A&A...507...71G]   \n",
       "2         [2009A&A...507...61S, 2009A&A...507...71G]   \n",
       "3  [1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...   \n",
       "4  [1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...   \n",
       "\n",
       "                                     sent_cit_masked  \\\n",
       "0  Indeed, [REF] have argued that SNe Iax are act...   \n",
       "1  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "2  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "3  [REF] and [REF] developed a different method w...   \n",
       "4  [REF] and [REF] developed a different method w...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.00657158, -0.029778033, -0.007904966, 0.03...  \n",
       "1  [0.036888514, -0.0060488163, -0.009207417, 0.0...  \n",
       "2  [0.036888514, -0.0060488163, -0.009207417, 0.0...  \n",
       "3  [-0.0115360785, -0.003134946, -0.008171569, 0....  \n",
       "4  [-0.0115360785, -0.003134946, -0.008171569, 0....  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = pd.read_json(\"data/dataset/nontrivial_checked.jsonl\", lines=True)\n",
    "examples = examples.sample(n=1000, random_state=43)\n",
    "print(len(examples))\n",
    "\n",
    "# Add vector column to examples\n",
    "examples[\"vector\"] = examples.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "# Denormalize on citation_dois (targets)\n",
    "examples = examples.explode(\"citation_dois\", ignore_index=True)\n",
    "print(f\"Number of samples after denormalization: {examples.shape[0]}\")\n",
    "examples.rename(columns={\"citation_dois\": \"target_doi\"}, inplace=True)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "311d7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_to_query(example: pd.Series, candidates: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes in an example (with 'vector' column already set), and from the candidates\n",
    "    (returned entities with that doi from the database), returns the vector most similar\n",
    "    to the example's vector.\n",
    "\n",
    "    \"\"\"\n",
    "    # Converts 'vector' column to rows * dim array, holding the candidate vectors\n",
    "    candidate_vectors = np.stack(candidates[\"vector\"])\n",
    "    best_idx = np.argmax(np.dot(candidate_vectors, example[\"vector\"]))\n",
    "    best_vector = candidate_vectors[best_idx]\n",
    "    return best_vector\n",
    "\n",
    "def difference_vector(example: pd.Series, doi: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the difference vector between the example's vector and the most similar vector\n",
    "    from the candidates retrieved by doi\n",
    "\n",
    "    \"\"\"\n",
    "    candidates = db.select_by_doi(doi, collection_name=\"qwen06_chunks\")\n",
    "    most_similar = most_similar_to_query(example, candidates)\n",
    "    # NOTE: be sure to remain consistent that query vector is first, target vector is 2nd in diff\n",
    "    return example[\"vector\"] - most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af3692ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1265/1265 [00:23<00:00, 53.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the sample of difference vectors from query to target\n",
    "target_diff_vectors = np.zeros((len(examples), embedder.dim))\n",
    "for i, row in tqdm(examples.iterrows(), total=examples.shape[0]):\n",
    "    target_diff_vectors[i] = difference_vector(row, doi=row['target_doi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9475f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vector_stats(vectors: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Computes basic statistics for a set of vectors.\n",
    "\n",
    "    Args:\n",
    "        vectors (np.ndarray): An array of shape (n_samples, n_features) containing the vectors.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the mean, std, min, and max for each feature.\n",
    "    \"\"\"\n",
    "    mean_vector = np.mean(vectors, axis=0)\n",
    "    cov_matrix = np.cov(vectors.T)\n",
    "    trace = np.trace(cov_matrix)\n",
    "    stats = {\n",
    "        \"mean_vector\": mean_vector,\n",
    "        \"average_norm\": np.linalg.norm(mean_vector),\n",
    "        \"std\": np.std(vectors, axis=0),\n",
    "        \"trace\": trace\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd973ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target mean_vector: [-0.00266595  0.00085247  0.00141372 ...  0.00421002 -0.00266596\n",
      " -0.00092041]\n",
      "Target average_norm: 0.1226045455638557\n",
      "Target std: [0.03290039 0.02799492 0.00250348 ... 0.02597544 0.02834654 0.02658496]\n",
      "Target trace: 0.7099010683512821\n"
     ]
    }
   ],
   "source": [
    "target_stats = compute_vector_stats(target_diff_vectors)\n",
    "for key, value in target_stats.items():\n",
    "    print(f\"Target {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1a6ec",
   "metadata": {},
   "source": [
    "## Get the sample difference & variation for random difference vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "23a618b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1265/1265 [00:10<00:00, 124.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_diff_vectors = np.zeros((len(examples), embedder.dim))\n",
    "sample_dois = set(examples['target_doi'])\n",
    "for i, example in tqdm(examples.iterrows(), total=examples.shape[0]):\n",
    "    # Get this example's target DOIs and remove from set of choices\n",
    "    example_doi = example['source_doi']\n",
    "    target_dois = set(examples.loc[examples['source_doi'] == example_doi, 'target_doi'])\n",
    "    choice_set = sample_dois - target_dois\n",
    "    random_doi = random.choice(list(choice_set))\n",
    "\n",
    "    random_diff_vectors[i] = difference_vector(example, doi=random_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "431a0908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random mean_vector: [-0.00324973  0.00231311  0.00253555 ...  0.00419267 -0.00098203\n",
      " -0.00374234]\n",
      "Random average_norm: 0.1496816436811038\n",
      "Random std: [0.04481936 0.03786146 0.00318765 ... 0.03365424 0.03345412 0.03632914]\n",
      "Random trace: 1.180025227938104\n"
     ]
    }
   ],
   "source": [
    "random_stats = compute_vector_stats(random_diff_vectors)\n",
    "for key, value in random_stats.items():\n",
    "    print(f\"Random {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "140f7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average difference vector to file\n",
    "\n",
    "np.save(\"qwen06_difference_vector.npy\", target_stats['mean_vector'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602402f0",
   "metadata": {},
   "source": [
    "The trace of random difference vectors' covariance matrix is 1.18, which is about 66% higher than that of the difference vectors between the query and the target. This suggests that there is much less variation in the difference vectors from the query to the target and this is perhaps a stable property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ccbe5",
   "metadata": {},
   "source": [
    "### Get the difference vector from query+add3 to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7d097a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryExpander(name=add_prev_3, data_length=2980)\n"
     ]
    }
   ],
   "source": [
    "from query_expander import get_expander\n",
    "\n",
    "add3 = get_expander(\"add_prev_3\", path_to_data=\"data/preprocessed/reviews.jsonl\")\n",
    "print(add3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "493d908b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jordan et al. (2012) , Kromer et al. (2013) , and Fink et al. (2014) model SNe Iax as “failed deflagrations”—SN Ia explosions in which a transition from deflagration to detonation fails to occur, and furthermore the explosion fails to completely unbind the WD, leaving behind an ∼1M ⊙ bound remnant. This could explain the low 56 Ni yields, the low velocities, the unburnt C and He in the ejecta, the high degree of mixing, and the clumps of high-density material. However, SNe Iax occur predominantly in star-forming galaxies (but there is one case, SN 2008ge, occurring in an S0 galaxy, with no signs of star formation or pre-explosion massive stars at the explosion site; Foley et al. 2010b ), and their locations within these galaxies track the SFR similarly to the common Type IIP CC SNe ( Lyman et al. 2013 ). Indeed,  have argued that SNe Iax are actually CC SNe with low ejecta velocities derived from 7−9M ⊙ or 25−30M ⊙ progenitors, with cores collapsing into black holes.\n"
     ]
    }
   ],
   "source": [
    "expansions = add3(examples)\n",
    "print(expansions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b1836027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1265/1265 [01:20<00:00, 15.68it/s]\n",
      "100%|██████████| 1265/1265 [02:59<00:00,  7.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>target_doi</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>resolved_bibcodes</th>\n",
       "      <th>sent_cit_masked</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1146/annurev-astro-082812-141031</td>\n",
       "      <td>Indeed, Valenti et al. (2009) have argued that...</td>\n",
       "      <td>Jordan et al. (2012) , Kromer et al. (2013) , ...</td>\n",
       "      <td>595</td>\n",
       "      <td>10.1038/nature08023</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[2009Natur.459..674V]</td>\n",
       "      <td>Indeed, [REF] have argued that SNe Iax are act...</td>\n",
       "      <td>[0.020763418, 0.014040946, -0.009526509, 0.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1007/s00159-011-0047-3</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>At even higher cluster redshift z ∼ 1, the Sup...</td>\n",
       "      <td>1029</td>\n",
       "      <td>10.1051/0004-6361/200911982</td>\n",
       "      <td>20111101</td>\n",
       "      <td>[2009A&amp;A...507...61S, 2009A&amp;A...507...71G]</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>[-0.005719765, -0.005792628, -0.012335606, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1007/s00159-011-0047-3</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>At even higher cluster redshift z ∼ 1, the Sup...</td>\n",
       "      <td>1029</td>\n",
       "      <td>10.1051/0004-6361/200811254</td>\n",
       "      <td>20111101</td>\n",
       "      <td>[2009A&amp;A...507...61S, 2009A&amp;A...507...71G]</td>\n",
       "      <td>Using a dedicated VLT/ISAAC multi-epoch SN sur...</td>\n",
       "      <td>[-0.005719765, -0.005792628, -0.012335606, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1146/annurev-astro-081811-125615</td>\n",
       "      <td>Madau et al. (1996 , 1998b ) and Lilly et al. ...</td>\n",
       "      <td>Redshifts z &gt;4 have been confirmed from CO mea...</td>\n",
       "      <td>904</td>\n",
       "      <td>10.1093/mnras/283.4.1388</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...</td>\n",
       "      <td>[REF] and [REF] developed a different method w...</td>\n",
       "      <td>[-0.02094898, -0.0007385412, -0.012135256, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1146/annurev-astro-081811-125615</td>\n",
       "      <td>Madau et al. (1996 , 1998b ) and Lilly et al. ...</td>\n",
       "      <td>Redshifts z &gt;4 have been confirmed from CO mea...</td>\n",
       "      <td>904</td>\n",
       "      <td>10.1086/305523</td>\n",
       "      <td>20140801</td>\n",
       "      <td>[1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...</td>\n",
       "      <td>[REF] and [REF] developed a different method w...</td>\n",
       "      <td>[-0.02094898, -0.0007385412, -0.012135256, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            source_doi  \\\n",
       "0  10.1146/annurev-astro-082812-141031   \n",
       "1            10.1007/s00159-011-0047-3   \n",
       "2            10.1007/s00159-011-0047-3   \n",
       "3  10.1146/annurev-astro-081811-125615   \n",
       "4  10.1146/annurev-astro-081811-125615   \n",
       "\n",
       "                                       sent_original  \\\n",
       "0  Indeed, Valenti et al. (2009) have argued that...   \n",
       "1  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "2  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "3  Madau et al. (1996 , 1998b ) and Lilly et al. ...   \n",
       "4  Madau et al. (1996 , 1998b ) and Lilly et al. ...   \n",
       "\n",
       "                                         sent_no_cit  sent_idx  \\\n",
       "0  Jordan et al. (2012) , Kromer et al. (2013) , ...       595   \n",
       "1  At even higher cluster redshift z ∼ 1, the Sup...      1029   \n",
       "2  At even higher cluster redshift z ∼ 1, the Sup...      1029   \n",
       "3  Redshifts z >4 have been confirmed from CO mea...       904   \n",
       "4  Redshifts z >4 have been confirmed from CO mea...       904   \n",
       "\n",
       "                    target_doi   pubdate  \\\n",
       "0          10.1038/nature08023  20140801   \n",
       "1  10.1051/0004-6361/200911982  20111101   \n",
       "2  10.1051/0004-6361/200811254  20111101   \n",
       "3     10.1093/mnras/283.4.1388  20140801   \n",
       "4               10.1086/305523  20140801   \n",
       "\n",
       "                                   resolved_bibcodes  \\\n",
       "0                              [2009Natur.459..674V]   \n",
       "1         [2009A&A...507...61S, 2009A&A...507...71G]   \n",
       "2         [2009A&A...507...61S, 2009A&A...507...71G]   \n",
       "3  [1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...   \n",
       "4  [1996MNRAS.283.1388M, 1998ApJ...498..106M, 199...   \n",
       "\n",
       "                                     sent_cit_masked  \\\n",
       "0  Indeed, [REF] have argued that SNe Iax are act...   \n",
       "1  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "2  Using a dedicated VLT/ISAAC multi-epoch SN sur...   \n",
       "3  [REF] and [REF] developed a different method w...   \n",
       "4  [REF] and [REF] developed a different method w...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.020763418, 0.014040946, -0.009526509, 0.012...  \n",
       "1  [-0.005719765, -0.005792628, -0.012335606, 0.0...  \n",
       "2  [-0.005719765, -0.005792628, -0.012335606, 0.0...  \n",
       "3  [-0.02094898, -0.0007385412, -0.012135256, 0.0...  \n",
       "4  [-0.02094898, -0.0007385412, -0.012135256, 0.0...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the df with sent_no_cit replaced by the expansion, and its embedding\n",
    "expansion_df = examples.copy()\n",
    "expansion_df['sent_no_cit'] = expansions\n",
    "expansion_df[\"vector\"] = expansion_df.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "expansion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20316af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1265/1265 [00:09<00:00, 132.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the sample of difference vectors from query to target\n",
    "expansion_diff_vectors = np.zeros((len(expansion_df), embedder.dim))\n",
    "for i, row in tqdm(expansion_df.iterrows(), total=expansion_df.shape[0]):\n",
    "    expansion_diff_vectors[i] = difference_vector(row, doi=row[\"target_doi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7c0df53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expansion mean_vector: [-0.00333019  0.00222054  0.00044202 ... -0.00071515 -0.00295082\n",
      " -0.00144575]\n",
      "Expansion average_norm: 0.09883509631172925\n",
      "Expansion std: [0.03148758 0.02819422 0.0024491  ... 0.02678819 0.02768929 0.02722017]\n",
      "Expansion trace: 0.6747653393168445\n"
     ]
    }
   ],
   "source": [
    "expansion_stats = compute_vector_stats(expansion_diff_vectors)\n",
    "for key, value in expansion_stats.items():\n",
    "    print(f\"Expansion {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e86b09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('expansion_diff_vector.npy', expansion_stats['mean_vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526f7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
