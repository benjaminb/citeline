{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAAI/bge-small-en, device=mps, normalize=True\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "from Embedders import SentenceTransformerEmbedder, EncoderEmbedder\n",
    "embedder = SentenceTransformerEmbedder(model_name='BAAI/bge-small-en', device='mps', normalize=True)\n",
    "print(embedder)\n",
    "print(embedder.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================CONFIG=================================\n",
      "Database         User             Host                             Port            \n",
      "citeline_db      bbasseri         localhost                        5432            \n",
      "========================================================================\n",
      "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from database.database import DatabaseProcessor\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# Database setup\n",
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT')\n",
    "}\n",
    "db = DatabaseProcessor(db_params)\n",
    "db.test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n",
      "{'dbname': 'test', 'user': 'bbasseri', 'password': 'citeline25', 'host': 'localhost', 'port': '5432'}\n"
     ]
    }
   ],
   "source": [
    "from database.database import DatabaseProcessor\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT'),\n",
    "}\n",
    "db = DatabaseProcessor(db_params)\n",
    "\n",
    "db.test_connection()\n",
    "print(db.db_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68dc6eba5fe495b962335b404f2499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 took 9.85 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b4e9f18bfc4856927e144cd812954e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 took 9.30 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867a64d02cfc4e9ea257f4f455fe2815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 took 8.97 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558cc4402804a05bebe7225b4cee243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 took 9.12 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5230489f91e4cd3a4d70c431ab16043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 took 9.56 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bfb4d3b7eb4e93b053bc163cb872f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 took 9.35 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bae4561b69f43d39724940e503f0476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 took 9.61 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d3a6ade4b342dfb3035470979caf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 took 10.10 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cf4d68565c43fcb5ac4833e07914ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9 took 9.77 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d17bdb74d144d6e9bc1cf61ff85c703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 took 10.63 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b2ae6af51f470da65c9ec11f6aa0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11 took 10.73 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810ccc47edf0403c8acd4f2ac0a3f628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 took 10.16 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f179c953d554a65a95b9695924d8c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13 took 10.15 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7ff9ce6dad418a832ce8afaa5d23f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14 took 10.35 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae71b9748d3499089d7368ba337a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15 took 10.48 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c34ad9c14a4e8784f46f45c6303570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 took 10.56 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35034f4901774035b2d7ac11583f221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17 took 10.63 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf96e482f294b81a940478be9d5e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18 took 10.84 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f5ea93c71240fa8754a8ea77dce3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19 took 9.95 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a41361bfda4c4dacf128b9e7df536c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 took 10.08 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1621953bfc479195a2f4b30256ad9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21 took 9.87 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63997ca7454fff88e976459f9371cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22 took 9.94 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aad63fe79ec40b1977331cecea1bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23 took 10.23 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef575c258b8148919b4b63d2e6c71ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24 took 9.93 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a212a521b3da4367995c15c2ca53a8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25 took 9.71 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4da9131a844ea0902d4b9c9526e1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26 took 9.12 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e787f2cedb40e5b5282e13ed1e9384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 27 took 9.11 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7c9108006c4cd9a25b83f2bbe2f18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 28 took 9.05 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4191812e908e4831902ce6c0946356a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 29 took 8.96 seconds. Shape: (1024, 384)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4528490dd6fc4c83bd636013d84f7279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 30 took 9.14 seconds. Shape: (1024, 384)\n",
      "Average time: 9.84 seconds\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from time import time\n",
    "conn = psycopg2.connect(**db.db_params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT text FROM chunks;')\n",
    "embedding_times = []\n",
    "for i in range(30):\n",
    "    rows = [row[0] for row in cursor.fetchmany(1024)]\n",
    "    start = time()\n",
    "    embeddings = embedder(rows)\n",
    "    end = time()\n",
    "    embedding_times.append(end - start)\n",
    "    print(f'Batch {i+1} took {end - start:.2f} seconds. Shape: {embeddings.shape}')\n",
    "\n",
    "print(f'Average time: {sum(embedding_times) / len(embedding_times):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1 chunks\n",
      "Result shape: (1, 768)\n",
      "Batch size 1 took 0.3265950679779053 seconds (0.3265950679779053 per chunk)\n",
      "Got 2 chunks\n",
      "Result shape: (2, 768)\n",
      "Batch size 2 took 0.14107275009155273 seconds (0.07053637504577637 per chunk)\n",
      "Got 4 chunks\n",
      "Result shape: (4, 768)\n",
      "Batch size 4 took 0.2704019546508789 seconds (0.06760048866271973 per chunk)\n",
      "Got 8 chunks\n",
      "Result shape: (8, 768)\n",
      "Batch size 8 took 0.2607390880584717 seconds (0.03259238600730896 per chunk)\n",
      "Got 16 chunks\n",
      "Result shape: (16, 768)\n",
      "Batch size 16 took 0.2776329517364502 seconds (0.017352059483528137 per chunk)\n",
      "Got 32 chunks\n",
      "Result shape: (32, 768)\n",
      "Batch size 32 took 0.5046610832214355 seconds (0.01577065885066986 per chunk)\n",
      "Got 64 chunks\n",
      "Result shape: (64, 768)\n",
      "Batch size 64 took 7.010876893997192 seconds (0.10954495146870613 per chunk)\n",
      "Got 128 chunks\n",
      "Result shape: (128, 768)\n",
      "Batch size 128 took 22.09320330619812 seconds (0.1726031508296728 per chunk)\n",
      "Got 256 chunks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Embed the chunks\u001b[39;00m\n\u001b[1;32m     19\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m---> 20\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m duration \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox/Studies/StellarDNN/citeline/Embedders.py:67\u001b[0m, in \u001b[0;36mEncoderEmbedder.__call__\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length\n\u001b[1;32m     66\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 67\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniforge3/envs/citeline/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    438\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    450\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from time import time\n",
    "\n",
    "averages = []\n",
    "batch_size = 1\n",
    "while batch_size < 2_500_000:\n",
    "    try:\n",
    "        # Get chunks from the database\n",
    "        conn = psycopg2.connect(**db.db_params)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\n",
    "            f\"SELECT text FROM chunks LIMIT {batch_size}\")\n",
    "        rows = cursor.fetchall()\n",
    "        conn.close()\n",
    "        chunks = [row[0] for row in rows]\n",
    "        print(f\"Got {len(chunks)} chunks\")\n",
    "\n",
    "        # Embed the chunks\n",
    "        start = time()\n",
    "        result = embedder(chunks)\n",
    "        duration = time() - start\n",
    "        print(f\"Result shape: {result.shape}\")\n",
    "        averages.append(duration/batch_size)\n",
    "        print(f\"Batch size {batch_size} took {duration} seconds ({duration/batch_size} per chunk)\")\n",
    "        batch_size *= 2\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.query_vector_table('bge', query_vector=embeddings[0], metric='vector_cosine_ops', top_k=5)\n",
    "for result in results:\n",
    "    print(result.similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_results = db.query_vector_table('bge', query_vector=embeddings[0], metric='vector_ip_ops', top_k=5)\n",
    "for result in ip_results:\n",
    "    print(result.similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import random\n",
    "\n",
    "plt.figure()\n",
    "x = [random() for _ in range(100)]\n",
    "y = [-x_i for x_i in x]\n",
    "plt.plot(x, y, marker='o', label='Average Score')\n",
    "plt.xlabel('Distance (n = 123)')\n",
    "plt.grid(True)\n",
    "plt.text(0.95, 0.05, \"n = 123\", horizontalalignment='right', verticalalignment='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
