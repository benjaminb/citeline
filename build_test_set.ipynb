{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PATH_TO_DATA = 'data/processed_for_chroma/reviews'\n",
    "# FILENAMES = os.listdir(PATH_TO_DATA)\n",
    "# review_data = dict()\n",
    "\n",
    "# for filename in FILENAMES:\n",
    "#     with open(f'{PATH_TO_DATA}/{filename}', 'r') as file:\n",
    "#         review_data[os.path.splitext(os.path.basename(filename))[0]] = json.load(file)\n",
    "\n",
    "# # This one is missing the doi key\n",
    "# del review_data['Earth_Science_Reviews']['metadatas'][292]\n",
    "# del review_data['Earth_Science_Reviews']['documents'][292]\n",
    "# del review_data['Earth_Science_Reviews']['ids'][292]\n",
    "\n",
    "# # postprocessing\n",
    "# for journal in review_data:\n",
    "#     for i, d in enumerate(review_data[journal]['metadatas']):\n",
    "#         # Convert stringified list to list\n",
    "#         d['reference'] = json.loads(d['reference'])\n",
    "#         d['doi'] = json.loads(d['doi'])\n",
    "\n",
    "# print(review_data.keys())\n",
    "# print(f\"Journal keys: {review_data['Astro_Reviews'].keys()}\")\n",
    "# paper = review_data['Astro_Reviews']['metadatas'][0]\n",
    "# print(paper.keys())\n",
    "# print(paper['doi'])\n",
    "# print(type(paper['doi']))\n",
    "# print(paper['reference'][:3])\n",
    "# all_reviews = [\n",
    "#     record for journal in review_data for record in review_data[journal]['metadatas']]\n",
    "# print(len(all_reviews))\n",
    "# print(all_reviews[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/json/Astro_Reviews.json: 996/1000 have all required keys\n",
      "dict_keys(['bibcode', 'abstract', 'aff', 'author', 'bibstem', 'doctype', 'doi', 'id', 'keyword', 'pubdate', 'title', 'read_count', 'reference', 'citation_count', 'citation', 'body'])\n",
      "data/json/Astro_Research.json: 981/1000 have all required keys\n"
     ]
    }
   ],
   "source": [
    "from utils import load_dataset\n",
    "\n",
    "PATH_TO_DATA = 'data/json/Astro_Reviews.json'\n",
    "astro_reviews = load_dataset(PATH_TO_DATA)\n",
    "print(astro_reviews[0].keys())\n",
    "\n",
    "astro_research = load_dataset('data/json/Astro_Research.json')\n",
    "\n",
    "all_records = astro_reviews + astro_research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_TO_DATA = 'data/processed_for_chroma/research'\n",
    "# FILENAMES = os.listdir(PATH_TO_DATA)\n",
    "# research_data = dict()\n",
    "\n",
    "# for filename in FILENAMES:\n",
    "#     with open(f'{PATH_TO_DATA}/{filename}', 'r') as file:\n",
    "#         research_data[os.path.splitext(os.path.basename(filename))[\n",
    "#             0]] = json.load(file)\n",
    "\n",
    "\n",
    "# # postprocessing\n",
    "# for journal in research_data:\n",
    "#     for i, d in enumerate(research_data[journal]['metadatas']):\n",
    "#         if not 'doi' in d:\n",
    "#             del research_data[journal]['metadatas'][i]\n",
    "#             del research_data[journal]['documents'][i]\n",
    "#             del research_data[journal]['ids'][i]\n",
    "\n",
    "# for journal in research_data:\n",
    "#     for d in research_data[journal]['metadatas']:\n",
    "\n",
    "#         # Convert stringified list to list\n",
    "#         d['reference'] = json.loads(d['reference'])\n",
    "#         d['doi'] = json.loads(d['doi'])\n",
    "\n",
    "# print(research_data.keys())\n",
    "# research_data['Astro_Research'].keys()\n",
    "\n",
    "# all_data = all_reviews + \\\n",
    "#     [record for journal in review_data for record in review_data[journal]['metadatas']]\n",
    "# print(f\"All data: {len(all_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [<re.Match object; span=(1, 23), match='Delbouille et al. 1981'>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Define bibcode and citation patterns\n",
    "lastname = r\"[A-Z][a-zA-ZÀ-ÖØ-öø-ÿ-]*(?:'[A-Z][a-zA-ZÀ-ÖØ-öø-ÿ-]*)?\"\n",
    "year = r\"\\(?(\\d{4}[a-z]?)\\)?\"\n",
    "name_sep = r\",?\\s\"\n",
    "INLINE_CITATION_PATTERN = fr\"({lastname}(?:{name_sep}{lastname})*(?: et al.?)?)\\s*{year}\"\n",
    "\n",
    "# Compile the regex pattern\n",
    "inline_regex = re.compile(INLINE_CITATION_PATTERN)\n",
    "\n",
    "test = \" Delbouille et al. 1981 the future (Section 5). 2. INGREDIENTS FOR SOLAR ABUNDANCE ANALYSIS 2.1. Observations Analyses of th\"\n",
    "\n",
    "# Find all matches using the compiled pattern\n",
    "matches = inline_regex.finditer(test)\n",
    "results = [match for match in matches]\n",
    "print(f\"Results: {results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to resolve incline citation to bibcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each result, get the first letter of the first author's last name\n",
    "# get the year\n",
    "def bibcode_regex(author: str, year: str):\n",
    "    \"\"\"\n",
    "    Given first author and year, return a regex pattern for the\n",
    "    corresponding bibcode\n",
    "    \"\"\"\n",
    "    initial = author[0]\n",
    "    year = year[:4] # cut off any letters at the end\n",
    "    pattern = fr'^{year}.*{initial}$'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "def bibcode_matches(inline_citation: tuple[str, str], references: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Given an inline citation and a list of references, return the number of\n",
    "    references that match the inline citation's bibcode regex pattern\n",
    "    \"\"\"\n",
    "    pattern = bibcode_regex(*inline_citation)\n",
    "    return [s for s in references if pattern.match(s)]\n",
    "\n",
    "# def make_citation_bibcode_list(inline_citations: list[tuple[str, str]], references: list[str]) -> list[tuple[tuple[str, str], str]]:\n",
    "#     \"\"\"\n",
    "#     Given a paper's list of inline citations and list of references, return a list of\n",
    "#     tuples where the first element is the inline citation and the second element\n",
    "#     is the corresponding bibcode from the references list where there is exactly one match\n",
    "#     \"\"\"\n",
    "#     return [(citation, matches[0]) for citation in inline_citations \n",
    "#             if len((matches := bibcode_matches(citation, references))) == 1]\n",
    "\n",
    "# usable_citations = make_citation_bibcode_list(inline_citations, paper['reference'])\n",
    "# print(f\"Results: {len(usable_citations)}\")\n",
    "# print(usable_citations[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysbd\n",
    "\n",
    "def get_inline_citations(text: str) -> list[tuple[str, str]]:\n",
    "    return [match.groups() for match in inline_regex.finditer(text)]\n",
    "\n",
    "def sentence_to_example(record, sentence, all_records):\n",
    "    \"\"\"\n",
    "    Takes all the inline citations of a sentence and if it can resolve them to dois\n",
    "    then it returns the \"\"\"\n",
    "    def citation_to_doi(citation):\n",
    "        \"\"\"\n",
    "        Takes a single inline citation as tuple of (author, year) and determines if there is a unique\n",
    "        matching bibcode in the record's references. If so, it continues to look for a unique\n",
    "        doi matching that bibcode in the entire dataset. It returns the doi if resolved, otherwise None.\n",
    "        \"\"\"\n",
    "        bibcodes = bibcode_matches(citation, record['reference'])\n",
    "        if len(bibcodes) != 1:\n",
    "            return None\n",
    "        \n",
    "        matching_dois = [record['doi'][0]\n",
    "                         for record in all_records if record['bibcode'] == bibcodes[0]]\n",
    "        if len(matching_dois) != 1:\n",
    "            return None\n",
    "        return matching_dois[0]\n",
    "    \n",
    "    inline_citations = get_inline_citations(sentence)\n",
    "    citation_dois = []\n",
    "    for citation in inline_citations:\n",
    "        if not (doi := citation_to_doi(citation)):\n",
    "            break\n",
    "        citation_dois.append(doi)\n",
    "\n",
    "    # If all citations resolved to dois, return the example\n",
    "    if len(inline_citations) != len(citation_dois):\n",
    "        return None\n",
    "    return {\n",
    "            'source_doi': record['doi'][0],\n",
    "            'sentence': sentence,\n",
    "            'citation_dois': citation_dois\n",
    "           }\n",
    "\n",
    "\n",
    "def create_examples_from_record(record):\n",
    "    splitter = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = [s for s in splitter.segment(record['body']) if len(s) > 40]\n",
    "    return [\n",
    "        example for sentence in sentences if (example := sentence_to_example(record, sentence))\n",
    "    ]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_salvageable_bibcodes(record, sentence, all_bibcodes):\n",
    "    \"\"\"\n",
    "    Similar logic to sentence_to_example, except this function, when it finds an inline citation\n",
    "    that resolves to a single bibcode in a record/sentence, but it CANNOT find the corresponding\n",
    "    doi in the entire dataset (i.e. the bibcode is not in the dataset), it returns the bibcode\n",
    "    \"\"\"\n",
    "    def citation_to_missing_bibcode(citation):\n",
    "        \"\"\"\n",
    "        Takes a single inline citation as tuple of (author, year) and determines if there is a unique\n",
    "        matching bibcode in the record's references. If so, it continues to look for a unique\n",
    "        doi matching that bibcode in the entire dataset. It returns the doi if resolved, otherwise None.\n",
    "        \"\"\"\n",
    "        bibcodes = bibcode_matches(citation, record['reference'])\n",
    "        if len(bibcodes) != 1:\n",
    "            return None\n",
    "        \n",
    "        bibcode = bibcodes[0]\n",
    "        \n",
    "        # The inline citation corresponds to a unique bibcode, but that bibcode is not in the dataset\n",
    "        if bibcode not in all_bibcodes:\n",
    "            return bibcode\n",
    "        \n",
    "        matching_dois = [record['doi'][0]\n",
    "                         for record in all_records if record['bibcode'] == bibcode]\n",
    "        if len(matching_dois) != 1:\n",
    "            return None\n",
    "        return matching_dois[0]\n",
    "\n",
    "    inline_citations = get_inline_citations(sentence)\n",
    "    return [bibcode for citation in inline_citations if (bibcode := citation_to_missing_bibcode(citation))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bibcodes = [record['bibcode'] for record in all_records]\n",
    "len(all_bibcodes) == len(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [1:06:51<00:00,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvageable bibcodes: 46333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pysbd\n",
    "\n",
    "salvageable_bibcodes = set()\n",
    "splitter = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "for record in tqdm(astro_reviews):\n",
    "    sentences = [s for s in splitter.segment(record['body']) if len(s) > 40]\n",
    "    for sentence in sentences:\n",
    "        salvageable_bibcodes.update(find_salvageable_bibcodes(record, sentence, all_bibcodes))\n",
    "\n",
    "print(f\"Salvageable bibcodes: {len(salvageable_bibcodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/json/Earth_Science_Reviews.json: 994/1000 have all required keys\n",
      "data/json/Earth_Science_Research.json: 1000/1000 have all required keys\n",
      "data/json/Planetary_Reviews.json: 994/1000 have all required keys\n",
      "data/json/Planetary_Research.json: 964/1000 have all required keys\n"
     ]
    }
   ],
   "source": [
    "earth_reviews = load_dataset('data/json/Earth_Science_Reviews.json')\n",
    "earth_research = load_dataset('data/json/Earth_Science_Research.json')\n",
    "planet_reviews = load_dataset('data/json/Planetary_Reviews.json')\n",
    "planet_research = load_dataset('data/json/Planetary_Research.json')\n",
    "\n",
    "all_records = astro_reviews + astro_research + earth_reviews + earth_research + planet_reviews + planet_research\n",
    "all_bibcodes = [record['bibcode'] for record in all_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1988/1988 [2:44:51<00:00,  4.98s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvageable bibcodes: 74365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for record in tqdm(earth_reviews + planet_reviews):\n",
    "    sentences = [s for s in splitter.segment(record['body']) if len(s) > 40]\n",
    "    for sentence in sentences:\n",
    "        salvageable_bibcodes.update(find_salvageable_bibcodes(record, sentence, all_bibcodes))\n",
    "\n",
    "print(f\"Salvageable bibcodes: {len(salvageable_bibcodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/salvageable_bibcodes.txt', 'w') as file:\n",
    "    for bibcode in salvageable_bibcodes:\n",
    "        file.write(f\"{bibcode}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test_set.jsonl', 'a') as file:\n",
    "    for journal in review_data:\n",
    "        for record in review_data[journal]['metadatas'][:10]:\n",
    "            examples = create_examples_from_record(record)\n",
    "            for example in examples:\n",
    "                json.dump(example, file)\n",
    "                file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = []\n",
    "num_examples = []\n",
    "examples_with_empty_labels = []\n",
    "total_examples = 0\n",
    "for i, record in tqdm(enumerate(review_data['Astro_Reviews']['metadatas'][:100])):\n",
    "    splitter = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "    sentences = [s for s in splitter.segment(record['body']) if len(s) > 40]\n",
    "    num_sentences.append(len(sentences))\n",
    "    examples = [example for sentence in sentences if (example := sentence_to_example(record, sentence))]\n",
    "    num_examples.append(len(examples))\n",
    "    examples_with_empty_labels.append(len([e for e in examples if e['citation_dois'] == []]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of examples: {sum(num_examples)}\")\n",
    "print(f\"Total number of examples with no citations: {sum(examples_with_empty_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1929ApJ....70...11R',\n",
       " '1956RvMP...28...53S',\n",
       " '1958ZA.....46..108B',\n",
       " '1960ApJS....5....1G',\n",
       " '1962ApJ...136..906V',\n",
       " '1967ZA.....65..365H',\n",
       " '1968ZPhy..211..404D',\n",
       " '1969ApL.....4..143H',\n",
       " '1972ApJ...175L..95H',\n",
       " '1972SoPh...26..250L',\n",
       " '1973apds.book.....D',\n",
       " '1974SoPh...39...19H',\n",
       " '1975A&A....42...37C',\n",
       " '1975SoPh...41...53M',\n",
       " '1976ApJS...30....1V',\n",
       " '1976Sci...191.1223R',\n",
       " '1978MNRAS.182..249L',\n",
       " '1978MNRAS.183...79L',\n",
       " '1982A&A...107....1N',\n",
       " '1982SoPh...81....3H',\n",
       " '1984A&A...141...10G',\n",
       " '1984ApJ...282..330S',\n",
       " '1984SoPh...90..205N',\n",
       " '1984sfat.book.....K',\n",
       " '1986A&A...164..395Y',\n",
       " '1988A&A...203..378Y',\n",
       " '1988ApJ...331..815M',\n",
       " '1989GeCoA..53..197A',\n",
       " '1989hra2.book.....F',\n",
       " '1990A&A...232..225G',\n",
       " '1990A&A...239..367Y',\n",
       " '1991A&A...242..488G',\n",
       " '1992A&A...259..301H',\n",
       " '1992RMxAA..23...45K',\n",
       " '1993A&A...275..101E',\n",
       " '1993A&A...275..269K',\n",
       " '1993ASPC...44..496C',\n",
       " '1993oee..conf...15G',\n",
       " '1994RSPTA.349..213G',\n",
       " '1994SoPh..153...91N',\n",
       " '1995A&A...296..217B',\n",
       " '1995A&A...296..233H',\n",
       " '1995MNRAS.276..859A',\n",
       " '1996A&A...311..680K',\n",
       " '1996ApOpt..35.2747A',\n",
       " '1997ApJ...489L.107K',\n",
       " '1997MNRAS.284..202A',\n",
       " '1997nceg.book.....P',\n",
       " '1998A&A...333..219Z',\n",
       " '1998A&A...337..495P',\n",
       " '1998ApJ...499..914S',\n",
       " '1998JPCRD..27.1275R',\n",
       " '1998Natur.392..791B',\n",
       " '1998SSRv...84..251M',\n",
       " '1998SSRv...85..161G',\n",
       " '1999A&A...342..610S',\n",
       " '1999A&A...346L..17A',\n",
       " '1999A&A...347..348G',\n",
       " '1999ApJ...512.1006C',\n",
       " '1999ApJ...525.1032B',\n",
       " '1999MNRAS.303..721B',\n",
       " '1999SSRv...90..413R',\n",
       " '2000A&A...359..669A',\n",
       " '2000A&A...359..729A',\n",
       " '2000A&A...359..743A',\n",
       " '2000A&A...359..755A',\n",
       " '2000A&A...363.1091B',\n",
       " '2000A&A...364..249M',\n",
       " '2000A&AS..142..467B',\n",
       " '2000IAUS..198..224G',\n",
       " '2000MNRAS.311..535B',\n",
       " '2000MNRAS.312..116B',\n",
       " '2001A&A...370..610L',\n",
       " '2001A&A...376..232M',\n",
       " '2001AIPC..598...23H',\n",
       " '2001ApJ...546L..65B',\n",
       " '2001ApJ...553L..77O',\n",
       " '2001ApJ...554L.221S',\n",
       " '2001ApJ...556..452L',\n",
       " '2001ApJ...556L..63A',\n",
       " '2001ApJ...558..830A',\n",
       " '2001ApJ...563.1075L',\n",
       " '2001ApJS..137..341L',\n",
       " '2001KFNT...17...37G',\n",
       " '2002A&A...385..951B',\n",
       " '2002AN....323..213F',\n",
       " '2002ApJ...573L.137A',\n",
       " '2002ApJ...576.1064R',\n",
       " '2002JGRA..107.1442T',\n",
       " '2002RvMG...47...21W',\n",
       " '2003A&A...399L..31A',\n",
       " '2003A&A...407..691K',\n",
       " '2003A&A...409L...1B',\n",
       " '2003ApJ...583.1004B',\n",
       " '2003ApJ...584L.107J',\n",
       " '2003ApJ...591.1220L',\n",
       " '2003ApJS..148..543D',\n",
       " '2003ChJAA...3..316T',\n",
       " '2003MNRAS.339...63C',\n",
       " '2003MNRAS.340..304R',\n",
       " '2003PhRvA..68f2703B',\n",
       " '2003SSRv..107..665F',\n",
       " '2004A&A...413.1045G',\n",
       " '2004A&A...417..751A',\n",
       " '2004A&A...417..769A',\n",
       " '2004A&A...421..741V',\n",
       " '2004A&A...423..683S',\n",
       " '2004A&A...423.1109A',\n",
       " '2004A&ARv..12...71G',\n",
       " '2004ApJ...604..850L',\n",
       " '2004ApJ...605..272S',\n",
       " '2004ApJ...606L..85B',\n",
       " '2004ApJ...615.1042M',\n",
       " '2004ApJ...617.1115D',\n",
       " '2004ESASP.559..574M',\n",
       " '2004MNRAS.350.1127A',\n",
       " '2004MNRAS.355..229E',\n",
       " '2004PhRvL..93u1102T',\n",
       " '2004oee..symp..336J',\n",
       " '2005A&A...431..693A',\n",
       " '2005A&A...433..185B',\n",
       " '2005A&A...435..373B',\n",
       " '2005A&A...439..361Y',\n",
       " '2005A&A...442..643C',\n",
       " '2005A&A...444L..45Y',\n",
       " '2005ARA&A..43..481A',\n",
       " '2005ASPC..336.....B',\n",
       " '2005ApJ...618..908Y',\n",
       " '2005ApJ...618..926S',\n",
       " '2005ApJ...618.1049B',\n",
       " '2005ApJ...618L..95E',\n",
       " '2005ApJ...619..891J',\n",
       " '2005ApJ...620L.129A',\n",
       " '2005ApJ...626..530B',\n",
       " '2005ApJ...627.1049G',\n",
       " '2005ApJ...631.1281B',\n",
       " '2005ApJ...634L.197S',\n",
       " '2005MNRAS.360..458B',\n",
       " '2005Natur.434..619H',\n",
       " '2005Natur.436..525D',\n",
       " '2005PASJ...57..751T',\n",
       " '2005Sci...309.2189C',\n",
       " '2006A&A...448.1207Q',\n",
       " '2006A&A...452..357X',\n",
       " '2006A&A...453..723Z',\n",
       " '2006A&A...456..675S',\n",
       " '2006A&A...456.1181L',\n",
       " '2006A&A...457..651M',\n",
       " '2006A&A...458..899F',\n",
       " '2006ApJ...639..441F',\n",
       " '2006ApJ...639L..39N',\n",
       " '2006ApJ...641..327C',\n",
       " '2006ApJ...646..560T',\n",
       " '2006ApJ...647.1106L',\n",
       " '2006ApJ...649..529D',\n",
       " '2006ApJS..162..227L',\n",
       " '2006ApJS..165..618A',\n",
       " '2006ApJS..167..292D',\n",
       " '2006Natur.440..776I',\n",
       " '2006astro.ph..5029K',\n",
       " '2007A&A...461..261M',\n",
       " '2007A&A...462..781B',\n",
       " '2007A&A...463..755C',\n",
       " '2007A&A...465..271R',\n",
       " '2007A&A...466..327B',\n",
       " '2007A&A...467L..11C',\n",
       " '2007A&A...470..699C',\n",
       " '2007A&A...471..315B',\n",
       " '2007A&A...472L..43B',\n",
       " '2007A&A...473..291B',\n",
       " '2007A&A...473L...9C',\n",
       " '2007ApJ...654..955J',\n",
       " '2007ApJ...656L..33M',\n",
       " '2007ApJ...658L..67Y',\n",
       " '2007ApJ...659..743L',\n",
       " '2007ApJ...667.1267S',\n",
       " '2007ApJ...670..457G',\n",
       " '2007ApJ...670..872C',\n",
       " '2007ApJS..169..120L',\n",
       " '2007SSRv..130..105G',\n",
       " '2007Sci...316.1591G',\n",
       " '2008A&A...480..581A',\n",
       " '2008A&A...481..489Z',\n",
       " '2008A&A...483..591C',\n",
       " '2008A&A...484..841M',\n",
       " '2008A&A...486..303S',\n",
       " '2008A&A...486..951G',\n",
       " '2008A&A...486..995R',\n",
       " '2008A&A...488.1031C',\n",
       " '2008A&A...490..817M',\n",
       " '2008ApJ...674..607L',\n",
       " '2008ApJ...678.1342L',\n",
       " '2008ApJ...680..764K',\n",
       " '2008ApJ...682L..61C',\n",
       " '2008ApJ...684..691R',\n",
       " '2008ApJ...686..731A',\n",
       " '2008ApJ...687..678H',\n",
       " '2008ApJ...688L.103P',\n",
       " '2008ApJS..178...71L',\n",
       " '2008LPI....39.1779H',\n",
       " '2008MNRAS.384..173F',\n",
       " '2008MNRAS.384..370V',\n",
       " '2008PhR...457..217B',\n",
       " '2008PhST..130a4036G',\n",
       " '2008PhST..133a4013B',\n",
       " '2008arXiv0811.2424P',\n",
       " '2009A&A...494..205C',\n",
       " '2009A&A...497..611M',\n",
       " '2009A&A...498..877C',\n",
       " '2009A&A...500.1221F',\n",
       " '2009A&A...501..941H',\n",
       " '2009ApJ...691L.119S',\n",
       " '2009ApJS..182...51L',\n",
       " '2009ApJS..182...80S',\n",
       " '2009CoAst.158..122M',\n",
       " '2009LPI....40.2494M',\n",
       " '2009LRSP....6....2N',\n",
       " '2009LanB...4B..712L',\n",
       " '2009MNRAS.396..203S']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper = astro_reviews[0]\n",
    "paper['body']\n",
    "paper['reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
