{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d241969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae60766b63eb494c919bb6e143559b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter name: [PRX]\n",
      "Active adapters: Stack[[PRX]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/specter2_base\")\n",
    "# Base model\n",
    "model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "adapter_name = model.load_adapter(\"allenai/specter2\", source=\"hf\", set_active=True)\n",
    "model.to(\"mps\")\n",
    "model.eval()\n",
    "print(f\"Adapter name: {adapter_name}\")\n",
    "print(f\"Active adapters: {model.active_adapters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b668b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "papers = [\n",
    "    {\"title\": \"BERT\", \"abstract\": \"We introduce a new language representation model called BERT\"},\n",
    "    {\n",
    "        \"title\": \"Attention is all you need\",\n",
    "        \"abstract\": \" The dominant sequence transduction models are based on complex recurrent or convolutional neural networks\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# concatenate title and abstract\n",
    "text_batch = [d[\"title\"] + tokenizer.sep_token + (d.get(\"abstract\") or \"\") for d in papers]\n",
    "# preprocess the input\n",
    "inputs = tokenizer(\n",
    "    text_batch, padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False, max_length=512\n",
    ")\n",
    "inputs = inputs.to(\"mps\")\n",
    "output = model(**inputs)\n",
    "# take the first token in the batch as the embedding\n",
    "embeddings = output.last_hidden_state[:, 0, :]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c547ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    \"This is a document about the BGE model.\",\n",
    "    \"This document discusses the AstroBERT model.\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(docs, padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False, max_length=512)\n",
    "inputs.to(\"mps\")\n",
    "output = model(**inputs)\n",
    "embeddings = output.last_hidden_state[:, 0, :]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a64f1e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9864641c90a348699278b69114652ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwriting existing adapter '[QRY]'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter name: [QRY]\n",
      "Adapters in use: Stack[[QRY]]\n"
     ]
    }
   ],
   "source": [
    "# Let's try with the ad hoc adapter\n",
    "\n",
    "adapter_name = model.load_adapter(\"allenai/specter2_adhoc_query\", source=\"hf\", set_active=True)\n",
    "model.to(\"mps\")\n",
    "print(f\"Adapter name: {adapter_name}\")\n",
    "print(f\"Adapters in use: {model.active_adapters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac03479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"This is a query\",\n",
    "    \"This is another query\"\n",
    "]\n",
    "inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"pt\", return_token_type_ids=False, max_length=512)\n",
    "inputs.to(\"mps\")\n",
    "output = model(**inputs)\n",
    "embeddings = output.last_hidden_state[:, 0, :]\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aad73f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.817785, 22.941668], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the norm of each vector\n",
    "import numpy as np\n",
    "np.linalg.norm(embeddings.detach().cpu().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc45d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(22.941668)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(embeddings[1].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b28a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999994 1.0000001 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "normed = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "print(np.linalg.norm(normed.detach().cpu().numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbd536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'[QRY]' in model.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "563bfdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(normed.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947c34f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a32e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
