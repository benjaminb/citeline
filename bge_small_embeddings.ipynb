{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with NVIDIA's model\n",
    "\n",
    "A `SentenceTransformer` model instantiated from `NVIDIA-Embed-v2` will return tensors or np arrays but can only take a string input or a list containing a single string. It cannot accept a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a9f4f354284a6f99a3d7749bf53a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 32768, 'do_lower_case': False}) with Transformer model: MistralModel \n",
      "  (1): Pooling({'word_embedding_dimension': 4096, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': True, 'include_prompt': True})\n",
      ")\n",
      "Batch embeddings shape: torch.Size([3, 4096])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model_name = \"BAAI/bge-en-icl\"\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "device = 'mps' # mps was producing a dimension error on batch input to model.encode \n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer(\n",
    "    model_name, trust_remote_code=True, device=device)\n",
    "print(model)\n",
    "\n",
    "# Encoding a list of strings\n",
    "try:\n",
    "    embeddings = model.encode(\n",
    "        sentences, convert_to_tensor=True, normalize_embeddings=False)\n",
    "    print(f\"Batch embeddings shape: {embeddings.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chromadb.api.client.Client object at 0x32bf8aad0>\n",
      "Return object type: <class 'list'>\n",
      "Inner object type: <class 'numpy.ndarray'>\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "client = chromadb.PersistentClient(path='./vector_stores/bge/')\n",
    "print(client)\n",
    "\n",
    "# Set up embedding model\n",
    "class BgeChromaEmbedder(EmbeddingFunction):\n",
    "    def __init__(self, embedding_fn):\n",
    "        self._encode = embedding_fn\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return self._encode(input)\n",
    "\n",
    "embedding_lambda = lambda docs: model.encode(docs, convert_to_numpy=True, normalize_embeddings=False)\n",
    "\n",
    "embedder = BgeChromaEmbedder(embedding_lambda)\n",
    "result = embedder(['hi there', 'hello world'])\n",
    "print(f\"Return object type: {type(result)}\")\n",
    "print(f\"Inner object type: {type(result[0])}\")\n",
    "print(result[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Earth_Science_Research', 'Planetary_Research', 'Astro_Research'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'metadatas', 'ids'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "METRICS = ['l2', 'cosine', 'ip']\n",
    "PATH_TO_DATA = 'data/processed_for_chroma/research'\n",
    "FILENAMES = os.listdir(PATH_TO_DATA)\n",
    "data = dict()\n",
    "\n",
    "for filename in FILENAMES:\n",
    "    with open(f'{PATH_TO_DATA}/{filename}', 'r') as file:\n",
    "        data[os.path.splitext(os.path.basename(filename))[0]] = json.load(file)\n",
    "\n",
    "print(data.keys())\n",
    "data['Astro_Research'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of doc string: 218019\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "doc = data['Astro_Research']['documents'][0]\n",
    "print(f\"Length of doc string: {len(doc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We present a new model for computing the spectral evolution of stellar populations at ages between 1 × 10<SUP>5</SUP> and 2 × 10<SUP>10</SUP> yr at a resolution of 3 Å across the whole wavelength range from 3200 to 9500 Å for a wide range of metallicities. These predictions are based on a newly available library of observed stellar spectra. We also compute the spectral evolution across a larger wavelength range, from 91 Å to 160 μm, at lower resolution. The model incorporates recent progress in stellar evolution theory and an observationally motivated prescription for thermally pulsing stars on the asymptotic giant branch. The latter is supported by observations of surface brightness fluctuations in nearby stellar populations. We show that this model reproduces well the observed optical and near-infrared colour-magnitude diagrams of Galactic star clusters of various ages and metallicities. Stochastic fluctuations in the numbers of stars in different evolutionary phases can account for the full range of observed integrated colours of star clusters in the Magellanic Clouds. The model reproduces in detail typical galaxy spectra from the Early Data Release (EDR) of the Sloan Digital Sky Survey (SDSS). We exemplify how this type of spectral fit can constrain physical parameters such as the star formation history, metallicity and dust content of galaxies. Our model is the first to enable accurate studies of absorption-line strengths in galaxies containing stars over the full range of ages. Using the highest-quality spectra of the SDSS EDR, we show that this model can reproduce simultaneously the observed strengths of those Lick indices that do not depend strongly on element abundance ratios. The interpretation of such indices with our model should be particularly useful for constraining the star formation histories and metallicities of galaxies.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.878101  ,  2.3778255 , -1.4578811 , ..., -3.2767513 ,\n",
       "        -0.22019193,  3.9709563 ], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = data['Astro_Research']['metadatas'][0]['abstract']\n",
    "print(abstract)\n",
    "embedder([abstract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.3989852 , -0.89258695, -1.0513442 , ..., -1.9740007 ,\n",
      "       -0.8036554 ,  2.7621977 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "res = embedder(doc[:50])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All collections have been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Reset collections\n",
    "collections = client.list_collections()\n",
    "\n",
    "# Delete each collection\n",
    "for collection in collections:\n",
    "    client.delete_collection(name=collection.name)\n",
    "\n",
    "print(\"All collections have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "    name='testing-insert',\n",
    "    embedding_function=embedder,\n",
    "    metadata={\"hnsw:space\": 'l2'}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=data['Astro_Research']['documents'][0:1],\n",
    "    metadatas=data['Astro_Research']['metadatas'][0:1],\n",
    "    ids=data['Astro_Research']['ids'][0:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_INCREMENT = 10\n",
    "\n",
    "for metric in METRICS:\n",
    "    clean_model_name = model_name.replace('/', '-')\n",
    "    collection_name = f\"{clean_model_name}_{metric}_no-norm\"\n",
    "    print(f\"Creating collection: {collection_name}...\")\n",
    "\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedder,\n",
    "        metadata={\"hnsw:space\": metric}\n",
    "    )\n",
    "    for journal, records in data.items():\n",
    "        print(f\"  Adding {journal} records...\")\n",
    "\n",
    "        # Add records 10 at a time\n",
    "        for i in range(len(records['documents']) // ADD_INCREMENT):\n",
    "            s = slice(i*ADD_INCREMENT, (i+1)*ADD_INCREMENT, 1)\n",
    "            collection.add(\n",
    "                documents=records['documents'][s],\n",
    "                metadatas=records['metadatas'][s],\n",
    "                ids=records['ids'][s]\n",
    "            )\n",
    "    print(f\"Finished {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dimensionality of the embeddings\n",
    "collection = client.get_collection(name=f\"{model_name}_cosine_no-norm\")\n",
    "chroma_embedding = collection.query(\n",
    "    query_texts=[\"the sun is a star\"],\n",
    "    n_results=1,\n",
    "    include=[\"embeddings\", \"documents\"]\n",
    ")\n",
    "\n",
    "print(type(chroma_embedding['embeddings']))\n",
    "print(type(chroma_embedding['embeddings'][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
