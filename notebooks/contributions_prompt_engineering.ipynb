{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9346f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<citeline.database.milvusdb.MilvusDB object at 0x11e340890>\n",
      "Qwen/Qwen3-Embedding-0.6B, device=mps, normalize=True, dim=1024\n",
      "QueryExpander(name=add_prev_3, data_length=2980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections:\n",
      " - astrobert_chunks: 460801 entities\n",
      " - astrobert_contributions: 89860 entities\n",
      " - bge_chunks: 460801 entities\n",
      " - bge_contributions: 89860 entities\n",
      " - nasa_chunks: 460801 entities\n",
      " - nasa_contributions: 89860 entities\n",
      " - qwen06_chunks: 460801 entities\n",
      " - qwen06_contributions: 89860 entities\n",
      " - qwen06_findings_v2: 4342 entities\n",
      " - qwen06_v3_contributions: 299286 entities\n",
      " - qwen8b_contributions: 89860 entities\n",
      " - specter_chunks: 460801 entities\n",
      " - specter_contributions: 89860 entities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>citation_dois</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>resolved_bibcodes</th>\n",
       "      <th>sent_cit_masked</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1007/s00159-008-0010-0</td>\n",
       "      <td>(Shang et al. 1998), do show unusual, faint fe...</td>\n",
       "      <td>Such events 123 196 R. Sancisi et al. are more...</td>\n",
       "      <td>159</td>\n",
       "      <td>[10.1086/311563]</td>\n",
       "      <td>20080601</td>\n",
       "      <td>[1998ApJ...504L..23S]</td>\n",
       "      <td>([REF]), do show unusual, faint features in th...</td>\n",
       "      <td>[0.019467777, -0.050828665, -0.009596894, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.newar.2004.03.017</td>\n",
       "      <td>Novak et al. (2003) studied the dust emission ...</td>\n",
       "      <td>The radio emission shows that the nonthermal e...</td>\n",
       "      <td>1329</td>\n",
       "      <td>[10.1086/368156]</td>\n",
       "      <td>20040901</td>\n",
       "      <td>[2003ApJ...583L..83N]</td>\n",
       "      <td>[REF] studied the dust emission at 450 μm in t...</td>\n",
       "      <td>[0.0020762016, 0.016566603, -0.0056969826, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1146/annurev-astro-091918-104430</td>\n",
       "      <td>The momentum per unit mass of stars formed del...</td>\n",
       "      <td>There has yet to be a comprehensive numerical ...</td>\n",
       "      <td>542</td>\n",
       "      <td>[10.1086/317785]</td>\n",
       "      <td>20190801</td>\n",
       "      <td>[2000ApJ...545..364M]</td>\n",
       "      <td>The momentum per unit mass of stars formed del...</td>\n",
       "      <td>[0.040522993, -0.03144786, -0.010288201, 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1146/annurev-astro-081309-130834</td>\n",
       "      <td>An example of the latter is the dormant blue s...</td>\n",
       "      <td>Because the observed YMCs will age to become o...</td>\n",
       "      <td>815</td>\n",
       "      <td>[10.48550/arXiv.astro-ph/9701042]</td>\n",
       "      <td>20100901</td>\n",
       "      <td>[1997A&amp;A...328..130P]</td>\n",
       "      <td>An example of the latter is the dormant blue s...</td>\n",
       "      <td>[-0.02477378, -0.02790011, -0.013496099, 0.052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1146/annurev.astro.37.1.127</td>\n",
       "      <td>Kaiser et al (1995) (see also Luppino Kaiser 1...</td>\n",
       "      <td>The anisotropy of the PSF is corrected on the ...</td>\n",
       "      <td>282</td>\n",
       "      <td>[10.1086/176071, 10.1086/303508, 10.1086/306102]</td>\n",
       "      <td>19990101</td>\n",
       "      <td>[1995ApJ...449..460K, 1997ApJ...475...20L, 199...</td>\n",
       "      <td>[REF] (see also [REF] for further developments...</td>\n",
       "      <td>[0.032639474, -0.07257655, -0.009156834, 0.008...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            source_doi  \\\n",
       "0            10.1007/s00159-008-0010-0   \n",
       "1          10.1016/j.newar.2004.03.017   \n",
       "2  10.1146/annurev-astro-091918-104430   \n",
       "3  10.1146/annurev-astro-081309-130834   \n",
       "4       10.1146/annurev.astro.37.1.127   \n",
       "\n",
       "                                       sent_original  \\\n",
       "0  (Shang et al. 1998), do show unusual, faint fe...   \n",
       "1  Novak et al. (2003) studied the dust emission ...   \n",
       "2  The momentum per unit mass of stars formed del...   \n",
       "3  An example of the latter is the dormant blue s...   \n",
       "4  Kaiser et al (1995) (see also Luppino Kaiser 1...   \n",
       "\n",
       "                                         sent_no_cit  sent_idx  \\\n",
       "0  Such events 123 196 R. Sancisi et al. are more...       159   \n",
       "1  The radio emission shows that the nonthermal e...      1329   \n",
       "2  There has yet to be a comprehensive numerical ...       542   \n",
       "3  Because the observed YMCs will age to become o...       815   \n",
       "4  The anisotropy of the PSF is corrected on the ...       282   \n",
       "\n",
       "                                      citation_dois   pubdate  \\\n",
       "0                                  [10.1086/311563]  20080601   \n",
       "1                                  [10.1086/368156]  20040901   \n",
       "2                                  [10.1086/317785]  20190801   \n",
       "3                 [10.48550/arXiv.astro-ph/9701042]  20100901   \n",
       "4  [10.1086/176071, 10.1086/303508, 10.1086/306102]  19990101   \n",
       "\n",
       "                                   resolved_bibcodes  \\\n",
       "0                              [1998ApJ...504L..23S]   \n",
       "1                              [2003ApJ...583L..83N]   \n",
       "2                              [2000ApJ...545..364M]   \n",
       "3                              [1997A&A...328..130P]   \n",
       "4  [1995ApJ...449..460K, 1997ApJ...475...20L, 199...   \n",
       "\n",
       "                                     sent_cit_masked  \\\n",
       "0  ([REF]), do show unusual, faint features in th...   \n",
       "1  [REF] studied the dust emission at 450 μm in t...   \n",
       "2  The momentum per unit mass of stars formed del...   \n",
       "3  An example of the latter is the dormant blue s...   \n",
       "4  [REF] (see also [REF] for further developments...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.019467777, -0.050828665, -0.009596894, 0.01...  \n",
       "1  [0.0020762016, 0.016566603, -0.0056969826, 0.0...  \n",
       "2  [0.040522993, -0.03144786, -0.010288201, 0.010...  \n",
       "3  [-0.02477378, -0.02790011, -0.013496099, 0.052...  \n",
       "4  [0.032639474, -0.07257655, -0.009156834, 0.008...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from citeline.database.milvusdb import MilvusDB\n",
    "from citeline.embedders import Embedder\n",
    "from citeline.query_expander import QueryExpander\n",
    "\n",
    "db = MilvusDB()\n",
    "print(db)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Setup: load embedder, expander, dataset, db collection\n",
    "embedder = Embedder.create(\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True)\n",
    "print(embedder)\n",
    "\n",
    "expander = QueryExpander(\"add_prev_3\", reference_data_path=\"../data/preprocessed/reviews.jsonl\")\n",
    "print(expander)\n",
    "\n",
    "sample = pd.read_json(\"../data/dataset/nontrivial_100.jsonl\", lines=True)\n",
    "# sample = sample.sample(96, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Apply query expansion and embed the queries\n",
    "sample[\"sent_no_cit\"] = expander(sample)\n",
    "sample[\"vector\"] = sample.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "db.list_collections()\n",
    "db.client.load_collection(\"qwen06_contributions\")\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c745673",
   "metadata": {},
   "source": [
    "### Data Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fa4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This row's sentence concats a body sentence with a figure caption, which the dataset builder agent should not have included\n",
    "row = sample.iloc[17]\n",
    "print(row['sent_original'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e01a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sentence ('Kartaltepe et al. (2012) find that a sample ...) actually got linked to the wrong paper, Kocevski et al 2012\n",
    "print(sample.iloc[26][\"sent_original\"])\n",
    "print(sample.at[26, \"citation_dois\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccbcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its true target, \"10.48550/arXiv.1110.4057\", not in the db\n",
    "sample.drop(index=15, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c36451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 231.40it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 18.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_hard_records(example: pd.Series, n: int = 2) -> list[str]:\n",
    "    \"\"\"\n",
    "    Overfetches 3*n most similar records (bc if two reps from same doc are in top n, we won't have n distinct non-target dois)\n",
    "\n",
    "    Returns:\n",
    "      A list of doi's, ordered by their max similarity to the query\n",
    "    \"\"\"\n",
    "    results = db.search(\n",
    "        collection_name=\"qwen06_contributions\",\n",
    "        query_records=[example.to_dict()],\n",
    "        query_vectors=[example.vector],\n",
    "        limit=10 * n,\n",
    "    )\n",
    "    results = results[0]  # db.search operates on lists of queries; we only need the first result\n",
    "\n",
    "    # Filter results to non-targets only\n",
    "    target_dois = set(example.citation_dois)\n",
    "    non_target_results = [r for r in results if r[\"doi\"] not in target_dois]\n",
    "    return non_target_results[:n]\n",
    "\n",
    "\n",
    "def get_similarity_to_targets(example: pd.Series) -> list[float]:\n",
    "    \"\"\"\n",
    "    For each target doi in the example, computes the max similarity between the example and any record with that doi.\n",
    "\n",
    "    Returns a list of scores in order of example.citation_dois\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for target_doi in example.citation_dois:\n",
    "        try:\n",
    "            results = db.select_by_doi(doi=target_doi, collection_name=\"qwen06_contributions\")\n",
    "            target_vectors = np.array(results[\"vector\"].tolist())\n",
    "            similarity_scores = np.dot(example.vector, target_vectors.T)\n",
    "            similarities.append(np.max(similarity_scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOI {target_doi}: {e}\")\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def compute_margins(df: pd.DataFrame, target_col: str, hard_col: str, margin_col_name: str) -> None:\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, computes the margin between each target similarity and the hardest non-target similarity.\n",
    "\n",
    "    Args:\n",
    "      df: DataFrame containing the data\n",
    "      target_col: Name of the column with list of target similarities\n",
    "      hard_col: Name of the column with list of hard non-target similarities\n",
    "      margin_col_name: Name of the column to store the computed margins\n",
    "\n",
    "    Returns:\n",
    "      None (modifies df in place)\n",
    "    \"\"\"\n",
    "\n",
    "    df[margin_col_name] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        target_similarities = row[target_col]\n",
    "        hardest_nontarget_similarity = max(row[hard_col])\n",
    "        margins = [target_sim - hardest_nontarget_similarity for target_sim in target_similarities]\n",
    "        df.at[idx, margin_col_name] = margins\n",
    "\n",
    "\n",
    "# Compute target and hard similarities, then the margins\n",
    "sample[\"target_similarities\"] = sample.progress_apply(get_similarity_to_targets, axis=1)\n",
    "sample[\"hard_dois\"] = None\n",
    "sample[\"hard_similarities\"] = None\n",
    "for idx, example in tqdm(sample.iterrows(), total=len(sample)):\n",
    "    hard_records = get_hard_records(example, n=2)\n",
    "    sample.at[idx, \"hard_dois\"] = [r[\"doi\"] for r in hard_records]\n",
    "    sample.at[idx, \"hard_similarities\"] = [r[\"metric\"] for r in hard_records]\n",
    "\n",
    "compute_margins(sample, target_col=\"target_similarities\", hard_col=\"hard_similarities\", margin_col_name=\"old_margins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877f8099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    131.000000\n",
       "mean      -0.076346\n",
       "std        0.084217\n",
       "min       -0.267450\n",
       "25%       -0.143250\n",
       "50%       -0.072353\n",
       "75%       -0.022547\n",
       "max        0.163279\n",
       "Name: old_margins, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins = pd.to_numeric(sample.explode(column=\"old_margins\")[\"old_margins\"], errors=\"coerce\").dropna()\n",
    "margins.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51c0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "margins.to_pickle(\"margins_v1_n100.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096c976",
   "metadata": {},
   "source": [
    "## Process the dois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08364f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI's to process: 309\n",
      "Loaded 309 research papers\n"
     ]
    }
   ],
   "source": [
    "dois_to_process = set(doi for dois in sample.citation_dois for doi in dois).union(\n",
    "    doi for dois in sample.hard_dois for doi in dois\n",
    ")\n",
    "print(f\"DOI's to process: {len(dois_to_process)}\")\n",
    "\n",
    "# Load research papers so we can get full text by doi\n",
    "research = pd.read_json(\"../data/research_used.jsonl\", lines=True)\n",
    "research = research[research[\"doi\"].isin(dois_to_process)].reset_index(drop=True)\n",
    "print(f\"Loaded {len(research)} research papers\")\n",
    "\n",
    "\n",
    "def doi_to_paper(doi: str) -> str:\n",
    "    record = research[research[\"doi\"] == doi].iloc[0]\n",
    "    return record[\"title\"] + \"\\n\\n\" + record[\"abstract\"] + \"\\n\\n\" + record[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c893fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek client\n",
    "from citeline.apis.deepseek import deepseek_formatted as deepseek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d78804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI, Gemini Clients\n",
    "\n",
    "# from citeline.apis.openai_client import openai_llm_client\n",
    "\n",
    "# openai_llm = openai_llm_client(model=\"gpt-5-nano\")\n",
    "\n",
    "\n",
    "# from google import genai\n",
    "# from google.genai import types\n",
    "# from citeline.llm.models import Findings\n",
    "\n",
    "# client = genai.Client()\n",
    "# with open(\"../src/citeline/llm/prompts/original_contributions_gemini_v3.txt\", \"r\") as f:\n",
    "#     prompt_template = f.read()\n",
    "\n",
    "\n",
    "# def gemini(paper: str) -> str:\n",
    "#     raw_text = \"\"\n",
    "#     try:\n",
    "#         response = client.models.generate_content(\n",
    "#             model=\"gemini-2.5-flash\",\n",
    "#             config=types.GenerateContentConfig(\n",
    "#                 temperature=0.0,\n",
    "#                 system_instruction=prompt_template,\n",
    "#                 response_mime_type=\"application/json\",\n",
    "#                 response_schema=Findings,\n",
    "#             ),\n",
    "#             contents=paper,\n",
    "#         )\n",
    "#         return response.parsed\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during Gemini call: {e}\")\n",
    "#         return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90094a6b",
   "metadata": {},
   "source": [
    "### Set the filename for this run's generated findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fd7a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_FINDINGS_FILENAME = \"findings_v3_reasoner_n100.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbc6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing findings file found. Starting fresh.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 171/309 [1:26:57<1:08:23, 29.74s/it]"
     ]
    }
   ],
   "source": [
    "with open(\"../src/citeline/llm/prompts/original_contributions_v3.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "# llm_function = deepseek\n",
    "# llm_function = openai_llm\n",
    "\n",
    "# Check if any dois have already been processed\n",
    "try:\n",
    "    with open(NEW_FINDINGS_FILENAME, \"r\") as f:\n",
    "        processed_dois = {json.loads(line)[\"doi\"] for line in f if line.strip()}\n",
    "        dois_to_process -= processed_dois\n",
    "    print(f\"Already processed {len(processed_dois)} DOI's.\")\n",
    "except FileNotFoundError:\n",
    "    processed_dois = set()\n",
    "    print(\"No existing findings file found. Starting fresh.\")\n",
    "\n",
    "with open(NEW_FINDINGS_FILENAME, \"a\") as f:\n",
    "    for doi in tqdm(dois_to_process):\n",
    "        paper = doi_to_paper(doi)\n",
    "        prompt = prompt_template.format(paper=paper)\n",
    "        try:\n",
    "            # response = llm_function(prompt)\n",
    "            response = deepseek(prompt, model=\"deepseek-chat\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing doi {doi}: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(response)\n",
    "            data[\"doi\"] = doi\n",
    "            f.write(json.dumps(data) + \"\\n\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON for doi {doi}. Response was:\\n{response}\")\n",
    "            with open(\"failed_dois.txt\", \"a\") as f_fail:\n",
    "                f_fail.write(doi + \"\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c7e78",
   "metadata": {},
   "source": [
    "# NOTE: When this process is done rename the file and filename variable to reflect 'chat' not 'reasoner'!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_findings = pd.read_json(NEW_FINDINGS_FILENAME, lines=True)\n",
    "print(f\"Loaded {len(new_findings)} new findings\")\n",
    "\n",
    "new_findings_exploded = new_findings.explode(\"findings\")\n",
    "new_findings_exploded[\"vector\"] = embedder(new_findings_exploded[\"findings\"].tolist()).tolist()\n",
    "new_findings_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new similarity to target\n",
    "sample[\"new_target_similarities\"] = None\n",
    "sample[\"new_hard_similarities\"] = None\n",
    "\n",
    "\n",
    "def get_vectors_by_doi(doi: str) -> np.ndarray:\n",
    "    return np.array(new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"vector\"].tolist())\n",
    "\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    # For each target doi, compute the max similarity wrt the new embeddings\n",
    "    query_vector = row[\"vector\"]\n",
    "    new_similarities = []\n",
    "    for target_doi in row[\"citation_dois\"]:\n",
    "        target_vectors = get_vectors_by_doi(target_doi)\n",
    "        new_similarities.append(np.max(np.dot(query_vector, target_vectors.T)))\n",
    "    sample.at[idx, \"new_target_similarities\"] = new_similarities\n",
    "\n",
    "    # Collect all the hard vectors, compute the hard similarities\n",
    "    new_hard_similarities = []\n",
    "    for doi in row[\"hard_dois\"]:\n",
    "        candidate_vectors = get_vectors_by_doi(doi)\n",
    "        new_hard_similarities.append(np.max(np.dot(query_vector, candidate_vectors.T)))\n",
    "    sample.at[idx, \"new_hard_similarities\"] = new_hard_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_margins(\n",
    "    sample, target_col=\"new_target_similarities\", hard_col=\"new_hard_similarities\", margin_col_name=\"new_margins\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_margin_diffs(df: pd.DataFrame, new_col: str, ref_col: str) -> pd.Series:\n",
    "    new_values = df[new_col].explode().tolist()\n",
    "    ref_values = df[ref_col].explode().tolist()\n",
    "    diffs = [new - ref for new, ref in zip(new_values, ref_values)]\n",
    "    return pd.Series(diffs)\n",
    "\n",
    "\n",
    "diffs = compute_margin_diffs(sample, new_col=\"new_margins\", ref_col=\"old_margins\")\n",
    "print(diffs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78533109",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs.to_pickle(\"margins_prompt3_chat_n50.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9faca",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "Let's look at where the new margin is still negative (the target document vectors aren't as close to the query as the hard examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows = sample[sample[\"new_margins\"].apply(lambda margins: any(margin < 0 for margin in margins))]\n",
    "print(f\"{len(error_rows)} rows have at least one negative new margin\")\n",
    "\n",
    "error_margins = pd.to_numeric(error_rows.explode(column=\"new_margins\")[\"new_margins\"], errors=\"coerce\").dropna()\n",
    "print(error_margins.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_row(idx: int) -> None:\n",
    "\n",
    "    example = error_rows.loc[idx]\n",
    "    margins = [round(float(margin), 4) for margin in example[\"new_margins\"]]\n",
    "    print(f\"Margins: {margins}\")\n",
    "    print(\"Original sentence:\")\n",
    "    print(example[\"sent_original\"])\n",
    "    print(\"\\nExpanded sentence:\")\n",
    "    print(example[\"sent_no_cit\"] + \"\\n\")\n",
    "\n",
    "    hardest_idx = np.argmax(example[\"new_hard_similarities\"])\n",
    "    hard_doi = example[\"hard_dois\"][hardest_idx]\n",
    "    hard_findings = new_findings_exploded[new_findings_exploded[\"doi\"] == hard_doi]\n",
    "    hard_vectors = np.array(hard_findings[\"vector\"].tolist())\n",
    "    hard_similarities = np.dot(example[\"vector\"], hard_vectors.T)\n",
    "    hardest_indices = np.argsort(-hard_similarities)[:3]\n",
    "    for idx in hardest_indices:\n",
    "        print(f\"Similarity: {hard_similarities[idx]:.4f}, DOI: {hard_findings.iloc[idx]['doi']}\")\n",
    "        pprint(hard_findings.iloc[idx][\"findings\"])\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "def print_target_contributions(idx: int) -> None:\n",
    "    row = error_rows.loc[idx]\n",
    "    print(\"Original sentence:\")\n",
    "    print(row[\"sent_original\"])\n",
    "\n",
    "    target_dois = row[\"citation_dois\"]\n",
    "    print(f\"Target DOIs: {target_dois}\")\n",
    "    target_records = {\n",
    "        doi: new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"findings\"] for doi in target_dois\n",
    "    }\n",
    "    pprint(\"Target findings:\")\n",
    "    for doi in target_records:\n",
    "        print(f\"DOI: {doi}\")\n",
    "        for i, finding in enumerate(target_records[doi]):\n",
    "            print(f\"{i}: {finding}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "idx = 4\n",
    "\n",
    "print_target_contributions(idx)\n",
    "analyze_error_row(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73deab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = \"10.1086/319733\"\n",
    "row = new_findings[new_findings[\"doi\"] == doi].iloc[0]\n",
    "target_texts = row[\"findings\"]\n",
    "target_vectors = embedder(target_texts)\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"One of the most surprising observations to date are those of the narrow absorption lines in the quasar 3C 191, which show evidence for partial covering at a large distance (28 kpc) from the nucleus ( ); it is difficult to understand how the small clouds have maintained their integrity over the outflow timescale of ∼3 × 10 7 year.\"\n",
    "    ]\n",
    ")[0]\n",
    "\n",
    "cosine_similarities = np.dot(query_vector, target_vectors.T)\n",
    "tups = sorted(enumerate(cosine_similarities), key=lambda x: -x[1])\n",
    "for i, sim in tups:\n",
    "    print(f\"Finding {i}: similarity {sim:.4f}\")\n",
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8908fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = embedder(\n",
    "    [\"Cosmic microwave background (CMB) anisotropy measurements indicate flat \" \"universe geometry.\"]\n",
    ")[0]\n",
    "# query_vector = error_rows.iloc[0][\"vector\"]\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"This data provided the most convincing evidence then available for the Euclidean nature of the Universe; i.e. that the geometry is flat Fig. 16 The first measurement of polarization made of the CMBR, obtained by the DASI experiment at the South Pole \"\n",
    "    ]\n",
    ")[0]\n",
    "print(f\"Cosine similarity: {query_vector.dot(target_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519056e",
   "metadata": {},
   "source": [
    "### Revision 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/citeline/llm/prompts/original_contributions_v2.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "NEW_FINDINGS_FILENAME = \"new_findings_v2.jsonl\"\n",
    "\n",
    "with open(NEW_FINDINGS_FILENAME, \"w\") as f:\n",
    "    for doi in tqdm(dois_to_process):\n",
    "        paper = doi_to_paper(doi)\n",
    "        prompt = prompt_template.format(paper=paper)\n",
    "        try:\n",
    "            response = deepseek(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing doi {doi}: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(response)\n",
    "            data[\"doi\"] = doi\n",
    "            f.write(json.dumps(data) + \"\\n\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON for doi {doi}. Response was:\\n{response}\")\n",
    "            with open(\"failed_dois.txt\", \"a\") as f_fail:\n",
    "                f_fail.write(doi + \"\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6486a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_findings = pd.read_json(NEW_FINDINGS_FILENAME, lines=True)\n",
    "print(f\"Loaded {len(new_findings)} new findings\")\n",
    "\n",
    "new_findings_exploded = new_findings.explode(\"findings\")\n",
    "new_findings_exploded[\"vector\"] = embedder(new_findings_exploded[\"findings\"].tolist()).tolist()\n",
    "new_findings_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save previous iteration and reset df for new results\n",
    "sample_old = sample.copy()\n",
    "\n",
    "# Get new similarity to target\n",
    "sample[\"new_target_similarities\"] = None\n",
    "sample[\"new_hard_similarities\"] = None\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    # For each target doi, compute the max similarity wrt the new embeddings\n",
    "    query_vector = row[\"vector\"]\n",
    "    new_similarities = []\n",
    "    for target_doi in row[\"citation_dois\"]:\n",
    "        target_vectors = get_vectors_by_doi(target_doi)\n",
    "        new_similarities.append(np.max(np.dot(query_vector, target_vectors.T)))\n",
    "    sample.at[idx, \"new_target_similarities\"] = new_similarities\n",
    "\n",
    "    # Collect all the hard vectors, compute the hard similarities\n",
    "    new_hard_similarities = []\n",
    "    for doi in row[\"hard_dois\"]:\n",
    "        candidate_vectors = get_vectors_by_doi(doi)\n",
    "        new_hard_similarities.append(np.max(np.dot(query_vector, candidate_vectors.T)))\n",
    "    sample.at[idx, \"new_hard_similarities\"] = new_hard_similarities\n",
    "\n",
    "compute_margins(\n",
    "    sample, target_col=\"new_target_similarities\", hard_col=\"new_hard_similarities\", margin_col_name=\"new_margins\"\n",
    ")\n",
    "sample.head()\n",
    "\n",
    "diffs = compute_margin_diffs(sample, new_col=\"new_margins\", ref_col=\"old_margins\")\n",
    "print(diffs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows = sample[sample[\"new_margins\"].apply(lambda margins: any(margin < 0 for margin in margins))]\n",
    "print(f\"Number of rows with negative new margins: {len(error_rows)}\")\n",
    "error_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the target contributions for an error row\n",
    "idx = 0\n",
    "analyze_error_row(idx)\n",
    "\n",
    "\n",
    "def print_target_contributions(idx: int) -> None:\n",
    "    row = error_rows.iloc[idx]\n",
    "    print(\"Original sentence:\")\n",
    "    print(row[\"sent_original\"])\n",
    "\n",
    "    target_dois = row[\"citation_dois\"]\n",
    "    target_records = {\n",
    "        doi: new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"findings\"] for doi in target_dois\n",
    "    }\n",
    "    pprint(\"Target findings:\")\n",
    "    for doi in target_records:\n",
    "        print(f\"DOI: {doi}\")\n",
    "        for i, finding in enumerate(target_records[doi]):\n",
    "            print(f\"{i}: {finding}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "print(f\"Sentence in context:\\n{error_rows.iloc[idx]['sent_no_cit']}\")\n",
    "print_target_contributions(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d080fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows.iloc[idx][\"sent_no_cit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = embedder(\n",
    "    [\n",
    "        \"Deep optical images shows a faint elliptical ring structure orbiting the spiral galaxy NGC 5907\",\n",
    "    ]\n",
    ")[0]\n",
    "# query_vector = error_rows.iloc[0][\"vector\"]\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"However, deep optical images of a number of spiral galaxies, such as NGC 253, M 83, M 104, NGC 2855, (Malin and Hadley 1997) and NGC 5907 (), do show unusual, faint features in their surroundings.\",\n",
    "    ]\n",
    ")[0]\n",
    "print(f\"Cosine similarity: {query_vector.dot(target_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_vector = embedder([\"Most extended and complete luminosity function obtained for Galactic bulge to date\"])[0]\n",
    "print(f\"Cosine similarity: {np.dot(hard_vector, query_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e14855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in new_findings_exploded[new_findings_exploded[\"doi\"] == \"10.1086/164480\"].iterrows():\n",
    "    print(f\"Finding {i}:\")\n",
    "    pprint(row[\"findings\"])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pickle files\n",
    "margins_v1 = pd.read_pickle(\"margins_v1_n50.pkl\")\n",
    "margins_reasoner_v3 = pd.read_pickle(\"margins_prompt3_reasoner_n50.pkl\")\n",
    "margins_chat_v3 = pd.read_pickle(\"margins_prompt3_chat_n50.pkl\")\n",
    "\n",
    "plt.boxplot(\n",
    "    [\n",
    "        margins_v1,\n",
    "        margins_chat_v3,\n",
    "        margins_reasoner_v3,\n",
    "    ],\n",
    "    labels=[\"Prompt v1\\ndeepseek-r1\", \"Prompt v3\\ndeepseek-chat\", \"Prompt v2\\ndeepseek-reasoner\"],\n",
    ")\n",
    "plt.axhline(y=0, color=\"blue\", linestyle=\"--\", linewidth=1.0)\n",
    "plt.title(f\"Margin Differences (n={len(sample)})\")\n",
    "plt.ylabel(\"Margins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "margins_reasoner_v3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074b161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
