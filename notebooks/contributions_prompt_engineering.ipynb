{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9346f4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<citeline.database.milvusdb.MilvusDB object at 0x111b49890>\n",
      "Qwen/Qwen3-Embedding-0.6B, device=mps, normalize=True, dim=1024\n",
      "QueryExpander(name=add_prev_3, data_length=2980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collections:\n",
      " - astrobert_chunks: 460801 entities\n",
      " - astrobert_contributions: 89860 entities\n",
      " - bge_chunks: 460801 entities\n",
      " - bge_contributions: 89860 entities\n",
      " - nasa_chunks: 460801 entities\n",
      " - nasa_contributions: 89860 entities\n",
      " - qwen06_chunks: 460801 entities\n",
      " - qwen06_contributions: 89860 entities\n",
      " - qwen06_findings_v2: 4342 entities\n",
      " - qwen06_v3_contributions: 299286 entities\n",
      " - qwen8b_contributions: 89860 entities\n",
      " - specter_chunks: 460801 entities\n",
      " - specter_contributions: 89860 entities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>citation_dois</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>resolved_bibcodes</th>\n",
       "      <th>sent_cit_masked</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1146/annurev-astro-021022-043545</td>\n",
       "      <td>For example, strong outliers from the MZR with...</td>\n",
       "      <td>There are important practical implications for...</td>\n",
       "      <td>494</td>\n",
       "      <td>[10.1088/0004-637X/695/1/259]</td>\n",
       "      <td>20220801</td>\n",
       "      <td>[2009ApJ...695..259P]</td>\n",
       "      <td>For example, strong outliers from the MZR with...</td>\n",
       "      <td>[-0.0304536, -0.03546455, -0.008876894, -0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1007/s001590050008</td>\n",
       "      <td>Grillmair et al. (1995a) conclude that the sta...</td>\n",
       "      <td>They find that most of their sample clusters s...</td>\n",
       "      <td>593</td>\n",
       "      <td>[10.1086/117470]</td>\n",
       "      <td>19970101</td>\n",
       "      <td>[1995AJ....109.2553G]</td>\n",
       "      <td>[REF] conclude that the stars found beyond the...</td>\n",
       "      <td>[-0.023469558, 0.0036594549, -0.009580555, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.newar.2021.101610</td>\n",
       "      <td>Later, a very similar study was carried out by...</td>\n",
       "      <td>For the problem at hand, these conditions are ...</td>\n",
       "      <td>608</td>\n",
       "      <td>[10.1111/j.1365-2966.2010.17674.x]</td>\n",
       "      <td>20210601</td>\n",
       "      <td>[2011MNRAS.411..155G]</td>\n",
       "      <td>Later, a very similar study was carried out by...</td>\n",
       "      <td>[0.012016729, -0.036106728, -0.008817904, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1146/annurev-astro-082214-122348</td>\n",
       "      <td>k Using column density of C-C bonds derived by...</td>\n",
       "      <td>h Identification based on a single absorption ...</td>\n",
       "      <td>377</td>\n",
       "      <td>[10.1088/0004-637X/784/2/172]</td>\n",
       "      <td>20150801</td>\n",
       "      <td>[2014ApJ...784..172H]</td>\n",
       "      <td>k Using column density of C-C bonds derived by...</td>\n",
       "      <td>[-0.05986425, -0.016321747, -0.008735628, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1146/annurev.astro.41.082801.100328</td>\n",
       "      <td>One of the most surprising observations to dat...</td>\n",
       "      <td>Additional evidence for clumpiness comes from ...</td>\n",
       "      <td>321</td>\n",
       "      <td>[10.1086/319733]</td>\n",
       "      <td>20030101</td>\n",
       "      <td>[2001ApJ...550..142H]</td>\n",
       "      <td>One of the most surprising observations to dat...</td>\n",
       "      <td>[-0.0136848325, -0.06581634, -0.010353548, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               source_doi  \\\n",
       "0     10.1146/annurev-astro-021022-043545   \n",
       "1                   10.1007/s001590050008   \n",
       "2             10.1016/j.newar.2021.101610   \n",
       "3     10.1146/annurev-astro-082214-122348   \n",
       "4  10.1146/annurev.astro.41.082801.100328   \n",
       "\n",
       "                                       sent_original  \\\n",
       "0  For example, strong outliers from the MZR with...   \n",
       "1  Grillmair et al. (1995a) conclude that the sta...   \n",
       "2  Later, a very similar study was carried out by...   \n",
       "3  k Using column density of C-C bonds derived by...   \n",
       "4  One of the most surprising observations to dat...   \n",
       "\n",
       "                                         sent_no_cit  sent_idx  \\\n",
       "0  There are important practical implications for...       494   \n",
       "1  They find that most of their sample clusters s...       593   \n",
       "2  For the problem at hand, these conditions are ...       608   \n",
       "3  h Identification based on a single absorption ...       377   \n",
       "4  Additional evidence for clumpiness comes from ...       321   \n",
       "\n",
       "                        citation_dois   pubdate      resolved_bibcodes  \\\n",
       "0       [10.1088/0004-637X/695/1/259]  20220801  [2009ApJ...695..259P]   \n",
       "1                    [10.1086/117470]  19970101  [1995AJ....109.2553G]   \n",
       "2  [10.1111/j.1365-2966.2010.17674.x]  20210601  [2011MNRAS.411..155G]   \n",
       "3       [10.1088/0004-637X/784/2/172]  20150801  [2014ApJ...784..172H]   \n",
       "4                    [10.1086/319733]  20030101  [2001ApJ...550..142H]   \n",
       "\n",
       "                                     sent_cit_masked  \\\n",
       "0  For example, strong outliers from the MZR with...   \n",
       "1  [REF] conclude that the stars found beyond the...   \n",
       "2  Later, a very similar study was carried out by...   \n",
       "3  k Using column density of C-C bonds derived by...   \n",
       "4  One of the most surprising observations to dat...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.0304536, -0.03546455, -0.008876894, -0.028...  \n",
       "1  [-0.023469558, 0.0036594549, -0.009580555, 0.0...  \n",
       "2  [0.012016729, -0.036106728, -0.008817904, 0.02...  \n",
       "3  [-0.05986425, -0.016321747, -0.008735628, 0.01...  \n",
       "4  [-0.0136848325, -0.06581634, -0.010353548, 0.0...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from citeline.database.milvusdb import MilvusDB\n",
    "from citeline.embedders import Embedder\n",
    "from citeline.query_expander import get_expander\n",
    "\n",
    "db = MilvusDB()\n",
    "print(db)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Setup: load embedder, expander, dataset, db collection\n",
    "embedder = Embedder.create(\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True)\n",
    "print(embedder)\n",
    "\n",
    "expander = get_expander(\"add_prev_3\", path_to_data=\"../data/preprocessed/reviews.jsonl\")\n",
    "print(expander)\n",
    "\n",
    "sample = pd.read_json(\"../data/dataset/nontrivial_nomath.jsonl\", lines=True)\n",
    "sample = sample.sample(50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Apply query expansion and embed the queries\n",
    "sample[\"sent_no_cit\"] = expander(sample)\n",
    "sample[\"vector\"] = sample.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "db.list_collections()\n",
    "db.client.load_collection(\"qwen06_contributions\")\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e01a453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kartaltepe et al. (2012) find that a sample of ULIRGs selected from the CANDELS fields are more likely than a field galaxy sample to be involved in galaxy interactions and mergers (72 +5 −7 % versus 32 ± 3%).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.iloc[15]['sent_original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dccbcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data patches\n",
    "\n",
    "# one sample has incorrect citation_dois\n",
    "# sample.at[15, \"citation_dois\"] = [\"10.48550/arXiv.1110.4057\"]\n",
    "# It's true target, \"10.48550/arXiv.1110.4057\", not in the db\n",
    "sample.drop(index=15, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc572a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-04-01 10.1086/346076 The BIMA Survey of Nearby Galaxies (BIMA SONG). II. The CO Data ['Helfer, Tamara T.', 'Thornley, Michele D.', 'Regan, Michael W.', 'Wong, Tony', 'Sheth, Kartik', 'Vogel, Stuart N.', 'Blitz, Leo', 'Bock, Douglas C. -J.']\n",
      "1999-03-01 10.1086/306824 Megamaser Disks in Active Galactic Nuclei ['Kartje, John F.', 'Königl, Arieh', 'Elitzur, Moshe']\n",
      "2015-05-01 10.1088/2041-8205/804/1/L21 Small Scatter and Nearly Isothermal Mass Profiles to Four Half-light Radii from Two-dimensional Stellar Dynamics of Early-type Galaxies ['Cappellari, Michele', 'Romanowsky, Aaron J.', 'Brodie, Jean P.', 'Forbes, Duncan A.', 'Strader, Jay', 'Foster, Caroline', 'Kartha, Sreeja S.', 'Pastorello, Nicola', 'Pota, Vincenzo', 'Spitler, Lee R.', 'Usher, Christopher', 'Arnold, Jacob A.']\n",
      "2012-07-01 10.1088/0004-637X/753/2/167 What Turns Galaxies Off? The Different Morphologies of Star-forming and Quiescent Galaxies since z ~ 2 from CANDELS ['Bell, Eric F.', 'van der Wel, Arjen', 'Papovich, Casey', 'Kocevski, Dale', 'Lotz, Jennifer', 'McIntosh, Daniel H.', 'Kartaltepe, Jeyhan', 'Faber, S. M.', 'Ferguson, Harry', 'Koekemoer, Anton', 'Grogin, Norman', 'Wuyts, Stijn', 'Cheung, Edmond', 'Conselice, Christopher J.', 'Dekel, Avishai', 'Dunlop, James S.', 'Giavalisco, Mauro', 'Herrington, Jessica', 'Koo, David C.', 'McGrath, Elizabeth J.', 'de Mello, Duilia', 'Rix, Hans-Walter', 'Robaina, Aday R.', 'Williams, Christina C.']\n",
      "2011-08-01 10.1088/0004-637X/737/1/32 Grand Design and Flocculent Spirals in the Spitzer Survey of Stellar Structure in Galaxies (S<SUP>4</SUP>G) ['Elmegreen, Debra Meloy', 'Elmegreen, Bruce G.', 'Yau, Andrew', 'Athanassoula, E.', 'Bosma, Albert', 'Buta, Ronald J.', 'Helou, George', 'Ho, Luis C.', 'Gadotti, Dimitri A.', 'Knapen, Johan H.', 'Laurikainen, Eija', 'Madore, Barry F.', 'Masters, Karen L.', 'Meidt, Sharon E.', 'Menéndez-Delmestre, Karín', 'Regan, Michael W.', 'Salo, Heikki', 'Sheth, Kartik', 'Zaritsky, Dennis', 'Aravena, Manuel', 'Skibba, Ramin', 'Hinz, Joannah L.', 'Laine, Jarkko', 'Gil de Paz, Armando', 'Muñoz-Mateos, Juan-Carlos', 'Seibert, Mark', 'Mizusawa, Trisha', 'Kim, Taehyun', 'Erroz Ferrer, Santiago']\n",
      "2013-02-01 10.1088/0004-637X/764/2/176 Widespread and Hidden Active Galactic Nuclei in Star-forming Galaxies at Redshift &gt;0.3 ['Juneau, Stéphanie', 'Dickinson, Mark', 'Bournaud, Frédéric', 'Alexander, David M.', 'Daddi, Emanuele', 'Mullaney, James R.', 'Magnelli, Benjamin', 'Kartaltepe, Jeyhan S.', 'Hwang, Ho Seong', 'Willner, S. P.', 'Coil, Alison L.', 'Rosario, David J.', 'Trump, Jonathan R.', 'Weiner, Benjamin J.', 'Willmer, Christopher N. A.', 'Cooper, Michael C.', 'Elbaz, David', 'Faber, S. M.', 'Frayer, David T.', 'Kocevski, Dale D.', 'Laird, Elise S.', 'Monkiewicz, Jacqueline A.', 'Nandra, Kirpal', 'Newman, Jeffrey A.', 'Salim, Samir', 'Symeonidis, Myrto']\n",
      "2019-01-01 10.3847/2041-8213/aaf8b9 SOFIA Far-infrared Imaging Polarimetry of M82 and NGC 253: Exploring the Supergalactic Wind ['Jones, Terry Jay', 'Dowell, C. Darren', 'Lopez Rodriguez, Enrique', 'Zweibel, Ellen G.', 'Berthoud, Marc', 'Chuss, David T.', 'Goldsmith, Paul F.', 'Hamilton, Ryan T.', 'Hanany, Shaul', 'Harper, Doyal A.', 'Lazarian, Alex', 'Looney, Leslie W.', 'Michail, Joseph M.', 'Morris, Mark R.', 'Novak, Giles', 'Santos, Fabio P.', 'Sheth, Kartik', 'Stacey, Gordon J.', 'Staguhn, Johannes', 'Stephens, Ian W.', 'Tassis, Konstantinos', 'Trinh, Christopher Q.', 'Volpert, C. G.', 'Werner, Michael', 'Wollack, Edward J.', 'HAWC+ Science Team']\n",
      "2016-02-01 10.3847/0004-637X/818/1/99 Globular Cluster Populations: Results Including S<SUP>4</SUP>G Late-type Galaxies ['Zaritsky, Dennis', 'McCabe, Kelsey', 'Aravena, Manuel', 'Athanassoula, E.', 'Bosma, Albert', 'Comerón, Sébastien', 'Courtois, Helene M.', 'Elmegreen, Bruce G.', 'Elmegreen, Debra M.', 'Erroz-Ferrer, Santiago', 'Gadotti, Dimitri A.', 'Hinz, Joannah L.', 'Ho, Luis C.', 'Holwerda, Benne', 'Kim, Taehyun', 'Knapen, Johan H.', 'Laine, Jarkko', 'Laurikainen, Eija', 'Muñoz-Mateos, Juan Carlos', 'Salo, Heikki', 'Sheth, Kartik']\n",
      "2001-11-01 10.1086/323221 The BIMA Survey of Nearby Galaxies. I. The Radial Distribution of CO Emission in Spiral Galaxies ['Regan, Michael W.', 'Thornley, Michele D.', 'Helfer, Tamara T.', 'Sheth, Kartik', 'Wong, Tony', 'Vogel, Stuart N.', 'Blitz, Leo', 'Bock, Douglas C. -J.']\n",
      "2011-12-01 10.1088/0067-0049/197/2/35 CANDELS: The Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey ['Grogin, Norman A.', 'Kocevski, Dale D.', 'Faber, S. M.', 'Ferguson, Henry C.', 'Koekemoer, Anton M.', 'Riess, Adam G.', 'Acquaviva, Viviana', 'Alexander, David M.', 'Almaini, Omar', 'Ashby, Matthew L. N.', 'Barden, Marco', 'Bell, Eric F.', 'Bournaud, Frédéric', 'Brown, Thomas M.', 'Caputi, Karina I.', 'Casertano, Stefano', 'Cassata, Paolo', 'Castellano, Marco', 'Challis, Peter', 'Chary, Ranga-Ram', 'Cheung, Edmond', 'Cirasuolo, Michele', 'Conselice, Christopher J.', 'Roshan Cooray, Asantha', 'Croton, Darren J.', 'Daddi, Emanuele', 'Dahlen, Tomas', 'Davé, Romeel', 'de Mello, Duília F.', 'Dekel, Avishai', 'Dickinson, Mark', 'Dolch, Timothy', 'Donley, Jennifer L.', 'Dunlop, James S.', 'Dutton, Aaron A.', 'Elbaz, David', 'Fazio, Giovanni G.', 'Filippenko, Alexei V.', 'Finkelstein, Steven L.', 'Fontana, Adriano', 'Gardner, Jonathan P.', 'Garnavich, Peter M.', 'Gawiser, Eric', 'Giavalisco, Mauro', 'Grazian, Andrea', 'Guo, Yicheng', 'Hathi, Nimish P.', 'Häussler, Boris', 'Hopkins, Philip F.', 'Huang, Jia-Sheng', 'Huang, Kuang-Han', 'Jha, Saurabh W.', 'Kartaltepe, Jeyhan S.', 'Kirshner, Robert P.', 'Koo, David C.', 'Lai, Kamson', 'Lee, Kyoung-Soo', 'Li, Weidong', 'Lotz, Jennifer M.', 'Lucas, Ray A.', 'Madau, Piero', 'McCarthy, Patrick J.', 'McGrath, Elizabeth J.', 'McIntosh, Daniel H.', 'McLure, Ross J.', 'Mobasher, Bahram', 'Moustakas, Leonidas A.', 'Mozena, Mark', 'Nandra, Kirpal', 'Newman, Jeffrey A.', 'Niemi, Sami-Matias', 'Noeske, Kai G.', 'Papovich, Casey J.', 'Pentericci, Laura', 'Pope, Alexandra', 'Primack, Joel R.', 'Rajan, Abhijith', 'Ravindranath, Swara', 'Reddy, Naveen A.', 'Renzini, Alvio', 'Rix, Hans-Walter', 'Robaina, Aday R.', 'Rodney, Steven A.', 'Rosario, David J.', 'Rosati, Piero', 'Salimbeni, Sara', 'Scarlata, Claudia', 'Siana, Brian', 'Simard, Luc', 'Smidt, Joseph', 'Somerville, Rachel S.', 'Spinrad, Hyron', 'Straughn, Amber N.', 'Strolger, Louis-Gregory', 'Telford, Olivia', 'Teplitz, Harry I.', 'Trump, Jonathan R.', 'van der Wel, Arjen', 'Villforth, Carolin', 'Wechsler, Risa H.', 'Weiner, Benjamin J.', 'Wiklind, Tommy', 'Wild, Vivienne', 'Wilson, Grant', 'Wuyts, Stijn', 'Yan, Hao-Jing', 'Yun, Min S.']\n",
      "2011-09-01 10.1051/0004-6361/201117239 GOODS-Herschel: an infrared main sequence for star-forming galaxies ['Elbaz, D.', 'Dickinson, M.', 'Hwang, H. S.', 'Díaz-Santos, T.', 'Magdis, G.', 'Magnelli, B.', 'Le Borgne, D.', 'Galliano, F.', 'Pannella, M.', 'Chanial, P.', 'Armus, L.', 'Charmandaris, V.', 'Daddi, E.', 'Aussel, H.', 'Popesso, P.', 'Kartaltepe, J.', 'Altieri, B.', 'Valtchanov, I.', 'Coia, D.', 'Dannerbauer, H.', 'Dasyra, K.', 'Leiton, R.', 'Mazzarella, J.', 'Alexander, D. M.', 'Buat, V.', 'Burgarella, D.', 'Chary, R. -R.', 'Gilli, R.', 'Ivison, R. J.', 'Juneau, S.', \"Le Floc'h, E.\", 'Lutz, D.', 'Morrison, G. E.', 'Mullaney, J. R.', 'Murphy, E.', 'Pope, A.', 'Scott, D.', 'Brodwin, M.', 'Calzetti, D.', 'Cesarsky, C.', 'Charlot, S.', 'Dole, H.', 'Eisenhardt, P.', 'Ferguson, H. C.', 'Förster Schreiber, N.', 'Frayer, D.', 'Giavalisco, M.', 'Huynh, M.', 'Koekemoer, A. M.', 'Papovich, C.', 'Reddy, N.', 'Surace, C.', 'Teplitz, H.', 'Yun, M. S.', 'Wilson, G.']\n",
      "2010-02-01 10.1088/0004-637X/709/2/644 Galaxy Stellar Mass Assembly Between 0.2 &lt; z &lt; 2 from the S-COSMOS Survey ['Ilbert, O.', 'Salvato, M.', \"Le Floc'h, E.\", 'Aussel, H.', 'Capak, P.', 'McCracken, H. J.', 'Mobasher, B.', 'Kartaltepe, J.', 'Scoville, N.', 'Sanders, D. B.', 'Arnouts, S.', 'Bundy, K.', 'Cassata, P.', 'Kneib, J. -P.', 'Koekemoer, A.', 'Le Fèvre, O.', 'Lilly, S.', 'Surace, J.', 'Taniguchi, Y.', 'Tasca, L.', 'Thompson, D.', 'Tresse, L.', 'Zamojski, M.', 'Zamorani, G.', 'Zucca, E.']\n",
      "2014-08-01 10.1088/0004-637X/791/2/80 The SLUGGS Survey: Wide-field Stellar Kinematics of Early-type Galaxies ['Arnold, Jacob A.', 'Romanowsky, Aaron J.', 'Brodie, Jean P.', 'Forbes, Duncan A.', 'Strader, Jay', 'Spitler, Lee R.', 'Foster, Caroline', 'Blom, Christina', 'Kartha, Sreeja S.', 'Pastorello, Nicola', 'Pota, Vincenzo', 'Usher, Christopher', 'Woodley, Kristin A.']\n",
      "2013-08-01 10.1051/0004-6361/201321100 Mass assembly in quiescent and star-forming galaxies since z ≃ 4 from UltraVISTA ['Ilbert, O.', 'McCracken, H. J.', 'Le Fèvre, O.', 'Capak, P.', 'Dunlop, J.', 'Karim, A.', 'Renzini, M. A.', 'Caputi, K.', 'Boissier, S.', 'Arnouts, S.', 'Aussel, H.', 'Comparat, J.', 'Guo, Q.', 'Hudelot, P.', 'Kartaltepe, J.', 'Kneib, J. P.', 'Krogager, J. K.', \"Le Floc'h, E.\", 'Lilly, S.', 'Mellier, Y.', 'Milvang-Jensen, B.', 'Moutard, T.', 'Onodera, M.', 'Richard, J.', 'Salvato, M.', 'Sanders, D. B.', 'Scoville, N.', 'Silverman, J. D.', 'Taniguchi, Y.', 'Tasca, L.', 'Thomas, R.', 'Toft, S.', 'Tresse, L.', 'Vergani, D.', 'Wolk, M.', 'Zirm, A.']\n",
      "2012-04-01 10.1088/0004-637X/748/2/142 Identifying Luminous Active Galactic Nuclei in Deep Surveys: Revised IRAC Selection Criteria ['Donley, J. L.', 'Koekemoer, A. M.', 'Brusa, M.', 'Capak, P.', 'Cardamone, C. N.', 'Civano, F.', 'Ilbert, O.', 'Impey, C. D.', 'Kartaltepe, J. S.', 'Miyaji, T.', 'Salvato, M.', 'Sanders, D. B.', 'Trump, J. R.', 'Zamorani, G.']\n",
      "2010-02-01 10.1088/0067-0049/186/2/341 The VLA-COSMOS Perspective on the Infrared-Radio Relation. I. New Constraints on Selection Biases and the Non-Evolution of the Infrared/Radio Properties of Star-Forming and Active Galactic Nucleus Galaxies at Intermediate and High Redshift ['Sargent, M. T.', 'Schinnerer, E.', 'Murphy, E.', 'Aussel, H.', \"Le Floc'h, E.\", 'Frayer, D. T.', 'Martínez-Sansigre, A.', 'Oesch, P.', 'Salvato, M.', 'Smolčić, V.', 'Zamorani, G.', 'Brusa, M.', 'Cappelluti, N.', 'Carilli, C. L.', 'Carollo, C. M.', 'Ilbert, O.', 'Kartaltepe, J.', 'Koekemoer, A. M.', 'Lilly, S. J.', 'Sanders, D. B.', 'Scoville, N. Z.']\n",
      "2015-07-01 10.1088/0067-0049/219/1/5 The Spitzer Survey of Stellar Structure in Galaxies (S<SUP>4</SUP>G): Precise Stellar Mass Distributions from Automated Dust Correction at 3.6 μm ['Querejeta, Miguel', 'Meidt, Sharon E.', 'Schinnerer, Eva', 'Cisternas, Mauricio', 'Muñoz-Mateos, Juan Carlos', 'Sheth, Kartik', 'Knapen, Johan', 'van de Ven, Glenn', 'Norris, Mark A.', 'Peletier, Reynier', 'Laurikainen, Eija', 'Salo, Heikki', 'Holwerda, Benne W.', 'Athanassoula, E.', 'Bosma, Albert', 'Groves, Brent', 'Ho, Luis C.', 'Gadotti, Dimitri A.', 'Zaritsky, Dennis', 'Regan, Michael', 'Hinz, Joannah', 'Gil de Paz, Armando', 'Menendez-Delmestre, Karin', 'Seibert, Mark', 'Mizusawa, Trisha', 'Kim, Taehyun', 'Erroz-Ferrer, Santiago', 'Laine, Jarkko', 'Comerón, Sébastien']\n",
      "2011-09-01 10.1051/0004-6361/201117264 GOODS-Herschel: evidence of a UV extinction bump in galaxies at z &gt; 1 ['Buat, V.', 'Giovannoli, E.', 'Heinis, S.', 'Charmandaris, V.', 'Coia, D.', 'Daddi, E.', 'Dickinson, M.', 'Elbaz, D.', 'Hwang, H. S.', 'Morrison, G.', 'Dasyra, K.', 'Aussel, H.', 'Altieri, B.', 'Dannerbauer, H.', 'Kartaltepe, J.', 'Leiton, R.', 'Magdis, G.', 'Magnelli, B.', 'Popesso, P.']\n",
      "2011-12-01 10.1088/0067-0049/197/2/36 CANDELS: The Cosmic Assembly Near-infrared Deep Extragalactic Legacy Survey—The Hubble Space Telescope Observations, Imaging Data Products, and Mosaics ['Koekemoer, Anton M.', 'Faber, S. M.', 'Ferguson, Henry C.', 'Grogin, Norman A.', 'Kocevski, Dale D.', 'Koo, David C.', 'Lai, Kamson', 'Lotz, Jennifer M.', 'Lucas, Ray A.', 'McGrath, Elizabeth J.', 'Ogaz, Sara', 'Rajan, Abhijith', 'Riess, Adam G.', 'Rodney, Steve A.', 'Strolger, Louis', 'Casertano, Stefano', 'Castellano, Marco', 'Dahlen, Tomas', 'Dickinson, Mark', 'Dolch, Timothy', 'Fontana, Adriano', 'Giavalisco, Mauro', 'Grazian, Andrea', 'Guo, Yicheng', 'Hathi, Nimish P.', 'Huang, Kuang-Han', 'van der Wel, Arjen', 'Yan, Hao-Jing', 'Acquaviva, Viviana', 'Alexander, David M.', 'Almaini, Omar', 'Ashby, Matthew L. N.', 'Barden, Marco', 'Bell, Eric F.', 'Bournaud, Frédéric', 'Brown, Thomas M.', 'Caputi, Karina I.', 'Cassata, Paolo', 'Challis, Peter J.', 'Chary, Ranga-Ram', 'Cheung, Edmond', 'Cirasuolo, Michele', 'Conselice, Christopher J.', 'Roshan Cooray, Asantha', 'Croton, Darren J.', 'Daddi, Emanuele', 'Davé, Romeel', 'de Mello, Duilia F.', 'de Ravel, Loic', 'Dekel, Avishai', 'Donley, Jennifer L.', 'Dunlop, James S.', 'Dutton, Aaron A.', 'Elbaz, David', 'Fazio, Giovanni G.', 'Filippenko, Alexei V.', 'Finkelstein, Steven L.', 'Frazer, Chris', 'Gardner, Jonathan P.', 'Garnavich, Peter M.', 'Gawiser, Eric', 'Gruetzbauch, Ruth', 'Hartley, Will G.', 'Häussler, Boris', 'Herrington, Jessica', 'Hopkins, Philip F.', 'Huang, Jia-Sheng', 'Jha, Saurabh W.', 'Johnson, Andrew', 'Kartaltepe, Jeyhan S.', 'Khostovan, Ali A.', 'Kirshner, Robert P.', 'Lani, Caterina', 'Lee, Kyoung-Soo', 'Li, Weidong', 'Madau, Piero', 'McCarthy, Patrick J.', 'McIntosh, Daniel H.', 'McLure, Ross J.', 'McPartland, Conor', 'Mobasher, Bahram', 'Moreira, Heidi', 'Mortlock, Alice', 'Moustakas, Leonidas A.', 'Mozena, Mark', 'Nandra, Kirpal', 'Newman, Jeffrey A.', 'Nielsen, Jennifer L.', 'Niemi, Sami', 'Noeske, Kai G.', 'Papovich, Casey J.', 'Pentericci, Laura', 'Pope, Alexandra', 'Primack, Joel R.', 'Ravindranath, Swara', 'Reddy, Naveen A.', 'Renzini, Alvio', 'Rix, Hans-Walter', 'Robaina, Aday R.', 'Rosario, David J.', 'Rosati, Piero', 'Salimbeni, Sara', 'Scarlata, Claudia', 'Siana, Brian', 'Simard, Luc', 'Smidt, Joseph', 'Snyder, Diana', 'Somerville, Rachel S.', 'Spinrad, Hyron', 'Straughn, Amber N.', 'Telford, Olivia', 'Teplitz, Harry I.', 'Trump, Jonathan R.', 'Vargas, Carlos', 'Villforth, Carolin', 'Wagner, Cory R.', 'Wandro, Pat', 'Wechsler, Risa H.', 'Weiner, Benjamin J.', 'Wiklind, Tommy', 'Wild, Vivienne', 'Wilson, Grant', 'Wuyts, Stijn', 'Yun, Min S.']\n",
      "2007-12-01 10.1086/522300 Star Formation in NGC 5194 (M51a). II. The Spatially Resolved Star Formation Law ['Kennicutt, Robert C., Jr.', 'Calzetti, Daniela', 'Walter, Fabian', 'Helou, George', 'Hollenbach, David J.', 'Armus, Lee', 'Bendo, George', 'Dale, Daniel A.', 'Draine, Bruce T.', 'Engelbracht, Charles W.', 'Gordon, Karl D.', 'Prescott, Moire K. M.', 'Regan, Michael W.', 'Thornley, Michele D.', 'Bot, Caroline', 'Brinks, Elias', 'de Blok, Erwin', 'de Mello, Dulia', 'Meyer, Martin', 'Moustakas, John', 'Murphy, Eric J.', 'Sheth, Kartik', 'Smith, J. D. T.']\n",
      "2014-11-01 10.1088/0004-637X/795/2/156 ALMA Observations of the Antennae Galaxies. I. A New Window on a Prototypical Merger ['Whitmore, Bradley C.', 'Brogan, Crystal', 'Chandar, Rupali', 'Evans, Aaron', 'Hibbard, John', 'Johnson, Kelsey', 'Leroy, Adam', 'Privon, George', 'Remijan, Anthony', 'Sheth, Kartik']\n",
      "2012-01-01 10.1088/0004-637X/744/2/148 CANDELS: Constraining the AGN-Merger Connection with Host Morphologies at z ~ 2 ['Kocevski, Dale D.', 'Faber, S. M.', 'Mozena, Mark', 'Koekemoer, Anton M.', 'Nandra, Kirpal', 'Rangel, Cyprian', 'Laird, Elise S.', 'Brusa, Marcella', 'Wuyts, Stijn', 'Trump, Jonathan R.', 'Koo, David C.', 'Somerville, Rachel S.', 'Bell, Eric F.', 'Lotz, Jennifer M.', 'Alexander, David M.', 'Bournaud, Frederic', 'Conselice, Christopher J.', 'Dahlen, Tomas', 'Dekel, Avishai', 'Donley, Jennifer L.', 'Dunlop, James S.', 'Finoguenov, Alexis', 'Georgakakis, Antonis', 'Giavalisco, Mauro', 'Guo, Yicheng', 'Grogin, Norman A.', 'Hathi, Nimish P.', 'Juneau, Stéphanie', 'Kartaltepe, Jeyhan S.', 'Lucas, Ray A.', 'McGrath, Elizabeth J.', 'McIntosh, Daniel H.', 'Mobasher, Bahram', 'Robaina, Aday R.', 'Rosario, David', 'Straughn, Amber N.', 'van der Wel, Arjen', 'Villforth, Carolin']\n"
     ]
    }
   ],
   "source": [
    "research = pd.read_json('../data/research_used.jsonl', lines=True)\n",
    "for idx, row in research.iterrows():\n",
    "    authors = row.author\n",
    "    if any([\"Kart\" in name for name in authors]):\n",
    "        print(row.pubdate, row.doi, row.title, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c36451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 178.75it/s]\n",
      "100%|██████████| 49/49 [00:02<00:00, 18.11it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_hard_records(example: pd.Series, n: int = 2) -> list[str]:\n",
    "    \"\"\"\n",
    "    Overfetches 3*n most similar records (bc if two reps from same doc are in top n, we won't have n distinct non-target dois)\n",
    "\n",
    "    Returns:\n",
    "      A list of doi's, ordered by their max similarity to the query\n",
    "    \"\"\"\n",
    "    results = db.search(\n",
    "        collection_name=\"qwen06_contributions\",\n",
    "        query_records=[example.to_dict()],\n",
    "        query_vectors=[example.vector],\n",
    "        limit=3 * n,\n",
    "    )\n",
    "    results = results[0]  # db.search operates on lists of queries; we only need the first result\n",
    "\n",
    "    # Filter results to non-targets only\n",
    "    target_dois = set(example.citation_dois)\n",
    "    non_target_results = [r for r in results if r[\"doi\"] not in target_dois]\n",
    "    return non_target_results[:n]\n",
    "\n",
    "\n",
    "def get_similarity_to_targets(example: pd.Series) -> list[float]:\n",
    "    \"\"\"\n",
    "    For each target doi in the example, computes the max similarity between the example and any record with that doi.\n",
    "\n",
    "    Returns a list of scores in order of example.citation_dois\n",
    "    \"\"\"\n",
    "    similarities = []\n",
    "    for target_doi in example.citation_dois:\n",
    "        try:\n",
    "            results = db.select_by_doi(doi=target_doi, collection_name=\"qwen06_contributions\")\n",
    "            target_vectors = np.array(results[\"vector\"].tolist())\n",
    "            similarity_scores = np.dot(example.vector, target_vectors.T)\n",
    "            similarities.append(np.max(similarity_scores))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing DOI {target_doi}: {e}\")\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def compute_margins(df: pd.DataFrame, target_col: str, hard_col: str, margin_col_name: str) -> None:\n",
    "    \"\"\"\n",
    "    For each row in the DataFrame, computes the margin between each target similarity and the hardest non-target similarity.\n",
    "\n",
    "    Args:\n",
    "      df: DataFrame containing the data\n",
    "      target_col: Name of the column with list of target similarities\n",
    "      hard_col: Name of the column with list of hard non-target similarities\n",
    "      margin_col_name: Name of the column to store the computed margins\n",
    "\n",
    "    Returns:\n",
    "      None (modifies df in place)\n",
    "    \"\"\"\n",
    "    df[margin_col_name] = None\n",
    "    for idx, row in df.iterrows():\n",
    "        target_similarities = row[target_col]\n",
    "        hardest_nontarget_similarity = max(row[hard_col])\n",
    "        margins = [target_sim - hardest_nontarget_similarity for target_sim in target_similarities]\n",
    "        df.at[idx, margin_col_name] = margins\n",
    "\n",
    "\n",
    "# Compute target and hard similarities, then the margins\n",
    "sample[\"target_similarities\"] = sample.progress_apply(get_similarity_to_targets, axis=1)\n",
    "sample[\"hard_dois\"] = None\n",
    "sample[\"hard_similarities\"] = None\n",
    "for idx, example in tqdm(sample.iterrows(), total=len(sample)):\n",
    "    hard_records = get_hard_records(example, n=2)\n",
    "    sample.at[idx, \"hard_dois\"] = [r[\"doi\"] for r in hard_records]\n",
    "    sample.at[idx, \"hard_similarities\"] = [r[\"metric\"] for r in hard_records]\n",
    "\n",
    "compute_margins(sample, target_col=\"target_similarities\", hard_col=\"hard_similarities\", margin_col_name=\"old_margins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877f8099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    67.000000\n",
       "mean     -0.073777\n",
       "std       0.083496\n",
       "min      -0.267450\n",
       "25%      -0.125003\n",
       "50%      -0.068840\n",
       "75%      -0.029816\n",
       "max       0.163279\n",
       "Name: old_margins, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins = pd.to_numeric(sample.explode(column=\"old_margins\")[\"old_margins\"], errors=\"coerce\").dropna()\n",
    "margins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096c976",
   "metadata": {},
   "source": [
    "## Process the dois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08364f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI's to process: 151\n",
      "Loaded 151 research papers\n",
      "Simulations of the formation of stellar discs in the Galactic Centre via cloud-cloud collisions\n",
      "\n",
      "Young massive stars in the central parsec of our Galaxy are best explained by star formation within at least one, and possibly two, massive self-gravitating gaseous discs. With help of numerical simulations, we here consider whether the observed population of young stars could have originated from a large angle collision of two massive gaseous clouds at R ~= 1pc from SgrA*. In all the simulations per\n"
     ]
    }
   ],
   "source": [
    "dois_to_process = set(doi for dois in sample.citation_dois for doi in dois).union(\n",
    "    doi for dois in sample.hard_dois for doi in dois\n",
    ")\n",
    "print(f\"DOI's to process: {len(dois_to_process)}\")\n",
    "\n",
    "# Load research papers so we can get full text by doi\n",
    "research = pd.read_json(\"../data/research_used.jsonl\", lines=True)\n",
    "research = research[research[\"doi\"].isin(dois_to_process)].reset_index(drop=True)\n",
    "print(f\"Loaded {len(research)} research papers\")\n",
    "\n",
    "\n",
    "def doi_to_paper(doi: str) -> str:\n",
    "    record = research[research[\"doi\"] == doi].iloc[0]\n",
    "    return record[\"title\"] + \"\\n\\n\" + record[\"abstract\"] + \"\\n\\n\" + record[\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c893fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"greeting\": \"Hello\",\n",
      "  \"farewell\": \"Goodbye\"\n",
      "}\n",
      "{'greeting': 'Hello', 'farewell': 'Goodbye'}\n"
     ]
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "# import os\n",
    "\n",
    "\n",
    "# def bind_client(func):\n",
    "#     \"\"\"\n",
    "#     Decorator to bind OpenAI client to a function that will provide DeepSeek API access\n",
    "#     \"\"\"\n",
    "#     client = OpenAI(api_key=os.getenv(\"DEEPSEEK_API_KEY\"), base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "#     def wrapper(*args, **kwargs):\n",
    "#         return func(client, *args, **kwargs)\n",
    "\n",
    "#     return wrapper\n",
    "\n",
    "\n",
    "# @bind_client\n",
    "# def deepseek(client, prompt: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Sends a prompt to the DeepSeek API (using DeepSeek-V3.1 non-thinking model)\n",
    "\n",
    "#     Expects a prompt that will instruct the model to respond with a JSON object.\n",
    "#     However, the function returns the raw string response, to allow for validation and\n",
    "#     error handling in multiple passes without losing the original response\n",
    "#     \"\"\"\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"deepseek-chat\",\n",
    "#         messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "#         stream=False,\n",
    "#         response_format={\"type\": \"json_object\"},\n",
    "#     )\n",
    "#     return response.choices[0].message.content\n",
    "\n",
    "from citeline.apis.deepseek import deepseek_formatted as deepseek\n",
    "\n",
    "response = deepseek(\"Respond with a JSON object with keys 'greeting' and 'farewell'\", model=\"deepseek-reasoner\")\n",
    "print(response)\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e76e58",
   "metadata": {},
   "source": [
    "#### OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d78804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from citeline.apis.openai_client import openai_llm_client\n",
    "\n",
    "# openai_llm = openai_llm_client(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f1ea50",
   "metadata": {},
   "source": [
    "#### Gemini Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acf22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google import genai\n",
    "# from google.genai import types\n",
    "# from citeline.llm.models import Findings\n",
    "\n",
    "# client = genai.Client()\n",
    "# with open(\"../src/citeline/llm/prompts/original_contributions_gemini_v3.txt\", \"r\") as f:\n",
    "#     prompt_template = f.read()\n",
    "\n",
    "\n",
    "# def gemini(paper: str) -> str:\n",
    "#     raw_text = \"\"\n",
    "#     try:\n",
    "#         response = client.models.generate_content(\n",
    "#             model=\"gemini-2.5-flash\",\n",
    "#             config=types.GenerateContentConfig(\n",
    "#                 temperature=0.0,\n",
    "#                 system_instruction=prompt_template,\n",
    "#                 response_mime_type=\"application/json\",\n",
    "#                 response_schema=Findings,\n",
    "#             ),\n",
    "#             contents=paper,\n",
    "#         )\n",
    "#         return response.parsed\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during Gemini call: {e}\")\n",
    "#         return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbc6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/151 [06:03<8:04:26, 195.08s/it]"
     ]
    }
   ],
   "source": [
    "with open(\"../src/citeline/llm/prompts/original_contributions_v3.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "# llm_function = deepseek\n",
    "# llm_function = openai_llm\n",
    "\n",
    "with open(\"new_findings.jsonl\", \"w\") as f:\n",
    "    for doi in tqdm(dois_to_process):\n",
    "        paper = doi_to_paper(doi)\n",
    "        prompt = prompt_template.format(paper=paper)\n",
    "        try:\n",
    "            # response = llm_function(prompt)\n",
    "            response = deepseek(prompt, model=\"deepseek-reasoner\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing doi {doi}: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(response)\n",
    "            data[\"doi\"] = doi\n",
    "            f.write(json.dumps(data) + \"\\n\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON for doi {doi}. Response was:\\n{response}\")\n",
    "            with open(\"failed_dois.txt\", \"a\") as f_fail:\n",
    "                f_fail.write(doi + \"\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ef5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_findings = pd.read_json(\"new_findings.jsonl\", lines=True)\n",
    "print(f\"Loaded {len(new_findings)} new findings\")\n",
    "\n",
    "new_findings_exploded = new_findings.explode(\"findings\")\n",
    "new_findings_exploded[\"vector\"] = embedder(new_findings_exploded[\"findings\"].tolist()).tolist()\n",
    "new_findings_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new similarity to target\n",
    "sample[\"new_target_similarities\"] = None\n",
    "sample[\"new_hard_similarities\"] = None\n",
    "\n",
    "\n",
    "def get_vectors_by_doi(doi: str) -> np.ndarray:\n",
    "    return np.array(new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"vector\"].tolist())\n",
    "\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    # For each target doi, compute the max similarity wrt the new embeddings\n",
    "    query_vector = row[\"vector\"]\n",
    "    new_similarities = []\n",
    "    for target_doi in row[\"citation_dois\"]:\n",
    "        target_vectors = get_vectors_by_doi(target_doi)\n",
    "        new_similarities.append(np.max(np.dot(query_vector, target_vectors.T)))\n",
    "    sample.at[idx, \"new_target_similarities\"] = new_similarities\n",
    "\n",
    "    # Collect all the hard vectors, compute the hard similarities\n",
    "    new_hard_similarities = []\n",
    "    for doi in row[\"hard_dois\"]:\n",
    "        candidate_vectors = get_vectors_by_doi(doi)\n",
    "        new_hard_similarities.append(np.max(np.dot(query_vector, candidate_vectors.T)))\n",
    "    sample.at[idx, \"new_hard_similarities\"] = new_hard_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_margins(\n",
    "    sample, target_col=\"new_target_similarities\", hard_col=\"new_hard_similarities\", margin_col_name=\"new_margins\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52a80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_margin_diffs(df: pd.DataFrame, new_col: str, ref_col: str) -> pd.Series:\n",
    "    new_values = df[new_col].explode().tolist()\n",
    "    ref_values = df[ref_col].explode().tolist()\n",
    "    diffs = [new - ref for new, ref in zip(new_values, ref_values)]\n",
    "    return pd.Series(diffs)\n",
    "\n",
    "\n",
    "diffs = compute_margin_diffs(sample, new_col=\"new_margins\", ref_col=\"old_margins\")\n",
    "print(diffs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78533109",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['new_margins'].explode().hist(bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9faca",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "\n",
    "Let's look at where the new margin is still negative (the target document vectors aren't as close to the query as the hard examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bcf288",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows = sample[sample[\"new_margins\"].apply(lambda margins: any(margin < 0 for margin in margins))]\n",
    "print(f\"{len(error_rows)} rows have at least one negative new margin\")\n",
    "\n",
    "error_margins = pd.to_numeric(error_rows.explode(column=\"new_margins\")[\"new_margins\"], errors=\"coerce\").dropna()\n",
    "print(error_margins.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d3238",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_row(idx: int) -> None:\n",
    "\n",
    "    example = error_rows.loc[idx]\n",
    "    margins = [round(float(margin), 4) for margin in example[\"new_margins\"]]\n",
    "    print(f\"Margins: {margins}\")\n",
    "    print(\"Original sentence:\")\n",
    "    print(example[\"sent_original\"])\n",
    "    print(\"\\nExpanded sentence:\")\n",
    "    print(example[\"sent_no_cit\"] + \"\\n\")\n",
    "\n",
    "    hardest_idx = np.argmax(example[\"new_hard_similarities\"])\n",
    "    hard_doi = example[\"hard_dois\"][hardest_idx]\n",
    "    hard_findings = new_findings_exploded[new_findings_exploded[\"doi\"] == hard_doi]\n",
    "    hard_vectors = np.array(hard_findings[\"vector\"].tolist())\n",
    "    hard_similarities = np.dot(example[\"vector\"], hard_vectors.T)\n",
    "    hardest_indices = np.argsort(-hard_similarities)[:3]\n",
    "    for idx in hardest_indices:\n",
    "        print(f\"Similarity: {hard_similarities[idx]:.4f}, DOI: {hard_findings.iloc[idx]['doi']}\")\n",
    "        pprint(hard_findings.iloc[idx][\"findings\"])\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "def print_target_contributions(idx: int) -> None:\n",
    "    row = error_rows.loc[idx]\n",
    "    print(\"Original sentence:\")\n",
    "    print(row[\"sent_original\"])\n",
    "\n",
    "    target_dois = row[\"citation_dois\"]\n",
    "    print(f\"Target DOIs: {target_dois}\")\n",
    "    target_records = {\n",
    "        doi: new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"findings\"] for doi in target_dois\n",
    "    }\n",
    "    pprint(\"Target findings:\")\n",
    "    for doi in target_records:\n",
    "        print(f\"DOI: {doi}\")\n",
    "        for i, finding in enumerate(target_records[doi]):\n",
    "            print(f\"{i}: {finding}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "idx = 4\n",
    "\n",
    "print_target_contributions(idx)\n",
    "analyze_error_row(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73deab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doi = \"10.1086/319733\"\n",
    "row = new_findings[new_findings[\"doi\"] == doi].iloc[0]\n",
    "target_texts = row[\"findings\"]\n",
    "target_vectors = embedder(target_texts)\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"One of the most surprising observations to date are those of the narrow absorption lines in the quasar 3C 191, which show evidence for partial covering at a large distance (28 kpc) from the nucleus ( ); it is difficult to understand how the small clouds have maintained their integrity over the outflow timescale of ∼3 × 10 7 year.\"\n",
    "    ]\n",
    ")[0]\n",
    "\n",
    "cosine_similarities = np.dot(query_vector, target_vectors.T)\n",
    "tups = sorted(enumerate(cosine_similarities), key=lambda x: -x[1])\n",
    "for i, sim in tups:\n",
    "    print(f\"Finding {i}: similarity {sim:.4f}\")\n",
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8908fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = embedder(\n",
    "    [\"Cosmic microwave background (CMB) anisotropy measurements indicate flat \" \"universe geometry.\"]\n",
    ")[0]\n",
    "# query_vector = error_rows.iloc[0][\"vector\"]\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"This data provided the most convincing evidence then available for the Euclidean nature of the Universe; i.e. that the geometry is flat Fig. 16 The first measurement of polarization made of the CMBR, obtained by the DASI experiment at the South Pole \"\n",
    "    ]\n",
    ")[0]\n",
    "print(f\"Cosine similarity: {query_vector.dot(target_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519056e",
   "metadata": {},
   "source": [
    "### Revision 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/citeline/llm/prompts/original_contributions_v2.txt\", \"r\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "NEW_FINDINGS_FILENAME = \"new_findings_v2.jsonl\"\n",
    "\n",
    "with open(NEW_FINDINGS_FILENAME, \"w\") as f:\n",
    "    for doi in tqdm(dois_to_process):\n",
    "        paper = doi_to_paper(doi)\n",
    "        prompt = prompt_template.format(paper=paper)\n",
    "        try:\n",
    "            response = deepseek(prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing doi {doi}: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            data = json.loads(response)\n",
    "            data[\"doi\"] = doi\n",
    "            f.write(json.dumps(data) + \"\\n\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to decode JSON for doi {doi}. Response was:\\n{response}\")\n",
    "            with open(\"failed_dois.txt\", \"a\") as f_fail:\n",
    "                f_fail.write(doi + \"\\n\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6486a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_findings = pd.read_json(NEW_FINDINGS_FILENAME, lines=True)\n",
    "print(f\"Loaded {len(new_findings)} new findings\")\n",
    "\n",
    "new_findings_exploded = new_findings.explode(\"findings\")\n",
    "new_findings_exploded[\"vector\"] = embedder(new_findings_exploded[\"findings\"].tolist()).tolist()\n",
    "new_findings_exploded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save previous iteration and reset df for new results\n",
    "sample_old = sample.copy()\n",
    "\n",
    "# Get new similarity to target\n",
    "sample[\"new_target_similarities\"] = None\n",
    "sample[\"new_hard_similarities\"] = None\n",
    "\n",
    "for idx, row in sample.iterrows():\n",
    "    # For each target doi, compute the max similarity wrt the new embeddings\n",
    "    query_vector = row[\"vector\"]\n",
    "    new_similarities = []\n",
    "    for target_doi in row[\"citation_dois\"]:\n",
    "        target_vectors = get_vectors_by_doi(target_doi)\n",
    "        new_similarities.append(np.max(np.dot(query_vector, target_vectors.T)))\n",
    "    sample.at[idx, \"new_target_similarities\"] = new_similarities\n",
    "\n",
    "    # Collect all the hard vectors, compute the hard similarities\n",
    "    new_hard_similarities = []\n",
    "    for doi in row[\"hard_dois\"]:\n",
    "        candidate_vectors = get_vectors_by_doi(doi)\n",
    "        new_hard_similarities.append(np.max(np.dot(query_vector, candidate_vectors.T)))\n",
    "    sample.at[idx, \"new_hard_similarities\"] = new_hard_similarities\n",
    "\n",
    "compute_margins(\n",
    "    sample, target_col=\"new_target_similarities\", hard_col=\"new_hard_similarities\", margin_col_name=\"new_margins\"\n",
    ")\n",
    "sample.head()\n",
    "\n",
    "diffs = compute_margin_diffs(sample, new_col=\"new_margins\", ref_col=\"old_margins\")\n",
    "print(diffs.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows = sample[sample[\"new_margins\"].apply(lambda margins: any(margin < 0 for margin in margins))]\n",
    "print(f\"Number of rows with negative new margins: {len(error_rows)}\")\n",
    "error_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the target contributions for an error row\n",
    "idx = 0\n",
    "analyze_error_row(idx)\n",
    "\n",
    "\n",
    "def print_target_contributions(idx: int) -> None:\n",
    "    row = error_rows.iloc[idx]\n",
    "    print(\"Original sentence:\")\n",
    "    print(row[\"sent_original\"])\n",
    "\n",
    "    target_dois = row[\"citation_dois\"]\n",
    "    target_records = {\n",
    "        doi: new_findings_exploded[new_findings_exploded[\"doi\"] == doi][\"findings\"] for doi in target_dois\n",
    "    }\n",
    "    pprint(\"Target findings:\")\n",
    "    for doi in target_records:\n",
    "        print(f\"DOI: {doi}\")\n",
    "        for i, finding in enumerate(target_records[doi]):\n",
    "            print(f\"{i}: {finding}\")\n",
    "        print(\"-----\")\n",
    "\n",
    "\n",
    "print(f\"Sentence in context:\\n{error_rows.iloc[idx]['sent_no_cit']}\")\n",
    "print_target_contributions(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d080fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rows.iloc[idx][\"sent_no_cit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = embedder(\n",
    "    [\n",
    "        \"Deep optical images shows a faint elliptical ring structure orbiting the spiral galaxy NGC 5907\",\n",
    "    ]\n",
    ")[0]\n",
    "# query_vector = error_rows.iloc[0][\"vector\"]\n",
    "query_vector = embedder(\n",
    "    [\n",
    "        \"However, deep optical images of a number of spiral galaxies, such as NGC 253, M 83, M 104, NGC 2855, (Malin and Hadley 1997) and NGC 5907 (), do show unusual, faint features in their surroundings.\",\n",
    "    ]\n",
    ")[0]\n",
    "print(f\"Cosine similarity: {query_vector.dot(target_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b60cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_vector = embedder([\"Most extended and complete luminosity function obtained for Galactic bulge to date\"])[0]\n",
    "print(f\"Cosine similarity: {np.dot(hard_vector, query_vector):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e14855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in new_findings_exploded[new_findings_exploded[\"doi\"] == \"10.1086/164480\"].iterrows():\n",
    "    print(f\"Finding {i}:\")\n",
    "    pprint(row[\"findings\"])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
