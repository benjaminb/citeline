{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccc8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metrics import Metric\n",
    "from rank_fuser import RankFuser\n",
    "from statistics_computation import compute_statistics\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "bge_reranker = Metric.get_metric(\"bge_reranker\")\n",
    "# roberta_nli = Metric.get_metric(\"roberta_nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d8412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 100 random lines from the file.\n",
      "Results length: 200\n"
     ]
    }
   ],
   "source": [
    "rf_bge = RankFuser(config={\"bge_reranker\": 1.0})\n",
    "# rf_roberta = RankFuser(config={\"roberta_nli\": 1.0})\n",
    "import random\n",
    "\n",
    "FILE = \"experiments/results/bge_title_search_results.jsonl\"\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# First, count the total number of lines in the file\n",
    "with open(FILE, \"r\") as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "# Randomly select 100 line indices\n",
    "random.seed(42)\n",
    "random_indices = set(random.sample(range(total_lines), SAMPLE_SIZE))\n",
    "\n",
    "# Read only the selected lines\n",
    "data = []\n",
    "with open(FILE, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i in random_indices:\n",
    "            row_data = json.loads(line)\n",
    "            row_data[\"results\"] = row_data[\"results\"][:200]\n",
    "            data.append(row_data)\n",
    "        if len(data) == SAMPLE_SIZE:\n",
    "            break\n",
    "\n",
    "print(f\"Read {len(data)} random lines from the file.\")\n",
    "print(f\"Results length: {len(data[0]['results']) if data else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ef30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_doi                         10.1146/annurev-astro-081811-125615\n",
      "sent_original        2. At lower redshifts, the faint-end slope was...\n",
      "sent_no_cit          2. At lower redshifts, the faint-end slope was...\n",
      "sent_idx                                                           600\n",
      "citation_dois                                       ['10.1086/376841']\n",
      "pubdate                                                       20140801\n",
      "resolved_bibcodes                              ['2003AJ....126.1607S']\n",
      "sent_cit_masked      2. At lower redshifts, the faint-end slope was...\n",
      "expanded_query                                                    None\n",
      "dtype: object\n",
      "Index(['text', 'doi', 'pubdate', 'citation_count', 'metric'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "query = pd.Series(data[0]['record'])\n",
    "results = pd.DataFrame(data[0]['results'])\n",
    "print(query)\n",
    "print(results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70df1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "200\n",
      "-1.468541145324707\n"
     ]
    }
   ],
   "source": [
    "from metrics import Metric\n",
    "bge_metric = Metric.get_metric(\"bge_reranker\")\n",
    "scores = bge_metric(query, results)\n",
    "print(type(scores))\n",
    "print(len(scores))\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c967282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reranking results: 100%|██████████| 100/100 [05:51<00:00,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "reranked = rf_bge.rerank(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed410f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = compute_statistics(reranked)\n",
    "print(stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['hitrate'][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc824c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hitrate, iou, and recall on the same plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(stats['hitrate'], label='Hitrate')\n",
    "plt.plot(stats['iou'], label='IoU')\n",
    "plt.plot(stats['recall'], label='Recall')\n",
    "plt.xlabel('Query')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Hitrate, IoU, and Recall')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20525573",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_stats = compute_statistics(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot original_stats['hitrate'] against stats['hitrate']\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(original_stats['hitrate'], label='Original Hitrate')\n",
    "plt.plot(stats['hitrate'], label='Reranked Hitrate')\n",
    "plt.xlabel('Query')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Original vs Reranked Hitrate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91595f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
