{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a736c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Rerankers import entailment_ranker\n",
    "from Embedders import get_embedder\n",
    "from database.database import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6d565cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================CONFIG=================================\n",
      "Database         User             Host                             Port            \n",
      "citeline_db      bbasseri         localhost                        5432            \n",
      "========================================================================\n",
      "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "examples = pd.read_json('data/dataset/100/nontrivial.jsonl', lines=True)\n",
    "db = Database()\n",
    "db.test_connection()\n",
    "\n",
    "bge_embedder = get_embedder('BAAI/bge-small-en', device='mps', normalize=True)\n",
    "roberta_reranker = entailment_ranker(model_name=\"cross-encoder/nli-roberta-base\", device='mps')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1443baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_of_target(query_results, target_doi: str) -> int:\n",
    "    \"\"\"\n",
    "    Get the index of the target DOI in the query results.\n",
    "    :param query_results: The query results from the database.\n",
    "    :param target_doi: The DOI of the target paper.\n",
    "    :return: The index of the target DOI in the query results.\n",
    "    \"\"\"\n",
    "    for i, result in enumerate(query_results):\n",
    "        if result.doi == target_doi:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ea51d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "initial_results = []\n",
    "for index, example in examples.iterrows():\n",
    "    print(index)\n",
    "    if index == 15:\n",
    "        break\n",
    "\n",
    "    input_sentence = example['sent_no_cit']\n",
    "    target_doi = example['citation_dois'][0]\n",
    "    pubdate = example['pubdate']\n",
    "\n",
    "    embedding = bge_embedder(input_sentence)\n",
    "    query_results = db.query_vector_column(\n",
    "        query_vector=embedding,\n",
    "        table_name='lib',\n",
    "        target_column='bge_norm',\n",
    "        pubdate=pubdate,\n",
    "        top_k=10_000,\n",
    "        probes=30,\n",
    "        explain=False,\n",
    "    )\n",
    "\n",
    "    target_index = get_index_of_target(query_results, target_doi)\n",
    "    initial_results.append({'example_index': index, 'target_rank': target_index, \"query_results\": query_results})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a061ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Index 0 didn't retrieve its target DOI at this top k/probes level\n",
      "1\n",
      "Reranking took 332.82916021347046 seconds\n",
      "2\n",
      "Reranking took 322.01701307296753 seconds\n",
      "3\n",
      "Reranking took 403.6238911151886 seconds\n",
      "4\n",
      "Reranking took 489.87950110435486 seconds\n",
      "5\n",
      "Reranking took 428.43002486228943 seconds\n",
      "6\n",
      "Reranking took 390.4660520553589 seconds\n",
      "7\n",
      "Reranking took 443.9020359516144 seconds\n",
      "8\n",
      "Index 8 didn't retrieve its target DOI at this top k/probes level\n",
      "9\n",
      "Reranking took 473.3110861778259 seconds\n",
      "10\n",
      "Index 10 didn't retrieve its target DOI at this top k/probes level\n",
      "11\n",
      "Index 11 didn't retrieve its target DOI at this top k/probes level\n",
      "12\n",
      "Reranking took 510.01005816459656 seconds\n",
      "13\n",
      "Reranking took 385.608925819397 seconds\n",
      "14\n",
      "Index 14 didn't retrieve its target DOI at this top k/probes level\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "# Iterate over all the initial results\n",
    "for i, result in enumerate(initial_results):\n",
    "    print(i)\n",
    "    if i == 15:\n",
    "        break\n",
    "\n",
    "    # Make sure you have a valid target to rerank\n",
    "    if result['target_rank'] < 0:\n",
    "        print(f\"Index {i} didn't retrieve its target DOI at this top k/probes level\")\n",
    "        continue\n",
    "\n",
    "    target_doi = examples.iloc[i].citation_dois[0]\n",
    "    input_sentence = examples.iloc[i].sent_no_cit\n",
    "    query_results = result['query_results']\n",
    "    reranked_query_results = query_results.copy()\n",
    "    start = time()\n",
    "    reranked_query_results.sort(key=lambda q: roberta_reranker(q.chunk, input_sentence), reverse=True)\n",
    "    end = time()\n",
    "    print(f\"Reranking took {end - start} seconds\")\n",
    "    reranked_rank = get_index_of_target(reranked_query_results, target_doi)\n",
    "\n",
    "    result['rerank'] = reranked_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b93fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rank: 510, Reranked rank: 340\n",
      "Original rank: 6319, Reranked rank: 220\n",
      "Original rank: 1893, Reranked rank: 3304\n",
      "Original rank: 0, Reranked rank: 27\n",
      "Original rank: 24, Reranked rank: 236\n",
      "Original rank: 0, Reranked rank: 120\n",
      "Original rank: 480, Reranked rank: 80\n",
      "Original rank: 459, Reranked rank: 185\n",
      "Original rank: 5, Reranked rank: 3\n",
      "Original rank: 1, Reranked rank: 40\n",
      "Average rank improvement: 513.6\n"
     ]
    }
   ],
   "source": [
    "diffs = []\n",
    "for result in initial_results:\n",
    "    if 'rerank' in result:\n",
    "        print(f\"Original rank: {result['target_rank']}, Reranked rank: {result['rerank']}\")\n",
    "        diffs.append(result['target_rank'] - result['rerank'])\n",
    "print(f\"Average rank improvement: {sum(diffs) / len(diffs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce410c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
