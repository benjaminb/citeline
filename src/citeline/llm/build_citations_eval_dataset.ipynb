{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9555c1c",
   "metadata": {},
   "source": [
    "This notebook reads in nontrivial examples from the full JSONL file and creates a subsample for the purpose of evolving the citation generation prompt.\n",
    "\n",
    "The dataset on which to evaluate the citation gen prompt consists of:\n",
    "* The subsample of examples (100 rows) with their embeddings (Qwen 0.6B, for quality + efficiency)\n",
    "* A list of the unique DOIs cited by this subsample\n",
    "\n",
    "Each iteration of prompt engineering will run the target DOIs through the citation generation LLM invocation using the current state of the prompt. This then generates a collection of 'contributions' which must also be embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from database.milvusdb import MilvusDB\n",
    "from embedders import Embedder\n",
    "\n",
    "db = MilvusDB()\n",
    "db.list_collections()\n",
    "\n",
    "# Set up query and document embedding models\n",
    "query_embedder = Embedder.create(model_name=\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True, for_queries=True)\n",
    "document_embedder = Embedder.create(\n",
    "    model_name=\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True, for_queries=False\n",
    ")\n",
    "document_embedder.model = (\n",
    "    query_embedder.model\n",
    ")  # Set the same underlying model since this model's query vs. doc behavior can switch dynamically\n",
    "print(f\"Query embedder: {query_embedder}\")\n",
    "print(f\"Document embedder: {document_embedder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fec376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataset of 100 samples randomly selected from all samples\n",
    "examples = pd.read_json(\"../data/dataset/nontrivial_checked.jsonl\", lines=True)\n",
    "examples = examples.sample(n=100, random_state=42)\n",
    "examples[\"embedding\"] = examples[\"sent_no_cit\"].apply(lambda x: query_embedder([x])[0])\n",
    "examples.to_parquet(\"citation_gen_examples.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
