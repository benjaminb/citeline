{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from embedders import Embedder\n",
    "from database.milvusdb import MilvusDB\n",
    "from query_expander import get_expander\n",
    "\n",
    "tqdm.pandas()\n",
    "embedder = Embedder.create(\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True, for_queries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8440b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_EXPANSION = 'add_prev_3'\n",
    "\n",
    "# from compute_difference_vector import get_sample_df\n",
    "# samples = get_sample_df(14000, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37b2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query expansion: QueryExpander(name=add_prev_3, data_length=2980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6367/14735 [08:56<23:18,  5.98it/s]  "
     ]
    }
   ],
   "source": [
    "examples = pd.read_json(\"data/dataset/nontrivial_checked.jsonl\", lines=True)\n",
    "expander = get_expander(QUERY_EXPANSION, path_to_data=\"data/preprocessed/reviews.jsonl\")\n",
    "print(f\"Using query expansion: {expander}\")\n",
    "examples[\"sent_no_cit\"] = expander(examples)\n",
    "\n",
    "# Add vector column to examples\n",
    "examples[\"vector\"] = examples.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "# Denormalize on citation_dois (targets)\n",
    "examples = examples.explode(\"citation_dois\", ignore_index=True)\n",
    "print(f\"Number of samples after denormalization: {examples.shape[0]}\")\n",
    "examples.rename(columns={\"citation_dois\": \"target_doi\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3503524",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20873655",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MilvusDB()\n",
    "def most_similar_to_query(example: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes in an example (with 'vector' column already set), and from the candidates\n",
    "    (returned entities with that doi from the database), returns the vector most similar\n",
    "    to the example's vector.\n",
    "\n",
    "    \"\"\"\n",
    "    # Converts 'vector' column to rows * dim array, holding the candidate vectors\n",
    "    candidates = db.select_by_doi(example.target_doi, collection_name=\"qwen06_chunks\")\n",
    "    candidate_vectors = np.stack(candidates[\"vector\"])\n",
    "    best_idx = np.argmax(np.dot(candidate_vectors, example[\"vector\"]))\n",
    "    best_vector = candidate_vectors[best_idx]\n",
    "    return best_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array(samples['vector'].tolist()).T\n",
    "\n",
    "V = np.array([most_similar_to_query(row) for _, row in tqdm(samples.iterrows(), total=len(samples))]).T\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"V shape:\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eceaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "M = V @ Q.T\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.heatmap(M, cmap=\"coolwarm\", center=0, cbar_kws={\"label\": \"value\"})  # center=0 for diverging data\n",
    "plt.title(\"Matrix heatmap (seaborn)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_seaborn.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U, S, Vt = np.linalg.svd(M)\n",
    "R = U @ Vt\n",
    "\n",
    "print(\"det R:\", np.linalg.det(R))\n",
    "# if np.linalg.det(R) < 0:\n",
    "#     D = np.eye(R.shape[0])\n",
    "#     D[-1, -1] = -1\n",
    "#     R = U @ D @ Vt\n",
    "# print(\"corrected det R:\", np.linalg.det(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f79138",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dois = set(samples.target_doi)\n",
    "print(research_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef08937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def negative_vectors(example: pd.Series, n=5):\n",
    "    # Get all target DOIs for this example, sample from those not cited\n",
    "    rows = samples[(samples.source_doi == example.source_doi) & (samples.sent_idx == example.sent_idx)]\n",
    "    citation_dois = set(rows.target_doi)\n",
    "    neg_dois = list(research_dois - citation_dois)\n",
    "    neg_samples = random.sample(neg_dois, n)\n",
    "    \n",
    "    # Get vectors for negative samples\n",
    "    neg_vectors = np.zeros((n, embedder.dim))\n",
    "    for i, doi in enumerate(neg_samples):\n",
    "        records = db.select_by_doi(doi, collection_name=\"qwen06_chunks\")\n",
    "        sample_record = records.sample(n=1).iloc[0]\n",
    "        neg_vectors[i] = np.array(sample_record['vector'])\n",
    "    return neg_vectors\n",
    "\n",
    "\n",
    "res = negative_vectors(samples.iloc[998])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8d5e8",
   "metadata": {},
   "source": [
    "Citation DOIs: {'10.1046/j.1365-8711.2000.03810.x', '10.1086/316394', '10.1086/186883'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed0ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.select_by_doi(\"10.1046/j.1365-8711.2000.03810.x\", collection_name=\"qwen06_chunks\")\n",
    "row = df.sample(n=1).iloc[0]\n",
    "print(np.array(row['vector']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_to_target = []\n",
    "differences_to_negative = []\n",
    "for _, row in samples.iterrows():\n",
    "    query_vector = row['vector']\n",
    "    target_vector = most_similar_to_query(row)\n",
    "    aligned_query_vector = R @ query_vector\n",
    "    before = cosine_similarity(query_vector, target_vector)\n",
    "    after = cosine_similarity(aligned_query_vector, target_vector)\n",
    "\n",
    "    differences_to_target.append(after - before)\n",
    "    neg_vectors = negative_vectors(row, n=5)\n",
    "    batch_distance_to_negative = []\n",
    "    for neg_vector in neg_vectors:\n",
    "        before_neg = cosine_similarity(query_vector, neg_vector)\n",
    "        after_neg = cosine_similarity(aligned_query_vector, neg_vector)\n",
    "        batch_distance_to_negative.append(after_neg - before_neg)\n",
    "        differences_to_negative.append(after_neg - before_neg)\n",
    "    print(_)\n",
    "    print(f\"Improvement to target: {after - before:.4f}\")\n",
    "    print(f\"Distance to negatives: {np.mean(batch_distance_to_negative):.4f} ± {np.std(batch_distance_to_negative):.4f}\")\n",
    "    print(\"---\")\n",
    "print(f\"Average improvement (target): {np.mean(differences_to_target):.6f} ± {np.std(differences_to_target):.6f}\")\n",
    "print(f\"Average improvement (negative): {np.mean(differences_to_negative):.6f} ± {np.std(differences_to_negative):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555eda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U, S, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "print(\"rank approx:\", np.sum(S > 1e-8))\n",
    "print(\"singular values (top/last):\", S[:30], S[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "U, S, Vt = np.linalg.svd(M)\n",
    "print(\"U shape:\", U.shape)\n",
    "print(\"S shape:\", S.shape)\n",
    "print(\"Vt shape:\", Vt.shape)\n",
    "print(\"Vt_trunc shape:\", Vt[:1, :].shape)\n",
    "print(\"S_trunc shape:\", S[:1].shape)\n",
    "print(\"U_trunc shape:\", U[:, 0:1].shape)\n",
    "trunc = U[:, 0:1] @ (S[:1] * Vt[0:1, :])\n",
    "print(\"trunc shape:\", trunc.shape)\n",
    "print(\"trunc rank:\", np.linalg.matrix_rank(trunc))\n",
    "print(trunc)\n",
    "\n",
    "\n",
    "plt.semilogy(S[:20])  # plot singular values\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.heatmap(trunc, cmap=\"coolwarm\", center=0, cbar_kws={\"label\": \"value\"})  # center=0 for diverging data\n",
    "plt.title(\"Matrix heatmap (seaborn)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc335e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qwen06_chunks_rotation_n2000.npy', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db1ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465499ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = S[0]\n",
    "eps = 1e-6  # try 1e-6 .. 1e-8 as needed\n",
    "r = 50\n",
    "# r = np.searchsorted(S / sigma1 < eps, True)  # first index where ratio < eps\n",
    "print(f\"Chosen rank r: {r}\")\n",
    "if r == 0:\n",
    "    r = len(S)  # fallback if no small ones found\n",
    "# alternative: r = np.searchsorted(np.cumsum(S**2) / np.sum(S**2), 0.99) + 1\n",
    "\n",
    "# build small rotation in top-r\n",
    "Ur = U[:, :r]  # n x r\n",
    "Vr = Vt[:r, :].T  # n x r  (since Vt[:r,:] is r x n)\n",
    "Msmall = Ur.T @ M @ Vr  # should be r x r but simpler compute: Tproj.T @ Qproj if you had them\n",
    "# simpler: compute r x r cross-covariance directly via projections:\n",
    "# Qproj = Q_all @ Ur  # expensive if many, but doable; here we reuse M decomposition\n",
    "# but we can use SVD of the small Mslice: compute Us, Ss, Vts = svd(Ur.T @ M @ Vr)\n",
    "\n",
    "# directly SVD the r x r matrix (numerically stable):\n",
    "Us, Ss, Vts = np.linalg.svd(Ur.T @ M @ Vr, full_matrices=False)\n",
    "Rsmall = Us @ Vts\n",
    "# ensure proper rotation (det +1)\n",
    "if np.linalg.det(Rsmall) < 0:\n",
    "    D = np.eye(r)\n",
    "    D[-1, -1] = -1\n",
    "    Rsmall = Us @ D @ Vts\n",
    "\n",
    "# map basis Ur to rotated basis Ur @ Rsmall @ Ur.T, then add identity on complement\n",
    "R_full = Ur @ Rsmall @ Ur.T + (np.eye(1024) - Ur @ Ur.T)\n",
    "print(\"det R_full:\", np.linalg.det(R_full))\n",
    "print(R_full.shape)\n",
    "print(R_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qwen06_chunks_r50.npy', R_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee21cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
