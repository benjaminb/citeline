{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aec98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from citeline.embedders import Embedder\n",
    "from database.milvusdb import MilvusDB\n",
    "from citeline.query_expander import get_expander\n",
    "\n",
    "tqdm.pandas()\n",
    "embedder = Embedder.create(\"Qwen/Qwen3-Embedding-0.6B\", device=\"mps\", normalize=True, for_queries=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8440b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_EXPANSION = 'add_prev_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b37b2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query expansion: QueryExpander(name=add_prev_3, data_length=2980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14735/14735 [18:30<00:00, 13.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after denormalization: 18801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "examples = pd.read_json(\"data/dataset/nontrivial_checked.jsonl\", lines=True)\n",
    "expander = get_expander(QUERY_EXPANSION, path_to_data=\"data/preprocessed/reviews.jsonl\")\n",
    "print(f\"Using query expansion: {expander}\")\n",
    "examples[\"sent_no_cit\"] = expander(examples)\n",
    "\n",
    "# Add vector column to examples\n",
    "examples[\"vector\"] = examples.progress_apply(lambda row: embedder([row[\"sent_no_cit\"]])[0], axis=1)\n",
    "\n",
    "# Denormalize on citation_dois (targets)\n",
    "examples = examples.explode(\"citation_dois\", ignore_index=True)\n",
    "print(f\"Number of samples after denormalization: {examples.shape[0]}\")\n",
    "examples.rename(columns={\"citation_dois\": \"target_doi\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3503524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>target_doi</th>\n",
       "      <th>pubdate</th>\n",
       "      <th>resolved_bibcodes</th>\n",
       "      <th>sent_cit_masked</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.newar.2024.101694</td>\n",
       "      <td>Subsequently, Andrews et al. (2017) selected a...</td>\n",
       "      <td>1 pc. Similar separation distributions had bee...</td>\n",
       "      <td>58</td>\n",
       "      <td>10.1093/mnras/stx2000</td>\n",
       "      <td>20240601</td>\n",
       "      <td>[2017MNRAS.472..675A]</td>\n",
       "      <td>Subsequently, [REF] selected a wide binary can...</td>\n",
       "      <td>[-0.013162542, -0.09026443, -0.0120118465, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1016/j.newar.2024.101694</td>\n",
       "      <td>Andrews et al. (2017) investigated how the sep...</td>\n",
       "      <td>Subsequently, Andrews et al. (2017) selected a...</td>\n",
       "      <td>61</td>\n",
       "      <td>10.1093/mnras/stx2000</td>\n",
       "      <td>20240601</td>\n",
       "      <td>[2017MNRAS.472..675A]</td>\n",
       "      <td>[REF] investigated how the separation of their...</td>\n",
       "      <td>[-0.07659445, -0.064264126, -0.007819046, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1016/j.newar.2024.101694</td>\n",
       "      <td>This led Andrews et al. (2017) to conclude tha...</td>\n",
       "      <td>Andrews et al. (2017) investigated how the sep...</td>\n",
       "      <td>64</td>\n",
       "      <td>10.1093/mnras/stx2000</td>\n",
       "      <td>20240601</td>\n",
       "      <td>[2017MNRAS.472..675A]</td>\n",
       "      <td>This led [REF] to conclude that most of the pa...</td>\n",
       "      <td>[-0.041363332, -0.067232065, -0.00943872, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.newar.2024.101694</td>\n",
       "      <td>It may also owe in part to the mass ratio dist...</td>\n",
       "      <td>The sample contains 97 resolved WD+MS binaries...</td>\n",
       "      <td>90</td>\n",
       "      <td>10.1093/mnras/stz2480</td>\n",
       "      <td>20240601</td>\n",
       "      <td>[2019MNRAS.489.5822E]</td>\n",
       "      <td>It may also owe in part to the mass ratio dist...</td>\n",
       "      <td>[-0.04453195, -0.07250524, -0.009316281, 0.052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1016/j.newar.2024.101694</td>\n",
       "      <td>Hwang et al. (2022c) used a related method to ...</td>\n",
       "      <td>This approach forward-models the distribution ...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.3847/2041-8213/ac7c70</td>\n",
       "      <td>20240601</td>\n",
       "      <td>[2022ApJ...933L..32H]</td>\n",
       "      <td>[REF] used a related method to study the eccen...</td>\n",
       "      <td>[-0.04475006, -0.01653341, -0.007177436, 0.053...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source_doi  \\\n",
       "0  10.1016/j.newar.2024.101694   \n",
       "1  10.1016/j.newar.2024.101694   \n",
       "2  10.1016/j.newar.2024.101694   \n",
       "3  10.1016/j.newar.2024.101694   \n",
       "4  10.1016/j.newar.2024.101694   \n",
       "\n",
       "                                       sent_original  \\\n",
       "0  Subsequently, Andrews et al. (2017) selected a...   \n",
       "1  Andrews et al. (2017) investigated how the sep...   \n",
       "2  This led Andrews et al. (2017) to conclude tha...   \n",
       "3  It may also owe in part to the mass ratio dist...   \n",
       "4  Hwang et al. (2022c) used a related method to ...   \n",
       "\n",
       "                                         sent_no_cit  sent_idx  \\\n",
       "0  1 pc. Similar separation distributions had bee...        58   \n",
       "1  Subsequently, Andrews et al. (2017) selected a...        61   \n",
       "2  Andrews et al. (2017) investigated how the sep...        64   \n",
       "3  The sample contains 97 resolved WD+MS binaries...        90   \n",
       "4  This approach forward-models the distribution ...       110   \n",
       "\n",
       "                 target_doi   pubdate      resolved_bibcodes  \\\n",
       "0     10.1093/mnras/stx2000  20240601  [2017MNRAS.472..675A]   \n",
       "1     10.1093/mnras/stx2000  20240601  [2017MNRAS.472..675A]   \n",
       "2     10.1093/mnras/stx2000  20240601  [2017MNRAS.472..675A]   \n",
       "3     10.1093/mnras/stz2480  20240601  [2019MNRAS.489.5822E]   \n",
       "4  10.3847/2041-8213/ac7c70  20240601  [2022ApJ...933L..32H]   \n",
       "\n",
       "                                     sent_cit_masked  \\\n",
       "0  Subsequently, [REF] selected a wide binary can...   \n",
       "1  [REF] investigated how the separation of their...   \n",
       "2  This led [REF] to conclude that most of the pa...   \n",
       "3  It may also owe in part to the mass ratio dist...   \n",
       "4  [REF] used a related method to study the eccen...   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.013162542, -0.09026443, -0.0120118465, -0....  \n",
       "1  [-0.07659445, -0.064264126, -0.007819046, 0.00...  \n",
       "2  [-0.041363332, -0.067232065, -0.00943872, 0.03...  \n",
       "3  [-0.04453195, -0.07250524, -0.009316281, 0.052...  \n",
       "4  [-0.04475006, -0.01653341, -0.007177436, 0.053...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20873655",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MilvusDB()\n",
    "def most_similar_to_query(example: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes in an example (with 'vector' column already set), and from the candidates\n",
    "    (returned entities with that doi from the database), returns the vector most similar\n",
    "    to the example's vector.\n",
    "\n",
    "    \"\"\"\n",
    "    # Converts 'vector' column to rows * dim array, holding the candidate vectors\n",
    "    candidates = db.select_by_doi(example.target_doi, collection_name=\"qwen06_chunks\")\n",
    "    candidate_vectors = np.stack(candidates[\"vector\"])\n",
    "    best_idx = np.argmax(np.dot(candidate_vectors, example[\"vector\"]))\n",
    "    best_vector = candidate_vectors[best_idx]\n",
    "    return best_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3da4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array(examples['vector'].tolist()).T\n",
    "\n",
    "V = np.array([most_similar_to_query(row) for _, row in tqdm(examples.iterrows(), total=len(examples))]).T\n",
    "print(\"Q shape:\", Q.shape)\n",
    "print(\"V shape:\", V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eceaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "M = V @ Q.T\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.heatmap(M, cmap=\"coolwarm\", center=0, cbar_kws={\"label\": \"value\"})  # center=0 for diverging data\n",
    "plt.title(\"Matrix heatmap (seaborn)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap_seaborn.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "U, S, Vt = np.linalg.svd(M)\n",
    "R = U @ Vt\n",
    "\n",
    "print(\"det R:\", np.linalg.det(R))\n",
    "# if np.linalg.det(R) < 0:\n",
    "#     D = np.eye(R.shape[0])\n",
    "#     D[-1, -1] = -1\n",
    "#     R = U @ D @ Vt\n",
    "# print(\"corrected det R:\", np.linalg.det(R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rank approx:\", np.sum(S > 1e-8))\n",
    "print(\"singular values (top/last):\", S[:30], S[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f79138",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_dois = set(examples.target_doi)\n",
    "print(research_dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef08937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "def negative_vectors(example: pd.Series, n=5):\n",
    "    # Get all target DOIs for this example, sample from those not cited\n",
    "    rows = examples[(examples.source_doi == example.source_doi) & (examples.sent_idx == example.sent_idx)]\n",
    "    citation_dois = set(rows.target_doi)\n",
    "    neg_dois = list(research_dois - citation_dois)\n",
    "    neg_samples = random.sample(neg_dois, n)\n",
    "    \n",
    "    # Get vectors for negative samples\n",
    "    neg_vectors = np.zeros((n, embedder.dim))\n",
    "    for i, doi in enumerate(neg_samples):\n",
    "        records = db.select_by_doi(doi, collection_name=\"qwen06_chunks\")\n",
    "        sample_record = records.sample(n=1).iloc[0]\n",
    "        neg_vectors[i] = np.array(sample_record['vector'])\n",
    "    return neg_vectors\n",
    "\n",
    "\n",
    "res = negative_vectors(examples.iloc[998])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8d5e8",
   "metadata": {},
   "source": [
    "Citation DOIs: {'10.1046/j.1365-8711.2000.03810.x', '10.1086/316394', '10.1086/186883'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_to_target = []\n",
    "differences_to_negative = []\n",
    "for _, row in examples.iterrows():\n",
    "    query_vector = row['vector']\n",
    "    target_vector = most_similar_to_query(row)\n",
    "    aligned_query_vector = R @ query_vector\n",
    "    before = cosine_similarity(query_vector, target_vector)\n",
    "    after = cosine_similarity(aligned_query_vector, target_vector)\n",
    "\n",
    "    differences_to_target.append(after - before)\n",
    "    neg_vectors = negative_vectors(row, n=5)\n",
    "    batch_distance_to_negative = []\n",
    "    for neg_vector in neg_vectors:\n",
    "        before_neg = cosine_similarity(query_vector, neg_vector)\n",
    "        after_neg = cosine_similarity(aligned_query_vector, neg_vector)\n",
    "        batch_distance_to_negative.append(after_neg - before_neg)\n",
    "        differences_to_negative.append(after_neg - before_neg)\n",
    "    print(_)\n",
    "    print(f\"Improvement to target: {after - before:.4f}\")\n",
    "    print(f\"Distance to negatives: {np.mean(batch_distance_to_negative):.4f} ± {np.std(batch_distance_to_negative):.4f}\")\n",
    "    print(\"---\")\n",
    "print(f\"Average improvement (target): {np.mean(differences_to_target):.6f} ± {np.std(differences_to_target):.6f}\")\n",
    "print(f\"Average improvement (negative): {np.mean(differences_to_negative):.6f} ± {np.std(differences_to_negative):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# U, S, Vt = np.linalg.svd(M)\n",
    "# print(\"U shape:\", U.shape)\n",
    "# print(\"S shape:\", S.shape)\n",
    "# print(\"Vt shape:\", Vt.shape)\n",
    "# print(\"Vt_trunc shape:\", Vt[:1, :].shape)\n",
    "# print(\"S_trunc shape:\", S[:1].shape)\n",
    "# print(\"U_trunc shape:\", U[:, 0:1].shape)\n",
    "# trunc = U[:, 0:1] @ (S[:1] * Vt[0:1, :])\n",
    "# print(\"trunc shape:\", trunc.shape)\n",
    "# print(\"trunc rank:\", np.linalg.matrix_rank(trunc))\n",
    "# print(trunc)\n",
    "\n",
    "\n",
    "plt.semilogy(S)  # plot singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc335e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qwen06_chunks_rotation_n2000.npy', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db1ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465499ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1 = S[0]\n",
    "eps = 1e-6  # try 1e-6 .. 1e-8 as needed\n",
    "r = 50\n",
    "# r = np.searchsorted(S / sigma1 < eps, True)  # first index where ratio < eps\n",
    "print(f\"Chosen rank r: {r}\")\n",
    "if r == 0:\n",
    "    r = len(S)  # fallback if no small ones found\n",
    "# alternative: r = np.searchsorted(np.cumsum(S**2) / np.sum(S**2), 0.99) + 1\n",
    "\n",
    "# build small rotation in top-r\n",
    "Ur = U[:, :r]  # n x r\n",
    "Vr = Vt[:r, :].T  # n x r  (since Vt[:r,:] is r x n)\n",
    "Msmall = Ur.T @ M @ Vr  # should be r x r but simpler compute: Tproj.T @ Qproj if you had them\n",
    "# simpler: compute r x r cross-covariance directly via projections:\n",
    "# Qproj = Q_all @ Ur  # expensive if many, but doable; here we reuse M decomposition\n",
    "# but we can use SVD of the small Mslice: compute Us, Ss, Vts = svd(Ur.T @ M @ Vr)\n",
    "\n",
    "# directly SVD the r x r matrix (numerically stable):\n",
    "Us, Ss, Vts = np.linalg.svd(Ur.T @ M @ Vr, full_matrices=False)\n",
    "Rsmall = Us @ Vts\n",
    "# ensure proper rotation (det +1)\n",
    "if np.linalg.det(Rsmall) < 0:\n",
    "    D = np.eye(r)\n",
    "    D[-1, -1] = -1\n",
    "    Rsmall = Us @ D @ Vts\n",
    "\n",
    "# map basis Ur to rotated basis Ur @ Rsmall @ Ur.T, then add identity on complement\n",
    "R_full = Ur @ Rsmall @ Ur.T + (np.eye(1024) - Ur @ Ur.T)\n",
    "print(\"det R_full:\", np.linalg.det(R_full))\n",
    "print(R_full.shape)\n",
    "print(R_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f35ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qwen06_chunks_fullR.npy', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee21cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = Vt[0, :]\n",
    "u1 = U[:, 0]\n",
    "print(\"v1 shape:\", v1.shape)\n",
    "print(\"u1 shape:\", u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = np.stack(examples['vector'].to_numpy())\n",
    "print(\"query_vectors shape:\", query_vectors.shape)\n",
    "X = np.dot(v1, query_vectors.T)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73227a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vectors = np.stack([most_similar_to_query(row) for _, row in tqdm(examples.iterrows(), total=len(examples))])\n",
    "Y = np.dot(u1, target_vectors.T)\n",
    "print(Y.shape)\n",
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dff2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
