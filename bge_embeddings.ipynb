{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with NVIDIA's model\n",
    "\n",
    "A `SentenceTransformer` model instantiated from `NVIDIA-Embed-v2` will return tensors or np arrays but can only take a string input or a list containing a single string. It cannot accept a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b2d1fc65e941569971ebcfd2ff34d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 32768, 'do_lower_case': False}) with Transformer model: MistralModel \n",
      "  (1): Pooling({'word_embedding_dimension': 4096, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': True, 'include_prompt': True})\n",
      ")\n",
      "Batch embeddings shape: torch.Size([3, 4096])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model_name = \"BAAI/bge-en-icl\"\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "device = 'cpu' # mps was producing a dimension error on batch input to model.encode \n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer(\n",
    "    model_name, trust_remote_code=True, device=device)\n",
    "print(model)\n",
    "\n",
    "# Encoding a list of strings\n",
    "try:\n",
    "    embeddings = model.encode(\n",
    "        sentences, convert_to_tensor=True, normalize_embeddings=False)\n",
    "    print(f\"Batch embeddings shape: {embeddings.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chromadb.api.client.Client object at 0x32afda6d0>\n",
      "Return object type: <class 'list'>\n",
      "Inner object type: <class 'numpy.ndarray'>\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "client = chromadb.PersistentClient(path='./vector_stores/bge/')\n",
    "print(client)\n",
    "\n",
    "# Set up embedding model\n",
    "class BgeChromaEmbedder(EmbeddingFunction):\n",
    "    def __init__(self, embedding_fn):\n",
    "        self._encode = embedding_fn\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return self._encode(input)\n",
    "\n",
    "embedding_lambda = lambda docs: model.encode(docs, convert_to_numpy=True, normalize_embeddings=False)\n",
    "\n",
    "embedder = BgeChromaEmbedder(embedding_lambda)\n",
    "result = embedder(['hi there', 'hello world'])\n",
    "print(f\"Return object type: {type(result)}\")\n",
    "print(f\"Inner object type: {type(result[0])}\")\n",
    "print(result[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Earth_Science_Research', 'Planetary_Research', 'Astro_Research'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['documents', 'metadatas', 'ids'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "METRICS = ['l2', 'cosine', 'ip']\n",
    "PATH_TO_DATA = 'data/processed_for_chroma/research'\n",
    "FILENAMES = os.listdir(PATH_TO_DATA)\n",
    "data = dict()\n",
    "\n",
    "for filename in FILENAMES:\n",
    "    with open(f'{PATH_TO_DATA}/{filename}', 'r') as file:\n",
    "        data[os.path.splitext(os.path.basename(filename))[0]] = json.load(file)\n",
    "\n",
    "print(data.keys())\n",
    "data['Astro_Research'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of doc string: 218019\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "doc = data['Astro_Research']['documents'][0]\n",
    "print(f\"Length of doc string: {len(doc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.3989852 , -0.89258695, -1.0513442 , ..., -1.9740007 ,\n",
      "       -0.8036554 ,  2.7621977 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "res = embedder(doc[:50])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All collections have been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Reset collections\n",
    "collections = client.list_collections()\n",
    "\n",
    "# Delete each collection\n",
    "for collection in collections:\n",
    "    client.delete_collection(name=collection.name)\n",
    "\n",
    "print(\"All collections have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.create_collection(\n",
    "    name='testing-insert',\n",
    "    embedding_function=embedder,\n",
    "    metadata={\"hnsw:space\": 'l2'}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=data['Astro_Research']['documents'][0:1],\n",
    "    metadatas=data['Astro_Research']['metadatas'][0:1],\n",
    "    ids=data['Astro_Research']['ids'][0:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_INCREMENT = 10\n",
    "\n",
    "for metric in METRICS:\n",
    "    clean_model_name = model_name.replace('/', '-')\n",
    "    collection_name = f\"{clean_model_name}_{metric}_no-norm\"\n",
    "    print(f\"Creating collection: {collection_name}...\")\n",
    "\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        embedding_function=embedder,\n",
    "        metadata={\"hnsw:space\": metric}\n",
    "    )\n",
    "    for journal, records in data.items():\n",
    "        print(f\"  Adding {journal} records...\")\n",
    "\n",
    "        # Add records 10 at a time\n",
    "        for i in range(len(records['documents']) // ADD_INCREMENT):\n",
    "            s = slice(i*ADD_INCREMENT, (i+1)*ADD_INCREMENT, 1)\n",
    "            collection.add(\n",
    "                documents=records['documents'][s],\n",
    "                metadatas=records['metadatas'][s],\n",
    "                ids=records['ids'][s]\n",
    "            )\n",
    "    print(f\"Finished {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the dimensionality of the embeddings\n",
    "collection = client.get_collection(name=f\"{model_name}_cosine_no-norm\")\n",
    "chroma_embedding = collection.query(\n",
    "    query_texts=[\"the sun is a star\"],\n",
    "    n_results=1,\n",
    "    include=[\"embeddings\", \"documents\"]\n",
    ")\n",
    "\n",
    "print(type(chroma_embedding['embeddings']))\n",
    "print(type(chroma_embedding['embeddings'][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
