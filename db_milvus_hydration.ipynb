{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c6c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymilvus import connections, MilvusClient, DataType, Collection\n",
    "from embedders import get_embedder\n",
    "from database.database import Database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc190bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: <pymilvus.milvus_client.milvus_client.MilvusClient object at 0x104ef54d0>\n",
      "<Collection>:\n",
      "-------------\n",
      "<name>: contributions\n",
      "<description>: \n",
      "<schema>: {'auto_id': True, 'description': '', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 2048}}, {'name': 'doi', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 64}}, {'name': 'pubdate', 'description': '', 'type': <DataType.INT64: 5>}, {'name': 'astrollama', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 4096}}], 'enable_dynamic_field': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "client = MilvusClient(alias=\"default\")\n",
    "print(f\"Client: {client}\")\n",
    "collection = Collection(name=\"contributions\")\n",
    "print(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5382929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8388d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pg database client\n",
    "db = Database()\n",
    "db.test_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ccdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the collection if it doesn't exist\n",
    "\n",
    "COLLECTION_NAME = \"contributions\"\n",
    "if not client.has_collection(collection_name=COLLECTION_NAME):\n",
    "    print(f\"Collection '{COLLECTION_NAME}' does not exist. Creating it.\")\n",
    "    schema = client.create_schema(\n",
    "        auto_id=True,\n",
    "        enable_dynamic_field=True\n",
    "    )\n",
    "    schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n",
    "    schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=2048)\n",
    "    schema.add_field(field_name=\"doi\", datatype=DataType.VARCHAR, max_length=64)\n",
    "    schema.add_field(field_name=\"pubdate\", datatype=DataType.INT64)  # Milvus has no date type\n",
    "    schema.add_field(field_name=\"astrollama\", datatype=DataType.FLOAT_VECTOR, dim=4096)\n",
    "\n",
    "    client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "print(f\"Collections on client: {client.list_collections()}\")\n",
    "collection = Collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate astrollama embedder\n",
    "embedder = get_embedder(\"UniverseTBD/astrollama\", device=\"mps\", normalize=False)\n",
    "print(f\"Embedder: {embedder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.schema.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20706f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema\n",
    "old_fields = collection.schema.fields\n",
    "new_fields = []\n",
    "\n",
    "for field in old_fields:\n",
    "    new_field = FieldSchema(\n",
    "        name=field.name,\n",
    "        dtype=field.dtype,\n",
    "        is_primary=field.is_primary,\n",
    "        auto_id=field.auto_id,\n",
    "        max_length=field.max_length if field.dtype == DataType.VARCHAR else None,\n",
    "        dim=field.dim if field.dtype in [DataType.FLOAT_VECTOR, DataType.FLOAT16_VECTOR, DataType.BFLOAT16_VECTOR] else None,\n",
    "        description=field.description\n",
    "    )\n",
    "    new_fields.append(new_field)\n",
    "\n",
    "new_schema = CollectionSchema(\n",
    "    fields=new_fields,\n",
    "    description=collection.schema.description,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_df(rows: list[tuple]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Expects a list of tuples (text, doi, pubdate)\n",
    "    Embeds the text using the embedder to create a new column 'astrollama'\n",
    "    Converts the pubdate in datetime.date format to an integer YYYYMMDD\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(rows, columns=[\"text\", \"doi\", \"pubdate\"])\n",
    "    df[\"astrollama\"] = embedder(df[\"text\"]).tolist()  # Convert numpy array to list of lists\n",
    "    df[\"pubdate\"] = df[\"pubdate\"].apply(lambda x: int(x.strftime(\"%Y%m%d\")))  # Convert date to int YYYYMMDD\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over DB contributions table and fetch data\n",
    "BATCH_SIZE = 16\n",
    "OFFSET = collection.num_entities\n",
    "with db.conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT text, doi, pubdate FROM contributions OFFSET %s\", (OFFSET,))\n",
    "    while True:\n",
    "        rows = cursor.fetchmany(BATCH_SIZE)\n",
    "        if not rows:\n",
    "            break\n",
    "        df = rows_to_df(rows)\n",
    "\n",
    "        # Insert into collection\n",
    "        result = collection.insert(df)\n",
    "        print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda99f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = collection.schema.fields[0]\n",
    "print(prop)\n",
    "print(type(prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d4aa53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 2048}}, {'name': 'doi', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 64}}, {'name': 'pubdate', 'description': '', 'type': <DataType.INT64: 5>}, {'name': 'astrollama', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 4096}}]\n",
      "Get just the names:\n",
      "['text', 'doi', 'pubdate', 'astrollama']\n"
     ]
    }
   ],
   "source": [
    "print(collection.schema.fields)\n",
    "print(\"Get just the names:\")\n",
    "names = [field.name for field in collection.schema.fields]\n",
    "names.remove(\"id\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a75bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contributions', 'chunks']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aceb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Create new collection with both vector fields\n",
    "NEW_COLLECTION_NAME = \"contributions_with_qwen\"\n",
    "\n",
    "if not client.has_collection(collection_name=NEW_COLLECTION_NAME):\n",
    "    print(f\"Creating new collection '{NEW_COLLECTION_NAME}' with both vector fields.\")\n",
    "    schema = client.create_schema(auto_id=True, enable_dynamic_field=True)\n",
    "    schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n",
    "    schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=2048)\n",
    "    schema.add_field(field_name=\"doi\", datatype=DataType.VARCHAR, max_length=64)\n",
    "    schema.add_field(field_name=\"pubdate\", datatype=DataType.INT64)\n",
    "    schema.add_field(field_name=\"astrollama\", datatype=DataType.FLOAT_VECTOR, dim=4096)\n",
    "    schema.add_field(field_name=\"qwen8b\", datatype=DataType.FLOAT_VECTOR, dim=4096)  # New field\n",
    "\n",
    "    client.create_collection(collection_name=NEW_COLLECTION_NAME, schema=schema)\n",
    "\n",
    "new_collection = Collection(NEW_COLLECTION_NAME)\n",
    "old_collection = Collection(\"contributions\")\n",
    "\n",
    "# Load embedder\n",
    "qwen_embedder = get_embedder(\"Qwen/Qwen3-Embedding-8B\", device=\"mps\", normalize=True)\n",
    "print(f\"Qwen Embedder: {qwen_embedder}\")\n",
    "\n",
    "# Migrate data with new embeddings\n",
    "BATCH_SIZE = 8\n",
    "total_entities = old_collection.num_entities\n",
    "processed = 0\n",
    "\n",
    "print(f\"Migrating {total_entities} entities from 'contributions' to '{NEW_COLLECTION_NAME}'\")\n",
    "\n",
    "with tqdm(total=total_entities, desc=\"Migrating with Qwen embeddings\") as pbar:\n",
    "    for offset in range(0, total_entities, BATCH_SIZE):\n",
    "        # Query batch from old collection\n",
    "        entities = old_collection.query(\n",
    "            expr=\"\", output_fields=[\"text\", \"doi\", \"pubdate\", \"astrollama\"], limit=BATCH_SIZE, offset=offset\n",
    "        )\n",
    "\n",
    "        if not entities:\n",
    "            break\n",
    "\n",
    "        # Extract data for new collection\n",
    "        texts = [entity[\"text\"] for entity in entities]\n",
    "        dois = [entity[\"doi\"] for entity in entities]\n",
    "        pubdates = [entity[\"pubdate\"] for entity in entities]\n",
    "        astrollama_embeddings = [entity[\"astrollama\"] for entity in entities]\n",
    "\n",
    "        # Generate new Qwen embeddings\n",
    "        qwen_embeddings = qwen_embedder(texts)\n",
    "\n",
    "        # Prepare data for insertion\n",
    "        insert_data = {\n",
    "            \"text\": texts,\n",
    "            \"doi\": dois,\n",
    "            \"pubdate\": pubdates,\n",
    "            \"astrollama\": astrollama_embeddings,\n",
    "            \"qwen8b\": qwen_embeddings.tolist(),\n",
    "        }\n",
    "\n",
    "        # Insert into new collection\n",
    "        result = new_collection.insert(insert_data)\n",
    "        processed += len(entities)\n",
    "        pbar.update(len(entities))\n",
    "\n",
    "print(f\"Migration complete! {processed} entities migrated.\")\n",
    "\n",
    "# Create indexes on the new collection\n",
    "new_collection.create_index(\n",
    "    field_name=\"astrollama\",\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"IP\",\n",
    "    },\n",
    ")\n",
    "\n",
    "new_collection.create_index(\n",
    "    field_name=\"qwen8b\",\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"COSINE\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Optional: Drop old collection and rename new one\n",
    "client.drop_collection(\"contributions\")\n",
    "client.rename_collection(old_name=NEW_COLLECTION_NAME, new_name=\"contributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a58fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.create_index(\n",
    "    field_name=\"astrollama\",\n",
    "    index_params={\n",
    "        \"index_type\": \"FLAT\",\n",
    "        \"metric_type\": \"L2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "index_params = client.prepare_index_params()\n",
    "index_params.add_index(\n",
    "    field_name=\"pubdate\",\n",
    "    index_type=\"STL_SORT\",\n",
    "    index_name=\"contributions_pubdate_index\",\n",
    ")\n",
    "\n",
    "client.create_index(\n",
    "    collection_name=collection.name,\n",
    "    index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0eeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the collection if it doesn't exist\n",
    "\n",
    "COLLECTION_NAME = \"chunks\"\n",
    "if not client.has_collection(collection_name=COLLECTION_NAME):\n",
    "    print(f\"Collection '{COLLECTION_NAME}' does not exist. Creating it.\")\n",
    "    schema = client.create_schema(auto_id=True, enable_dynamic_field=True)\n",
    "    schema.add_field(field_name=\"id\", datatype=DataType.INT64, is_primary=True)\n",
    "    schema.add_field(field_name=\"text\", datatype=DataType.VARCHAR, max_length=2048)\n",
    "    schema.add_field(field_name=\"doi\", datatype=DataType.VARCHAR, max_length=64)\n",
    "    schema.add_field(field_name=\"pubdate\", datatype=DataType.INT64)  # Milvus has no date type\n",
    "    schema.add_field(field_name=\"astrollama\", datatype=DataType.FLOAT_VECTOR, dim=4096)\n",
    "\n",
    "    client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "print(f\"Collections on client: {client.list_collections()}\")\n",
    "collection = Collection(COLLECTION_NAME)\n",
    "print(f\"{collection.num_entities} entities in collection {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc3dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over DB contributions table and fetch data\n",
    "with db.conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM chunks\")\n",
    "    total_chunks = cursor.fetchone()[0]\n",
    "\n",
    "processed = 0\n",
    "print(f\"Total chunks to process: {total_chunks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c661b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679283cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "with db.conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT text, doi, pubdate FROM chunks\")\n",
    "    while True:\n",
    "        rows = cursor.fetchmany(BATCH_SIZE)\n",
    "        # print(f\"Fetched {len(rows)} rows.\")\n",
    "        if not rows:\n",
    "            break\n",
    "        df = rows_to_df(rows)\n",
    "        # print(f\"Converted rows to DataFrame with {len(df)} entries.\")\n",
    "\n",
    "        # Insert into collection\n",
    "        result = collection.insert(df)\n",
    "        processed += len(rows)\n",
    "        print(f\"\\rProcessed {processed}/{total_chunks} total chunks.\", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd9ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
