{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "659ef850",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Research len: 10027\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "research_df = pd.read_json('data/research_used.jsonl', lines=True)\n",
        "print(f\"Research len: {len(research_df)}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "65c98901",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up splitter\n",
        "from semantic_text_splitter import TextSplitter\n",
        "\n",
        "splitter = TextSplitter(capacity=1500, overlap=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "035f0535",
      "metadata": {},
      "outputs": [],
      "source": [
        "def reconstruct_paper(example: pd.Series) -> str:\n",
        "    return f\"{example.title}\\n\\nAbstract: {example.abstract}\\n\\n{example.body}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "03891225",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "processing: 10027it [00:02, 4761.84it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for doi in tqdm(research_df.itertuples(), desc=\"processing\"):\n",
        "    doi = row.doi\n",
        "    # Convert pubdate from 'YYYY-MM-DD' to int YYYYMMDD\n",
        "    pubdate = int(row.pubdate.replace(\"-\", \"\"))\n",
        "    paper = reconstruct_paper(row)\n",
        "\n",
        "    chunks = splitter.chunks(paper)\n",
        "    chunks = [chunk.strip().replace(\"\\x00\", \"\") for chunk in chunks if chunk.strip()]  # Remove null chars and empty chunks\n",
        "    with open('data/research_chunks.jsonl', 'a') as file:\n",
        "        for chunk in chunks:\n",
        "            file.write(json.dumps({\"text\": chunk, \"doi\": doi, \"pubdate\": pubdate}) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d695347f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique DOIs in chunks after hydration: 10027\n",
            "Number of unique DOIs in contributions: 10027\n",
            "Same set of DOIS: True\n"
          ]
        }
      ],
      "source": [
        "# Check that the set of DOIs present in `chunks` is the same as those in `contributions`\n",
        "results = db.query(f\"SELECT DISTINCT doi FROM chunks\")\n",
        "chunk_dois = {row[0] for row in results}\n",
        "print(f\"Number of unique DOIs in chunks after hydration: {len(chunk_dois)}\")\n",
        "print(f\"Number of unique DOIs in contributions: {len(contribution_dois)}\")\n",
        "print(f\"Same set of DOIS: {chunk_dois == contribution_dois}\")\n",
        "assert chunk_dois == contribution_dois, \"DOIs in chunks do not match those in contributions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7baa16ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples len: 15133\n",
            "Examples after filtering: 14739\n"
          ]
        }
      ],
      "source": [
        "examples = pd.read_json('data/dataset/nontrivial_llm.jsonl', lines=True)\n",
        "print(f\"Examples len: {len(examples)}\")\n",
        "# Filter for only those examples where all citation_dois are in the contributions_dois\n",
        "examples = examples[examples['citation_dois'].apply(lambda x: all(doi in contribution_dois for doi in x))]\n",
        "print(f\"Examples after filtering: {len(examples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a52bf7",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "citeline",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
