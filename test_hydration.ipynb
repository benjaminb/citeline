{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9cb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978cabd",
   "metadata": {},
   "source": [
    "Establish control set of DOI's: those cited in the query dataset and all cited papers are small enough to extract contributions (less than ~65k tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301247a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 14815\n",
      "Number of unique cited DOIs: 10017\n"
     ]
    }
   ],
   "source": [
    "# Get the doi's cited by the dataset\n",
    "query_dataset = pd.read_json('data/dataset/nontrivial_filtered.jsonl', lines=True)\n",
    "cited_dois = []\n",
    "for row in query_dataset.itertuples():\n",
    "    cited_dois.extend(row.citation_dois)\n",
    "\n",
    "cited_dois_set = set(cited_dois)\n",
    "print(f\"Number of rows: {len(query_dataset)}\")\n",
    "print(f\"Number of unique cited DOIs: {len(cited_dois_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b7f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "research = pd.read_json(\"data/preprocessed/research.jsonl\", lines=True)\n",
    "\n",
    "\n",
    "def reconstruct_paper(example: pd.Series) -> str:\n",
    "    return f\"{example['title']}\\n\\nAbstract: {example['abstract']}\\n\\n{example['body']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377f8488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered query dataset to 14815 rows\n"
     ]
    }
   ],
   "source": [
    "MAX_PAPER_LEN = 250_000\n",
    "\n",
    "query_df_filtered = query_dataset[query_dataset.apply(lambda x: all(len(reconstruct_paper(research.loc[research.doi == doi].iloc[0])) < MAX_PAPER_LEN for doi in x['citation_dois']), axis=1)]\n",
    "print(f\"Filtered query dataset to {len(query_df_filtered)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "255d4102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contributions contains 9786 unique DOIs.\n",
      "9750 unique DOIs\n"
     ]
    }
   ],
   "source": [
    "# Load the existing contributions, filter out any that are from uncited paper\n",
    "contributions_df = pd.read_json(\"data/findings/combined.jsonl\", lines=True)\n",
    "print(f\"Contributions contains {len(contributions_df.doi.unique())} unique DOIs.\")\n",
    "contributions_df_filtered = contributions_df[contributions_df.doi.isin(cited_dois_set)]\n",
    "print(f\"{len(contributions_df_filtered.doi.unique())} unique DOIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbd53634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9750 rows\n"
     ]
    }
   ],
   "source": [
    "# If there are any duplicate DOIs in the contributions_df_filtered, only keep the first occurrence\n",
    "contributions_df_filtered = contributions_df_filtered.drop_duplicates(subset='doi', keep='first')\n",
    "print(len(contributions_df_filtered), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e0ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOIs to process: 267\n"
     ]
    }
   ],
   "source": [
    "dois_to_process = cited_dois_set - set(contributions_df_filtered.doi)\n",
    "print(f\"DOIs to process: {len(dois_to_process)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f65268",
   "metadata": {},
   "source": [
    "## Process the remaining DOI's\n",
    "\n",
    "1. Set up logging and functions\n",
    "1. Send each doi to LLM for contribution extraction\n",
    "1. Write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f638b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/deepseek.log\",\n",
    "    filemode=\"w\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d9894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deepseek api, which copies the openai api\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llm.models import Findings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def deepseek_client():\n",
    "    assert \"DEEPSEEK_API_KEY\" in os.environ, \"DEEPSEEK_API_KEY must be set in environment variables\"\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "        base_url=\"https://api.deepseek.com\",\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "client = deepseek_client()\n",
    "\n",
    "with open(\"llm/prompts/original_contributions.txt\", \"r\") as f:\n",
    "    SYSTEM_PROMPT = f.read()\n",
    "\n",
    "\n",
    "def get_deepseek_response(paper: str):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[{\"role\": \"system\", \"content\": SYSTEM_PROMPT}, {\"role\": \"user\", \"content\": paper}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            stream=False,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def get_contributions_from_paper(record: pd.Series) -> list[str]:\n",
    "    paper = reconstruct_paper(record)\n",
    "    if len(paper) > MAX_PAPER_LEN:\n",
    "        # Use ChatOllama with deepseek\n",
    "\n",
    "        with open(\"logs/long_papers.jsonl\", \"a\") as file:\n",
    "            file.write(json.dumps({\"doi\": record[\"doi\"], \"length\": len(paper)}) + \"\\n\")\n",
    "        logging.warning(f\"Paper for DOI {record['doi']} is too long: {len(paper)} characters, skipping.\")\n",
    "        return []\n",
    "\n",
    "    # Get the deepseek API response\n",
    "    json_response = None\n",
    "    try:\n",
    "        json_response = get_deepseek_response(paper)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing JSON for DOI {record['doi']}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Parse the JSON response, log any error\n",
    "    try:\n",
    "        data = json.loads(json_response)\n",
    "        findings_obj = Findings.model_validate(data)\n",
    "        return findings_obj.findings  # This is your list of strings\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error parsing JSON for DOI {record['doi']}: {e}\")\n",
    "        print(f\"JSON parse error for DOI {record['doi']}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4466a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \n",
      "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
      "41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, JSON parse error for DOI 10.1111/j.1365-2966.2004.07881.x\n",
      "54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, \n",
      "81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, \n",
      "121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, \n",
      "161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, \n",
      "201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, \n",
      "241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"findings_{timestamp}.jsonl\"\n",
    "\n",
    "\n",
    "# For each remaining DOI, get the findings\n",
    "with open(filename, \"a\") as file:\n",
    "    for i, doi in enumerate(dois_to_process):\n",
    "        print(i, end=\", \")  # Get the record from the research DataFrame\n",
    "        if i % 40 == 0:\n",
    "            print()\n",
    "\n",
    "        record = research[research[\"doi\"] == doi].iloc[0]\n",
    "        if record.empty:\n",
    "            logging.warning(f\"Record for DOI {doi} not found in research DataFrame\")\n",
    "            continue\n",
    "        findings = get_contributions_from_paper(record)\n",
    "        if not findings:\n",
    "            logging.warning(f\"No findings extracted for DOI {doi}\")\n",
    "            continue\n",
    "\n",
    "        # Add to jsonl\n",
    "        findings_data = {\"doi\": doi, \"findings\": findings}\n",
    "        file.write(json.dumps(findings_data) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7a7b2",
   "metadata": {},
   "source": [
    "It turns out string length does not always approximate token length well. Checking the log for doi processing we find that several papers, although well below 250,000 chars, still exceeded DeepSeek's 65k token limit. Since we are limiting our dataset papers that can be processed by this LLM, we must now change the doi control group to those found in our findings.\n",
    "\n",
    "Once again let's combine all the findings, remove any duplicates by doi, then set the unique doi's from the findings as the doi control set. \n",
    "\n",
    "1. Write out this control set as doi's used\n",
    "1. Make sure the query dataset only includes examples that cite these doi's\n",
    "1. Write out contributions dataset for only these doi's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f64f0bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>[Direct images of a parsec-scale disk of ioniz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1051/0004-6361/202038096</td>\n",
       "      <td>[Low H I covering fractions are strongly corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1093/mnras/stx127</td>\n",
       "      <td>[Diffusive cosmic ray (CR) transport results i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1086/311810</td>\n",
       "      <td>[The hard X-rays in Cyg X-1 and similar black ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1093/mnras/sty2984</td>\n",
       "      <td>[Investigated the formation of extremely metal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           doi  \\\n",
       "0                10.1038/42201   \n",
       "1  10.1051/0004-6361/202038096   \n",
       "2         10.1093/mnras/stx127   \n",
       "3               10.1086/311810   \n",
       "4        10.1093/mnras/sty2984   \n",
       "\n",
       "                                            findings  \n",
       "0  [Direct images of a parsec-scale disk of ioniz...  \n",
       "1  [Low H I covering fractions are strongly corre...  \n",
       "2  [Diffusive cosmic ray (CR) transport results i...  \n",
       "3  [The hard X-rays in Cyg X-1 and similar black ...  \n",
       "4  [Investigated the formation of extremely metal...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d9cf6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1086/345660</td>\n",
       "      <td>[The intergalactic medium contains less neutra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1086/426070</td>\n",
       "      <td>[Standard solar models with older, higher heav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1088/0004-637X/763/2/148</td>\n",
       "      <td>[The circumgalactic medium (CGM) of late-type ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1086/163605</td>\n",
       "      <td>[Monte Carlo computations accurately model X-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1086/300959</td>\n",
       "      <td>[The universal rest-frame ultraviolet luminosi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           doi  \\\n",
       "0               10.1086/345660   \n",
       "1               10.1086/426070   \n",
       "2  10.1088/0004-637X/763/2/148   \n",
       "3               10.1086/163605   \n",
       "4               10.1086/300959   \n",
       "\n",
       "                                            findings  \n",
       "0  [The intergalactic medium contains less neutra...  \n",
       "1  [Standard solar models with older, higher heav...  \n",
       "2  [The circumgalactic medium (CGM) of late-type ...  \n",
       "3  [Monte Carlo computations accurately model X-r...  \n",
       "4  [The universal rest-frame ultraviolet luminosi...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_json(\"data/findings/findings_20250818_123938.jsonl\", lines=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8133730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9989 rows\n",
      "9989 unique DOIs in combined DataFrame\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([contributions_df_filtered, new_df], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset='doi', keep='first')\n",
    "print(len(combined_df), \"rows\")\n",
    "print(f\"{len(combined_df.doi.unique())} unique DOIs in combined DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d19d7",
   "metadata": {},
   "source": [
    "The set of doi's in the contributions dataset becomes our control group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72322164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "research_dois_used = list(combined_df.doi.unique())\n",
    "with open(\"data/research_dois_used.json\", \"w\") as f:\n",
    "    json.dump(research_dois_used, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "research = pd.read_json(\"data/preprocessed/research.jsonl\", lines=True)\n",
    "research_used = research[research.doi.isin(research_dois_used)]\n",
    "len(research_used)\n",
    "assert len(research_used) == len(research_dois_used), \"Should be one record per doi\"\n",
    "research_used.to_json(\"data/research_used.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60926cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1974-05-01\n",
       "1    1955-01-01\n",
       "6    1997-12-01\n",
       "8    1978-05-01\n",
       "9    2011-08-01\n",
       "Name: pubdate, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_used.pubdate[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e0d293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using research_used df and looking up by 'doi', add citation count and pubdate to combined_df\n",
    "combined_df['citation_count'] = combined_df['doi'].apply(lambda x: research_used.loc[research_used['doi'] == x, 'citation_count'].values[0])\n",
    "combined_df['pubdate'] = combined_df['doi'].apply(lambda x: research_used.loc[research_used['doi'] == x, 'pubdate'].values[0])\n",
    "\n",
    "# Convert pubdate to int YYYYMMDD format\n",
    "combined_df['pubdate'] = combined_df['pubdate'].apply(lambda x: int(x.replace(\"-\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76c3d047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>findings</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>[Direct images of a parsec-scale disk of ioniz...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1051/0004-6361/202038096</td>\n",
       "      <td>[Low H I covering fractions are strongly corre...</td>\n",
       "      <td>95</td>\n",
       "      <td>20200701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1093/mnras/stx127</td>\n",
       "      <td>[Diffusive cosmic ray (CR) transport results i...</td>\n",
       "      <td>118</td>\n",
       "      <td>20170501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1086/311810</td>\n",
       "      <td>[The hard X-rays in Cyg X-1 and similar black ...</td>\n",
       "      <td>355</td>\n",
       "      <td>19990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1093/mnras/sty2984</td>\n",
       "      <td>[Investigated the formation of extremely metal...</td>\n",
       "      <td>52</td>\n",
       "      <td>20190101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           doi  \\\n",
       "0                10.1038/42201   \n",
       "1  10.1051/0004-6361/202038096   \n",
       "2         10.1093/mnras/stx127   \n",
       "3               10.1086/311810   \n",
       "4        10.1093/mnras/sty2984   \n",
       "\n",
       "                                            findings  citation_count   pubdate  \n",
       "0  [Direct images of a parsec-scale disk of ioniz...             114  19970801  \n",
       "1  [Low H I covering fractions are strongly corre...              95  20200701  \n",
       "2  [Diffusive cosmic ray (CR) transport results i...             118  20170501  \n",
       "3  [The hard X-rays in Cyg X-1 and similar black ...             355  19990101  \n",
       "4  [Investigated the formation of extremely metal...              52  20190101  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ccceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row, 'findings' is a list of strings. Split that into a row for each string, doi, citation_count, and pubdate carrying over to new rows\n",
    "contributions_denormalized = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    for finding in row['findings']:\n",
    "        contributions_denormalized.append({\n",
    "            'doi': row['doi'],\n",
    "            'text': finding,\n",
    "            'citation_count': row['citation_count'],\n",
    "            'pubdate': row['pubdate']\n",
    "        })\n",
    "\n",
    "contributions_df = pd.DataFrame(contributions_denormalized)\n",
    "\n",
    "assert len(contributions_df) == sum(len(row['findings']) for _, row in combined_df.iterrows())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19781877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89860\n",
      "9989\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(contributions_df)}\")\n",
    "print(f\"{len(contributions_df.doi.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47cd3ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>text</th>\n",
       "      <th>citation_count</th>\n",
       "      <th>pubdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>Direct images of a parsec-scale disk of ionize...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>The disk is viewed nearly edge-on, with indivi...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>The projected axes of the disk and AGN are ali...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>Observations using the Very Large Baseline Arr...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1038/42201</td>\n",
       "      <td>The brightness temperature of the 'hot zone' (...</td>\n",
       "      <td>114</td>\n",
       "      <td>19970801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             doi                                               text  \\\n",
       "0  10.1038/42201  Direct images of a parsec-scale disk of ionize...   \n",
       "1  10.1038/42201  The disk is viewed nearly edge-on, with indivi...   \n",
       "2  10.1038/42201  The projected axes of the disk and AGN are ali...   \n",
       "3  10.1038/42201  Observations using the Very Large Baseline Arr...   \n",
       "4  10.1038/42201  The brightness temperature of the 'hot zone' (...   \n",
       "\n",
       "   citation_count   pubdate  \n",
       "0             114  19970801  \n",
       "1             114  19970801  \n",
       "2             114  19970801  \n",
       "3             114  19970801  \n",
       "4             114  19970801  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87d0ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions_df.to_json(\"data/research_contributions.jsonl\", lines=True, orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ee59141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89860"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contributions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c13da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
