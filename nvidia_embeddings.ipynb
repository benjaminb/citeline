{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding with NVIDIA's model\n",
    "\n",
    "A `SentenceTransformer` model instantiated from `NVIDIA-Embed-v2` will return tensors or np arrays but can only take a string input or a list containing a single string. It cannot accept a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5430d312524945a6a7066b0fcbf1a696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 4096, 'do_lower_case': False}) with Transformer model: NVEmbedModel \n",
      "  (1): Pooling({'word_embedding_dimension': 4096, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': False})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbasseri/miniforge3/envs/citeline/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String embedding shape: torch.Size([4096])\n",
      "Singleton shape: torch.Size([1, 4096])\n",
      "Batch embeddings shape: torch.Size([3, 4096])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "device = 'cpu' # mps was producing a dimension error on batch input to model.encode \n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer(\n",
    "    \"nvidia/NV-Embed-v2\", trust_remote_code=True, device=device)\n",
    "print(model)\n",
    "\n",
    "# Encoding a single string will work:\n",
    "string_embedding = model.encode(\n",
    "    sentences[0], convert_to_tensor=True, normalize_embeddings=False)\n",
    "print(f\"String embedding shape: {string_embedding.shape}\")\n",
    "\n",
    "\n",
    "# Encoding a list containing a single string works:\n",
    "singleton_embedding = model.encode(\n",
    "    sentences[:1], convert_to_tensor=True, normalize_embeddings=False)\n",
    "print(f\"Singleton shape: {singleton_embedding.shape}\")\n",
    "\n",
    "# Encoding a list of strings\n",
    "try:\n",
    "    embeddings = model.encode(\n",
    "        sentences, convert_to_tensor=True, normalize_embeddings=False)\n",
    "    print(f\"Batch embeddings shape: {embeddings.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(3, 4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbasseri/miniforge3/envs/citeline/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences, convert_to_numpy=True, normalize_embeddings=False)\n",
    "print(type(embeddings))\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chromadb.api.client.Client object at 0xa878b2750>\n",
      "<class 'list'>\n",
      "2\n",
      "<class 'numpy.ndarray'>\n",
      "(4096,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbasseri/miniforge3/envs/citeline/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "client = chromadb.PersistentClient(path='./vector_stores/nv/')\n",
    "print(client)\n",
    "\n",
    "# Set up embedding model\n",
    "class NVChromaEmbedder(EmbeddingFunction):\n",
    "    def __init__(self, embedding_fn):\n",
    "        self._encode = embedding_fn\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return self._encode(input)\n",
    "\n",
    "embedding_lambda = lambda docs: model.encode(docs, convert_to_numpy=True, normalize_embeddings=False)\n",
    "\n",
    "embedder = NVChromaEmbedder(embedding_lambda)\n",
    "result = embedder(['hi there', 'hello world'])\n",
    "print(type(result))\n",
    "print(type(result[0]))\n",
    "print(result[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All collections have been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Get all collection names\n",
    "collections = client.list_collections()\n",
    "\n",
    "# Delete each collection\n",
    "for collection in collections:\n",
    "    client.delete_collection(name=collection.name)\n",
    "\n",
    "print(\"All collections have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Collection(name=nv_test)\n"
     ]
    }
   ],
   "source": [
    "collection = client.create_collection(\n",
    "    name=\"nv_test\",\n",
    "    embedding_function=embedder,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "print(f\"Created {collection}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files:\n",
      "  Earth_Science_Reviews\n",
      "  Earth_Science_Research\n",
      "  Planetary_Research\n",
      "  Planetary_Reviews\n",
      "  Astro_Reviews\n",
      "  Astro_Research\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "PATH_TO_DATA = 'data/json/'\n",
    "FILENAMES = os.listdir(PATH_TO_DATA)\n",
    "data = dict()\n",
    "for filename in FILENAMES:\n",
    "    with open(f'{PATH_TO_DATA}/{filename}', 'r') as file:\n",
    "        data[os.path.splitext(os.path.basename(filename))[0]] = json.load(file)\n",
    "\n",
    "print(\"Found files:\")\n",
    "for filename in data:\n",
    "    print(f\"  {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 3000\n"
     ]
    }
   ],
   "source": [
    "def preprocess_papers(papers):\n",
    "    # Convert titles from list to string\n",
    "    for paper in papers:\n",
    "        paper['title'] = paper['title'][0]\n",
    "    return papers\n",
    "\n",
    "\n",
    "def construct_document(record, fields):\n",
    "    \"\"\"\n",
    "    Construct a document from the specified fields\n",
    "    \"\"\"\n",
    "    return \"\\n\".join([record[field] for field in fields])\n",
    "\n",
    "\n",
    "def prep_metadata(record):\n",
    "    \"\"\"\n",
    "    JSONify any list or dict fields, as Chroma requires all metadata to be primitive\n",
    "    \"\"\"\n",
    "    return {key: json.dumps(value) if isinstance(value, (list, dict)) else value for key, value in record.items()}\n",
    "\n",
    "\n",
    "data = {key: preprocess_papers(value) for key, value in data.items()}\n",
    "\n",
    "all_papers = data['Astro_Research'] + \\\n",
    "    data['Earth_Science_Research'] + data['Planetary_Research']\n",
    "print(f\"Number of records: {len(all_papers)}\")\n",
    "\n",
    "documents = [construct_document(\n",
    "    paper, ['title', 'abstract', 'body']) for paper in all_papers]\n",
    "metadatas = [prep_metadata(paper) for paper in all_papers]\n",
    "ids = [paper['id'] for paper in all_papers]\n",
    "\n",
    "assert len(documents) == len(metadatas) == len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminbasseri/miniforge3/envs/citeline/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "direct_embedding = embedding_lambda([\"the sun is a star\"])\n",
    "foo = collection.add(\n",
    "    documents=[\"the sun is a star\"],\n",
    "    # metadatas=[{}],\n",
    "    ids=['foo_id']\n",
    ")\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['foo_id']], 'embeddings': [array([[-0.02781531, -0.00907008,  0.0181422 , ..., -0.00454538,\n",
      "        -0.0195914 ,  0.00130222]])], 'documents': [['the sun is a star']], 'uris': None, 'data': None, 'metadatas': None, 'distances': None, 'included': [<IncludeEnum.embeddings: 'embeddings'>, <IncludeEnum.documents: 'documents'>]}\n"
     ]
    }
   ],
   "source": [
    "chroma_embedding = collection.query(\n",
    "    query_texts=[\"the sun is a star\"],\n",
    "    n_results=1,\n",
    "    include=[\"embeddings\", \"documents\"]\n",
    ")\n",
    "\n",
    "print(chroma_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "print(type(chroma_embedding['embeddings'][0]))\n",
    "print(chroma_embedding['embeddings'][0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direct_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "(1, 4096)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "chroma_numpy = chroma_embedding['embeddings'][0]\n",
    "print(direct_embedding.shape)\n",
    "print(chroma_numpy.shape)\n",
    "print(np.array_equal(direct_embedding, chroma_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
