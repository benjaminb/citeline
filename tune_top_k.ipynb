{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuning the Top-k Query parameter\n",
        "\n",
        "First we set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5432\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import psycopg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import torch\n",
        "from TextEnrichers import get_enricher, TextEnricher\n",
        "from database.database import Database\n",
        "from Embedders import Embedder, get_embedder\n",
        "from tqdm import tqdm\n",
        "\n",
        "load_dotenv('.env', override=True)\n",
        "print(os.getenv('DB_PORT'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================CONFIG=================================\n",
            "Database         User             Host                             Port            \n",
            "citeline_db      bbasseri         localhost                        5432            \n",
            "========================================================================\n",
            "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n",
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Database setup\n",
        "db = Database()\n",
        "db.test_connection()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available(\n",
        ") else 'mps' if torch.mps.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Investigating precision over `k`\n",
        "\n",
        "For our various embedding models and enrichment strategies, we want to know the smallest `top_k` value that will still retrieve the target reference for a given sentence. \n",
        "\n",
        "To investigate this, we'll sample 100 examples from the non-trivial training data. Each example typically has 1-2 target DOI's. For each example, we'll query the database with a large `top_k` parameter to start, so we can be sure the database returns the target references. Then we can ask at what index in the query results does a target DOI first appear. Ideally, the ranks will all be very high, indicated by having *low* indices in the query results. We also expect enriched examples to have their target doi's higher ranked (lower indices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_json('data/dataset/split/train.jsonl', lines=True)\n",
        "examples = data.sample(10, random_state=42)\n",
        "\n",
        "def lowest_index_matching_doi(target_doi: str, query_results: list) -> int:\n",
        "    \"\"\"\n",
        "    Returns the first index of the query results where the chunk doi matches the target doi.\n",
        "    If no match is found, returns -1.\n",
        "    \"\"\"\n",
        "    for i, result in enumerate(query_results):\n",
        "        if target_doi == result.doi:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def get_ranks(\n",
        "    example: pd.Series,\n",
        "    embedding,\n",
        "    top_k: int,\n",
        "    ef_search: int,\n",
        "    table_name: str = 'library',\n",
        "    target_column: str = 'bge_norm',\n",
        "    metric: str = 'vector_cosine_ops'\n",
        ") -> list[int]:\n",
        "    target_dois = example['citation_dois']\n",
        "\n",
        "    # Query\n",
        "    start = time()\n",
        "    query_results = db.query_vector_column(\n",
        "        query_vector=embedding,\n",
        "        target_column=target_column,\n",
        "        table_name=table_name,\n",
        "        top_k=top_k,\n",
        "        use_index=True,\n",
        "        ef_search=ef_search\n",
        "    )\n",
        "    \n",
        "    ranks = [lowest_index_matching_doi(\n",
        "        target_doi=doi, query_results=query_results) for doi in target_dois]\n",
        "    return ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ranks_at_k(\n",
        "                examples: pd.DataFrame,\n",
        "                embedder_name: str, \n",
        "                enricher_name: str, \n",
        "                target_column: str, \n",
        "                top_k: int,\n",
        "                ef_search: 256) -> list[int]:\n",
        "    \"\"\"\n",
        "    Calculates the 'ranks' for a given embedding model and enrichment function.\n",
        "    The ranks are the indices of the first chunk with the target doi for each example, i.e.\n",
        "    the lowest k that would retrieve a chunk with the target doi.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup\n",
        "    print(f\"Embedding model: {embedder_name}, Enricher: {enricher_name}\")\n",
        "    embedder = get_embedder(embedder_name, device=device)\n",
        "    enricher = get_enricher(enricher_name, path_to_data='data/preprocessed/reviews.jsonl')\n",
        "    \n",
        "    # Enrich\n",
        "    texts_with_dois = list(\n",
        "        examples[['sent_no_cit', 'source_doi']].itertuples(index=False, name=None))\n",
        "    enriched_texts = enricher.enrich_batch(texts_with_dois)\n",
        "    embeddings = embedder(enriched_texts)\n",
        "\n",
        "    # Rank\n",
        "    ranks = []\n",
        "    for i in tqdm(range(len(examples))):\n",
        "        embedding = embeddings[i]\n",
        "        example = examples.iloc[i]\n",
        "        ranks += get_ranks(\n",
        "            example=example,\n",
        "            embedding=embedding,\n",
        "            table_name='library',\n",
        "            target_column=target_column,\n",
        "            top_k=top_k,\n",
        "            ef_search=ef_search)\n",
        "    return ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combos: [('BAAI/bge-small-en', 'identity'), ('BAAI/bge-small-en', 'add_abstract'), ('BAAI/bge-small-en', 'add_title'), ('BAAI/bge-small-en', 'add_title_an_abstract')]\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "                      \n",
        "embedding_models = ['BAAI/bge-small-en']\n",
        "enrichment_methods = ['identity', 'add_abstract',\n",
        "                      'add_title', 'add_title_an_abstract']\n",
        "if device == 'cuda':\n",
        "    embedding_models += ['bert-base-uncased', 'adsabs/astroBERT']\n",
        "\n",
        "combos = list(product(embedding_models, enrichment_methods))\n",
        "print(f\"Combos: {combos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding model: BAAI/bge-small-en, Enricher: identity\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "While enriching example with source doi '10.1016/S1387-6473(99)00004-4', full record not found",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[43mranks_at_k\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedder_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBAAI/bge-small-en\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43menricher_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43midentity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbge_norm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2_261_334\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mef_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[27], line 22\u001b[0m, in \u001b[0;36mranks_at_k\u001b[0;34m(examples, embedder_name, enricher_name, target_column, top_k, ef_search)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Enrich\u001b[39;00m\n\u001b[1;32m     20\u001b[0m texts_with_dois \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     21\u001b[0m     examples[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msent_no_cit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_doi\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mitertuples(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 22\u001b[0m enriched_texts \u001b[38;5;241m=\u001b[39m \u001b[43menricher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menrich_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_with_dois\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedder(enriched_texts)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Rank\u001b[39;00m\n",
            "File \u001b[0;32m~/Dropbox/Studies/StellarDNN/citeline/TextEnrichers.py:99\u001b[0m, in \u001b[0;36mTextEnricher.enrich_batch\u001b[0;34m(self, texts_with_dois)\u001b[0m\n\u001b[1;32m     97\u001b[0m     record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoi_to_record\u001b[38;5;241m.\u001b[39mget(doi)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhile enriching example with source doi \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, full record not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menricher(text, record))\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
            "\u001b[0;31mValueError\u001b[0m: While enriching example with source doi '10.1016/S1387-6473(99)00004-4', full record not found"
          ]
        }
      ],
      "source": [
        "ranks = ranks_at_k(\n",
        "    examples=examples,\n",
        "    embedder_name='BAAI/bge-small-en',\n",
        "    enricher_name='identity',\n",
        "    target_column='bge_norm',\n",
        "    top_k=2_261_334,\n",
        "    ef_search=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[710023,\n",
              " 133663,\n",
              " 1894654,\n",
              " 1290280,\n",
              " -1,\n",
              " 1187023,\n",
              " 1418260,\n",
              " 971105,\n",
              " 574665,\n",
              " 1250933,\n",
              " 1878241,\n",
              " 1909213,\n",
              " 693581,\n",
              " 235882,\n",
              " 1021555,\n",
              " 406718,\n",
              " 1136869,\n",
              " 1145444,\n",
              " 302827,\n",
              " 47560,\n",
              " 470245,\n",
              " 1663816,\n",
              " 1152997,\n",
              " 1432779,\n",
              " 575236,\n",
              " 1469286,\n",
              " 559218,\n",
              " -1,\n",
              " -1,\n",
              " 1367275,\n",
              " 779756,\n",
              " 1119317,\n",
              " 94417,\n",
              " 968245,\n",
              " 1651681]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "source_doi                              10.1007/s00159-022-00140-3\n",
              "sent_original    Clouds with sufficiently short cooling time in...\n",
              "sent_no_cit      Clouds with sufficiently short cooling time in...\n",
              "sent_idx                                                       662\n",
              "citation_dois                             [10.1093/mnras/stab3351]\n",
              "Name: 6646, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples.iloc[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Clouds with sufficiently short cooling time in the mixed gas can even grow with time (e.g. Gronke et al. 2022 ). '"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples.iloc[4].sent_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bibcode</th>\n",
              "      <th>abstract</th>\n",
              "      <th>aff</th>\n",
              "      <th>author</th>\n",
              "      <th>bibstem</th>\n",
              "      <th>doctype</th>\n",
              "      <th>doi</th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>pubdate</th>\n",
              "      <th>title</th>\n",
              "      <th>read_count</th>\n",
              "      <th>reference</th>\n",
              "      <th>data</th>\n",
              "      <th>citation_count</th>\n",
              "      <th>citation</th>\n",
              "      <th>body</th>\n",
              "      <th>dois</th>\n",
              "      <th>loaded_from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27600</th>\n",
              "      <td>2022MNRAS.511..859G</td>\n",
              "      <td>Astrophysical gases are commonly multiphase an...</td>\n",
              "      <td>[Department of Physics &amp;amp; Astronomy, Johns ...</td>\n",
              "      <td>[Gronke, Max, Oh, S. Peng, Ji, Suoqing, Norman...</td>\n",
              "      <td>[MNRAS, MNRAS.511]</td>\n",
              "      <td>article</td>\n",
              "      <td>10.1093/mnras/stab3351</td>\n",
              "      <td>21012594</td>\n",
              "      <td>[hydrodynamics, ISM: clouds, ISM: structure, g...</td>\n",
              "      <td>2022-03-00</td>\n",
              "      <td>Survival and mass growth of cold gas in a turb...</td>\n",
              "      <td>51</td>\n",
              "      <td>[1953ApJ...118..513H, 1956ApJ...124...20S, 196...</td>\n",
              "      <td>None</td>\n",
              "      <td>82</td>\n",
              "      <td>[2021ApJ...923..115M, 2021MNRAS.508.6155W, 202...</td>\n",
              "      <td>1 INTRODUCTION Turbulent, multiphase gases are...</td>\n",
              "      <td>[10.1093/mnras/stab3351, 10.48550/arXiv.2107.1...</td>\n",
              "      <td>data/json/salvaged_articles.json</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   bibcode                                           abstract  \\\n",
              "27600  2022MNRAS.511..859G  Astrophysical gases are commonly multiphase an...   \n",
              "\n",
              "                                                     aff  \\\n",
              "27600  [Department of Physics &amp; Astronomy, Johns ...   \n",
              "\n",
              "                                                  author             bibstem  \\\n",
              "27600  [Gronke, Max, Oh, S. Peng, Ji, Suoqing, Norman...  [MNRAS, MNRAS.511]   \n",
              "\n",
              "       doctype                     doi        id  \\\n",
              "27600  article  10.1093/mnras/stab3351  21012594   \n",
              "\n",
              "                                                 keyword     pubdate  \\\n",
              "27600  [hydrodynamics, ISM: clouds, ISM: structure, g...  2022-03-00   \n",
              "\n",
              "                                                   title  read_count  \\\n",
              "27600  Survival and mass growth of cold gas in a turb...          51   \n",
              "\n",
              "                                               reference  data  \\\n",
              "27600  [1953ApJ...118..513H, 1956ApJ...124...20S, 196...  None   \n",
              "\n",
              "       citation_count                                           citation  \\\n",
              "27600              82  [2021ApJ...923..115M, 2021MNRAS.508.6155W, 202...   \n",
              "\n",
              "                                                    body  \\\n",
              "27600  1 INTRODUCTION Turbulent, multiphase gases are...   \n",
              "\n",
              "                                                    dois  \\\n",
              "27600  [10.1093/mnras/stab3351, 10.48550/arXiv.2107.1...   \n",
              "\n",
              "                            loaded_from  \n",
              "27600  data/json/salvaged_articles.json  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "research = pd.read_json('data/preprocessed/research.jsonl', lines=True)\n",
        "research[research.doi == '10.1093/mnras/stab3351']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names_to_filenames = {\n",
        "    'BAAI/bge-small-en': 'bge',\n",
        "    'bert-base-uncased': 'bert',\n",
        "    'adsabs/astroBERT': 'astrobert'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "citeline",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
