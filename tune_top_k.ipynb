{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tuning the Top-k Query parameter\n",
        "\n",
        "First we set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5432\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import psycopg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import torch\n",
        "from TextEnrichers import get_enricher, TextEnricher\n",
        "from database.database import Database\n",
        "from Embedders import Embedder, get_embedder\n",
        "from tqdm import tqdm\n",
        "\n",
        "load_dotenv('.env', override=True)\n",
        "print(os.getenv('DB_PORT'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================CONFIG=================================\n",
            "Database         User             Host                             Port            \n",
            "citeline_db      bbasseri         localhost                        5432            \n",
            "========================================================================\n",
            "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n",
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Database setup\n",
        "db = Database()\n",
        "db.test_connection()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available(\n",
        ") else 'mps' if torch.mps.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Investigating precision over `k`\n",
        "\n",
        "For our various embedding models and enrichment strategies, we want to know the smallest `top_k` value that will still retrieve the target reference for a given sentence. \n",
        "\n",
        "To investigate this, we'll sample 100 examples from the non-trivial training data. Each example typically has 1-2 target DOI's. For each example, we'll query the database with a large `top_k` parameter to start, so we can be sure the database returns the target references. Then we can ask at what index in the query results does a target DOI first appear. Ideally, the ranks will all be very high, indicated by having *low* indices in the query results. We also expect enriched examples to have their target doi's higher ranked (lower indices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_json('data/dataset/split/train.jsonl', lines=True)\n",
        "examples = data.sample(10, random_state=42)\n",
        "\n",
        "def lowest_index_matching_doi(target_doi: str, query_results: list) -> int:\n",
        "    \"\"\"\n",
        "    Returns the first index of the query results where the chunk doi matches the target doi.\n",
        "    If no match is found, returns -1.\n",
        "    \"\"\"\n",
        "    for i, result in enumerate(query_results):\n",
        "        if target_doi == result.doi:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def get_ranks(\n",
        "    example: pd.Series,\n",
        "    embedding,\n",
        "    top_k: int,\n",
        "    ef_search: int,\n",
        "    table_name: str = 'library',\n",
        "    target_column: str = 'bge_norm',\n",
        "    metric: str = 'vector_cosine_ops'\n",
        ") -> list[int]:\n",
        "    target_dois = example['citation_dois']\n",
        "\n",
        "    # Query\n",
        "    start = time()\n",
        "    query_results = db.query_vector_column(\n",
        "        query_vector=embedding,\n",
        "        target_column=target_column,\n",
        "        table_name=table_name,\n",
        "        top_k=top_k,\n",
        "        use_index=True,\n",
        "        ef_search=ef_search\n",
        "    )\n",
        "    \n",
        "    ranks = [lowest_index_matching_doi(\n",
        "        target_doi=doi, query_results=query_results) for doi in target_dois]\n",
        "    return ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ranks_at_k(\n",
        "                examples: pd.DataFrame,\n",
        "                embedder_name: str, \n",
        "                enricher_name: str, \n",
        "                target_column: str, \n",
        "                top_k: int,\n",
        "                ef_search: 256) -> list[int]:\n",
        "    \"\"\"\n",
        "    Calculates the 'ranks' for a given embedding model and enrichment function.\n",
        "    The ranks are the indices of the first chunk with the target doi for each example, i.e.\n",
        "    the lowest k that would retrieve a chunk with the target doi.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup\n",
        "    print(f\"Embedding model: {embedder_name}, Enricher: {enricher_name}\")\n",
        "    embedder = get_embedder(embedder_name, device=device)\n",
        "    enricher = get_enricher(enricher_name, path_to_data='data/preprocessed/reviews.jsonl')\n",
        "    \n",
        "    # Enrich\n",
        "    texts_with_dois = list(\n",
        "        examples[['sent_no_cit', 'source_doi']].itertuples(index=False, name=None))\n",
        "    enriched_texts = enricher.enrich_batch(texts_with_dois)\n",
        "    embeddings = embedder(enriched_texts)\n",
        "\n",
        "    # Rank\n",
        "    ranks = []\n",
        "    for i in tqdm(range(len(examples))):\n",
        "        embedding = embeddings[i]\n",
        "        example = examples.iloc[i]\n",
        "        ranks += get_ranks(\n",
        "            example=example,\n",
        "            embedding=embedding,\n",
        "            table_name='library',\n",
        "            target_column=target_column,\n",
        "            top_k=top_k,\n",
        "            ef_search=ef_search)\n",
        "    return ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combos: [('BAAI/bge-small-en', 'identity'), ('BAAI/bge-small-en', 'add_abstract'), ('BAAI/bge-small-en', 'add_title'), ('BAAI/bge-small-en', 'add_title_an_abstract')]\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "                      \n",
        "embedding_models = ['BAAI/bge-small-en']\n",
        "enrichment_methods = ['identity', 'add_abstract',\n",
        "                      'add_title', 'add_title_an_abstract']\n",
        "if device == 'cuda':\n",
        "    embedding_models += ['bert-base-uncased', 'adsabs/astroBERT']\n",
        "\n",
        "combos = list(product(embedding_models, enrichment_methods))\n",
        "print(f\"Combos: {combos}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding model: BAAI/bge-small-en, Enricher: identity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 156.13 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [02:52<25:49, 172.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 138.14 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [05:20<21:04, 158.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 157.61 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [08:09<19:03, 163.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 162.05 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [11:03<16:43, 167.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 148.03 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [13:42<13:42, 164.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 157.41 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [16:31<11:04, 166.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 135.40 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [18:57<07:57, 159.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 136.99 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [21:26<05:12, 156.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 133.53 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [23:50<02:32, 152.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 150.18 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [26:32<00:00, 159.22s/it]\n"
          ]
        }
      ],
      "source": [
        "ranks = ranks_at_k(\n",
        "    examples=examples,\n",
        "    embedder_name='BAAI/bge-small-en',\n",
        "    enricher_name='identity',\n",
        "    target_column='bge_norm',\n",
        "    top_k=2_261_334,\n",
        "    ef_search=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding model: BAAI/bge-small-en, Enricher: add_abstract\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 139.02 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [02:30<22:34, 150.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 120.09 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [04:40<18:28, 138.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 155.48 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [07:27<17:38, 151.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 141.55 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [09:59<15:10, 151.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 189.57 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [13:19<14:05, 169.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 236.72 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [17:30<13:07, 196.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 126.54 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [19:48<08:53, 177.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 114.59 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [21:53<05:21, 160.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 261.31 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [26:25<03:15, 195.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 419.79 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [33:36<00:00, 201.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding model: BAAI/bge-small-en, Enricher: add_title\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 451.70 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [07:46<1:09:54, 466.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n",
            "  Query execution time: 160.13 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [10:43<39:29, 296.23s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  WARNING: ef_search (20) is less than top_k (2261334).\n"
          ]
        }
      ],
      "source": [
        "rank_data = {'identity': ranks}\n",
        "for enricher_name in ['add_abstract', 'add_title', 'add_title_an_abstract']:\n",
        "    rank_data[enricher_name] = ranks_at_k(\n",
        "        examples=examples,\n",
        "        embedder_name='BAAI/bge-small-en',\n",
        "        enricher_name=enricher_name,\n",
        "        target_column='bge_norm',\n",
        "        top_k=2_261_334,\n",
        "        ef_search=20\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# write rank_data dict to file\n",
        "import json\n",
        "with open('data/rank_data.json', 'w') as f:\n",
        "    json.dump(rank_data, f)\n",
        "print('Rank data saved to file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "examples.iloc[4].sent_original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "research = pd.read_json('data/preprocessed/research.jsonl', lines=True)\n",
        "research[research.doi == '10.1093/mnras/stab3351']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_names_to_filenames = {\n",
        "    'BAAI/bge-small-en': 'bge',\n",
        "    'bert-base-uncased': 'bert',\n",
        "    'adsabs/astroBERT': 'astrobert'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "citeline",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
