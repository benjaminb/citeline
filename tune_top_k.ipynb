{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Top-k Query parameter\n",
    "\n",
    "First we set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home05/bbasseri/.conda/envs/clnb/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8265\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import torch\n",
    "from Enrichers import Enricher, get_enricher, ENRICHMENT_FN\n",
    "from database.database import DatabaseProcessor\n",
    "from Embedders import Embedder, get_embedder\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "print(os.getenv('DB_PORT'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================CONFIG=================================\n",
      "Database         User             Host                             Port            \n",
      "citeline_db      bbasseri         holy8a30112.rc.fas.harvard.edu   8265            \n",
      "========================================================================\n",
      "Database version: ('PostgreSQL 17.0 (Debian 17.0-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit',)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Database setup\n",
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT')\n",
    "}\n",
    "db = DatabaseProcessor(db_params)\n",
    "db.test_connection()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.mps.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating precision over `k`\n",
    "\n",
    "For our various embedding models and enrichment strategies, we want to know the smallest `top_k` value that will still retrieve the target reference for a given sentence. \n",
    "\n",
    "To investigate this, we'll sample 100 examples from the non-trivial training data. Each example typically has 1-2 target DOI's. For each example, we'll query the database with a large `top_k` parameter to start, so we can be sure the database returns the target references. Then we can ask at what index in the query results does a target DOI first appear. Ideally, the ranks will all be very high, indicated by having *low* indices in the query results. We also expect enriched examples to have their target doi's higher ranked (lower indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_doi</th>\n",
       "      <th>sent_original</th>\n",
       "      <th>sent_no_cit</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>citation_dois</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9902</th>\n",
       "      <td>10.1007/s00159-013-0064-5</td>\n",
       "      <td>CGRO observations of X-ray binaries detected n...</td>\n",
       "      <td>CGRO observations of X-ray binaries detected n...</td>\n",
       "      <td>821</td>\n",
       "      <td>[10.1086/305746]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>10.1016/S1387-6473(99)00004-4</td>\n",
       "      <td>By the time a 0.5 M ⊙ disk has dwindled to a t...</td>\n",
       "      <td>By the time a 0.5 M ⊙ disk has dwindled to a t...</td>\n",
       "      <td>77</td>\n",
       "      <td>[10.1086/115385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16785</th>\n",
       "      <td>10.1146/annurev.aa.31.090193.001135</td>\n",
       "      <td>New York: Springer-Verlag (1991) Aitken, D. K....</td>\n",
       "      <td>New York:  Aitken, D. K., Smith, C. H., James,...</td>\n",
       "      <td>420</td>\n",
       "      <td>[10.1086/115938]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34992</th>\n",
       "      <td>10.1016/j.newar.2023.101684</td>\n",
       "      <td>, 1988 and the spectroscopic mass ratio from R...</td>\n",
       "      <td>, 1988 and the spectroscopic mass ratio from R...</td>\n",
       "      <td>468</td>\n",
       "      <td>[10.1086/300933]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>10.1007/s00159-022-00140-3</td>\n",
       "      <td>Clouds with sufficiently short cooling time in...</td>\n",
       "      <td>Clouds with sufficiently short cooling time in...</td>\n",
       "      <td>662</td>\n",
       "      <td>[10.1093/mnras/stab3351]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                source_doi  \\\n",
       "9902             10.1007/s00159-013-0064-5   \n",
       "1808         10.1016/S1387-6473(99)00004-4   \n",
       "16785  10.1146/annurev.aa.31.090193.001135   \n",
       "34992          10.1016/j.newar.2023.101684   \n",
       "6646            10.1007/s00159-022-00140-3   \n",
       "\n",
       "                                           sent_original  \\\n",
       "9902   CGRO observations of X-ray binaries detected n...   \n",
       "1808   By the time a 0.5 M ⊙ disk has dwindled to a t...   \n",
       "16785  New York: Springer-Verlag (1991) Aitken, D. K....   \n",
       "34992  , 1988 and the spectroscopic mass ratio from R...   \n",
       "6646   Clouds with sufficiently short cooling time in...   \n",
       "\n",
       "                                             sent_no_cit  sent_idx  \\\n",
       "9902   CGRO observations of X-ray binaries detected n...       821   \n",
       "1808   By the time a 0.5 M ⊙ disk has dwindled to a t...        77   \n",
       "16785  New York:  Aitken, D. K., Smith, C. H., James,...       420   \n",
       "34992  , 1988 and the spectroscopic mass ratio from R...       468   \n",
       "6646   Clouds with sufficiently short cooling time in...       662   \n",
       "\n",
       "                  citation_dois  \n",
       "9902           [10.1086/305746]  \n",
       "1808           [10.1086/115385]  \n",
       "16785          [10.1086/115938]  \n",
       "34992          [10.1086/300933]  \n",
       "6646   [10.1093/mnras/stab3351]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database.database import SingleQueryResult\n",
    "\n",
    "data = pd.read_json('data/dataset/split/train.jsonl', lines=True)\n",
    "examples = data.sample(100, random_state=42)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_index_matching_doi(target_doi: str, query_results: list[SingleQueryResult]) -> int:\n",
    "    \"\"\"\n",
    "    Returns the first index of the query results where the chunk doi matches the target doi.\n",
    "    If no match is found, returns -1.\n",
    "    \"\"\"\n",
    "    for i, result in enumerate(query_results):\n",
    "        if target_doi == result.doi:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_ranks(\n",
    "    example: pd.Series,\n",
    "    embedder: Embedder,\n",
    "    enricher: Enricher,\n",
    "    table_name: str,\n",
    "    top_k: int,\n",
    "    ef_search: int,\n",
    "    metric: str = 'vector_cosine_ops'\n",
    ") -> list[int]:\n",
    "    target_dois = example['citation_dois']\n",
    "\n",
    "    # Prepare query vector\n",
    "    enriched_sentence = enricher.enrich(example=example)\n",
    "    embedding = embedder([enriched_sentence])[0]\n",
    "\n",
    "    # Query\n",
    "    start = time()\n",
    "    query_results = db.query_vector_table(\n",
    "        table_name=table_name,\n",
    "        query_vector=embedding,\n",
    "        metric=metric,\n",
    "        use_index=True,\n",
    "        top_k=top_k,\n",
    "        ef_search=ef_search\n",
    "    )\n",
    "    \n",
    "    ranks = [lowest_index_matching_doi(\n",
    "        target_doi=doi, query_results=query_results) for doi in target_dois]\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = get_embedder('bert-base-uncased', device=device)\n",
    "enricher = get_enricher('identity')\n",
    "embeddings = embedder(examples.sent_no_cit.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 26.62 seconds\n",
      "  Query fetch time: 0.00 seconds\n",
      "Time take: 26.627\n",
      "  Query execution time: 12.43 seconds\n",
      "  Query fetch time: 0.00 seconds\n",
      "Time take: 12.433\n",
      "  Query execution time: 12.75 seconds\n",
      "  Query fetch time: 0.00 seconds\n",
      "Time take: 12.763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m embeddings:\n\u001b[32m      2\u001b[39m     start = time()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     query_results = \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_vector_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbert_hnsw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvector_cosine_ops\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mef_search\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     end = time()\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTime take: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/n/holylabs/LABS/protopapas_lab/Lab/bbasseri/citeline/database/database.py:795\u001b[39m, in \u001b[36mDatabaseProcessor.query_vector_table\u001b[39m\u001b[34m(self, table_name, query_vector, metric, top_k, probes, ef_search, use_index)\u001b[39m\n\u001b[32m    791\u001b[39m     \u001b[38;5;66;03m# cursor.execute(f\"SET ivfflat.probes={probes};\")\u001b[39;00m\n\u001b[32m    794\u001b[39m start = time()\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\n\u001b[32m    797\u001b[39m \u001b[33;43m    -- EXPLAIN (ANALYZE, BUFFERS, VERBOSE, FORMAT JSON)\u001b[39;49m\n\u001b[32m    798\u001b[39m \u001b[33;43m    SELECT \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.chunk_id, chunks.doi, chunks.text, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.embedding \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moperator\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m %s AS distance\u001b[39;49m\n\u001b[32m    799\u001b[39m \u001b[33;43m    FROM \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[32m    800\u001b[39m \u001b[33;43m    JOIN chunks ON \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.chunk_id = chunks.id\u001b[39;49m\n\u001b[32m    801\u001b[39m \u001b[33;43m    ORDER BY \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.embedding \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moperator\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m %s ASC\u001b[39;49m\n\u001b[32m    802\u001b[39m \u001b[33;43m    LIMIT %s;\u001b[39;49m\n\u001b[32m    803\u001b[39m \u001b[33;43m    \u001b[39;49m\u001b[33;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Query execution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    808\u001b[39m start = time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/clnb/lib/python3.11/encodings/utf_8.py:15\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(input, errors)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[32m     13\u001b[39m encode = codecs.utf_8_encode\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.utf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIncrementalEncoder\u001b[39;00m(codecs.IncrementalEncoder):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for embedding in embeddings:\n",
    "    start = time()\n",
    "    query_results = db.query_vector_table(\n",
    "        table_name='bert_hnsw',\n",
    "        query_vector=embedding,\n",
    "        metric='vector_cosine_ops',\n",
    "        top_k=50,\n",
    "        ef_search=50)\n",
    "    end = time()\n",
    "    print(f\"Time take: {end - start:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model: BAAI/bge-small-en, Enricher: identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:28<47:14, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 21.89 seconds\n",
      "  Query fetch time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:39<30:06, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 11.17 seconds\n",
      "  Query fetch time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:51<24:43, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 11.52 seconds\n",
      "  Query fetch time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:02<21:49, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 11.09 seconds\n",
      "  Query fetch time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:14<20:41, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query execution time: 12.05 seconds\n",
      "  Query fetch time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:25<27:09, 17.15s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "embedding_models = ['BAAI/bge-small-en']\n",
    "if device == 'cuda':\n",
    "    embedding_models += ['bert-base-uncased', 'adsabs/astroBERT']\n",
    "enrichers = ENRICHMENT_FN.keys()\n",
    "combos = list(product(embedding_models, enrichers))\n",
    "\n",
    "model_names_to_tables = {\n",
    "    'BAAI/bge-small-en': 'bge',\n",
    "    'bert-base-uncased': 'bert_hnsw',\n",
    "    'adsabs/astroBERT': 'astrobert_hnsw'\n",
    "}\n",
    "\n",
    "# Dict mapping \"model name\": pd.DataFrame() of results (enrichment functions used -> columns)\n",
    "results = {model: pd.DataFrame() for model in embedding_models}\n",
    "top_k=50\n",
    "\n",
    "for embedding_model, enricher_name in combos:\n",
    "    print(f\"Embedding model: {embedding_model}, Enricher: {enricher_name}\")\n",
    "    embedder = get_embedder(embedding_model, device=device)\n",
    "    enricher = get_enricher(enricher_name)\n",
    "    table_name = model_names_to_tables[embedding_model]\n",
    "    ranks = []\n",
    "    for i in tqdm(range(len(examples))):\n",
    "        example = examples.iloc[i]\n",
    "        ranks += get_ranks(\n",
    "            example=example, \n",
    "            embedder=embedder, \n",
    "            enricher=enricher,\n",
    "            table_name=table_name,\n",
    "            top_k=top_k,\n",
    "            ef_search=top_k)\n",
    "    series = pd.Series(ranks)\n",
    "    results[embedding_model][enricher_name] = series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results for BAAI/bge-small-en to tests/bge_ranks.csv\n"
     ]
    }
   ],
   "source": [
    "model_names_to_filenames = {\n",
    "    'BAAI/bge-small-en': 'bge',\n",
    "    'bert-base-uncased': 'bert',\n",
    "    'adsabs/astroBERT': 'astrobert'\n",
    "}\n",
    "\n",
    "# Save the results to CSV files\n",
    "for model_name, df in results.items():\n",
    "    filename = f\"tests/{model_names_to_filenames[model_name]}_ranks.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved results for {model_name} to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-clnb]",
   "language": "python",
   "name": "conda-env-.conda-clnb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
