{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Top-k Query parameter\n",
    "\n",
    "First we set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================CONFIG=================================\n",
      "Database         User             Host                             Port            \n",
      "citeline_db      bbasseri         localhost                        5432            \n",
      "========================================================================\n",
      "Database version: ('PostgreSQL 17.3 (Homebrew) on x86_64-apple-darwin23.6.0, compiled by Apple clang version 16.0.0 (clang-1600.0.26.6), 64-bit',)\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from Enrichers import Enricher, get_enricher\n",
    "from database.database import DatabaseProcessor\n",
    "from Embedders import Embedder, get_embedder\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv('.env', override=True)\n",
    "\n",
    "# Database setup\n",
    "db_params = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT')\n",
    "}\n",
    "db = DatabaseProcessor(db_params)\n",
    "db.test_connection()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available(\n",
    ") else 'mps' if torch.mps.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating precision over `k`\n",
    "\n",
    "For our various embedding models and enrichment strategies, we want to know the smallest `top_k` value that will still retrieve the target reference for a given sentence. \n",
    "\n",
    "To investigate this, we'll sample 100 examples from the non-trivial training data. Each example typically has 1-2 target DOI's. For each example, we'll query the database with a large `top_k` parameter to start, so we can be sure the database returns the target references. Then we can ask at what index in the query results does a target DOI first appear. Ideally, the ranks will all be very high, indicated by having *low* indices in the query results. We also expect enriched examples to have their target doi's higher ranked (lower indices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.database import SingleQueryResult\n",
    "\n",
    "data = pd.read_json('data/dataset/split/train.jsonl', lines=True)\n",
    "examples = data.sample(100, random_state=42)\n",
    "\n",
    "def lowest_index_matching_doi(target_doi: str, query_results: list[SingleQueryResult]) -> int:\n",
    "    for i, result in enumerate(query_results):\n",
    "        if target_doi == result.doi:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def get_ranks(\n",
    "    example: pd.Series,\n",
    "    embedder: Embedder,\n",
    "    enricher: Enricher,\n",
    "    table_name: str,\n",
    "    top_k:\n",
    "    int,\n",
    "    metric: str = 'vector_cosine_ops'\n",
    ") -> list[int]:\n",
    "    target_dois = example['citation_dois']\n",
    "\n",
    "    # Prepare query vector\n",
    "    enriched_sentence = enricher.enrich(example=example)\n",
    "    embedding = embedder([enriched_sentence])[0]\n",
    "\n",
    "    # Query\n",
    "    query_results = db.query_vector_table(\n",
    "        table_name=table_name,\n",
    "        query_vector=embedding,\n",
    "        metric=metric,\n",
    "        use_index=True,\n",
    "        top_k=top_k\n",
    "    )\n",
    "    ranks = [lowest_index_matching_doi(\n",
    "        target_doi=doi, query_results=query_results) for doi in target_dois]\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:47<00:00,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrichment function: add_headers_and_previous_7_sentences.\n",
      "Stats: count      112.000000\n",
      "mean      3136.544643\n",
      "std       7961.988777\n",
      "min          0.000000\n",
      "25%         38.250000\n",
      "50%        373.000000\n",
      "75%       2512.750000\n",
      "max      52857.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedder = get_embedder(model_name='BAAI/bge-small-en', device=device, normalize=True)\n",
    "# from Enrichers import ENRICHMENT_FN as enrichment_functions\n",
    "\n",
    "\n",
    "results = {}\n",
    "for fn in ['add_headers_and_previous_7_sentences']:\n",
    "    enricher = get_enricher(fn)\n",
    "    ranks = []\n",
    "    for i in tqdm(range(len(examples))):\n",
    "        example = examples.iloc[i]\n",
    "        ranks += get_ranks(\n",
    "            example=example, \n",
    "            embedder=embedder, \n",
    "            enricher=enricher,\n",
    "            table_name='bge', \n",
    "            top_k=340000)\n",
    "    results[fn] = ranks\n",
    "    series = pd.Series(ranks)\n",
    "    print(f\"Enrichment function: {fn}.\")\n",
    "    print(f\"Stats: {series.describe()}\")\n",
    "# Save results\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('ranks3.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>add_abstract</th>\n",
       "      <th>add_title</th>\n",
       "      <th>add_title_and_abstract</th>\n",
       "      <th>add_previous_3_sentences</th>\n",
       "      <th>add_previous_7_sentences</th>\n",
       "      <th>add_headers_and_previous_3_sentences</th>\n",
       "      <th>add_headers_and_previous_7_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>1037</td>\n",
       "      <td>6</td>\n",
       "      <td>545</td>\n",
       "      <td>259</td>\n",
       "      <td>2974</td>\n",
       "      <td>1074</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>44</td>\n",
       "      <td>599</td>\n",
       "      <td>539</td>\n",
       "      <td>216</td>\n",
       "      <td>230</td>\n",
       "      <td>847</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7565</td>\n",
       "      <td>179</td>\n",
       "      <td>175</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1869</td>\n",
       "      <td>235</td>\n",
       "      <td>305</td>\n",
       "      <td>303</td>\n",
       "      <td>629</td>\n",
       "      <td>2489</td>\n",
       "      <td>458</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>3700</td>\n",
       "      <td>119</td>\n",
       "      <td>2313</td>\n",
       "      <td>651</td>\n",
       "      <td>7159</td>\n",
       "      <td>3887</td>\n",
       "      <td>3080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity  add_abstract  add_title  add_title_and_abstract  \\\n",
       "0        34          1037          6                     545   \n",
       "1       128            44        599                     539   \n",
       "2      7565           179        175                      18   \n",
       "3      1869           235        305                     303   \n",
       "4        23          3700        119                    2313   \n",
       "\n",
       "   add_previous_3_sentences  add_previous_7_sentences  \\\n",
       "0                       259                      2974   \n",
       "1                       216                       230   \n",
       "2                         3                        57   \n",
       "3                       629                      2489   \n",
       "4                       651                      7159   \n",
       "\n",
       "   add_headers_and_previous_3_sentences  add_headers_and_previous_7_sentences  \n",
       "0                                  1074                                   568  \n",
       "1                                   847                                   865  \n",
       "2                                    13                                    20  \n",
       "3                                   458                                   375  \n",
       "4                                  3887                                  3080  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('ranks.csv')\n",
    "df2 = pd.read_csv('ranks2.csv')\n",
    "df3 = pd.read_csv('ranks3.csv')\n",
    "df_combined = pd.concat([df1, df2, df3], axis=1)\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ranks.csv')\n",
    "df.add_title.describe()\n",
    "df.add_abstract.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again at 100,000 top k\n",
    "ranks = []\n",
    "for i in tqdm(range(len(examples))):\n",
    "    example = examples.iloc[i]\n",
    "    ranks += get_ranks(example=example, table_name='bge', top_k=250000)\n",
    "\n",
    "print(ranks)\n",
    "\n",
    "len([rank for rank in ranks if rank == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of ranks: {len(ranks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "plt.hist(ranks, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
